{"pages":[{"title":"About","text":"I’m Uy Nguyen.I’m a Software Engineer, creating awesome and effective softwares to serve people around the world.Let’s start scrolling and learn more about me. Education:University of Science - Vietnam National UniversityBachelor in Software Engineering, GPA 8.86 / 10.0Thesis: Web-based IDE for collaborating programming.This system allows users to create projects, build, run and debug applications online with an IDE that supports three majors programming languages: C/C++, C#, and Java. If there are any problems while development, users can post questions linked to their projects, other members will help them to solve the problems by answering the questions directly. By using this system, users will not have to spend time installing IDEs on their computers and reducing debugging time thanks to the help of the community. ProjectsClue: Construction ManagementClue App allows users to control equipment and construction projects in a single platform; generate real-time insights and performance reports to maximize the productivity of the operation.Link to App Store (React Native)Link to Google Play (React Native) Software Development Kit – Fossil GroupThe Fossil App is the companion app for Fossil’s line of smartwatches. Receive alerts from your favorite contacts and apps, compare multiple time zones and track everything from steps to sleep through the app. Turn your smartwatch into a remote control with customizable buttons that can control your music, check your commute time and more.As a Device Integration Engineer, I develop an SDK built in Bluetooth Low Energy technology in iOS. The SDK lets the application communicate with smartwatches or trackers.Link to App Store (iOS Native, Swift / Objective-C, CoreBluetooth) Dark Hat (Side project)An iOS BLE tool written in Swift supports test and control BLE devices.Link to App Store (iOS Native, Swift) Ayobody (Side project)Fitness social app connects users to Personal Nutrition Coach.Provide Personal Meal Plan: Craft a personal nutrition plan, get recommendations and track progress of users.Link to App Store (React Native)Link to Google Play (React Native) HTVC Calendar (Side project)HTV Calendar was built in React Native. It provides information of TV shows and events in Vietnam every day. It also allows users to add/edit/remove personal notes including notification feature.Link to App Store (React Native)Link to Google Play (React Native) News Market (Side project)News Market is the place to sell news between news hunters and media channels or newspapers.Website (ReactJs): http://chotintuc.htvc.com.vn Link to App Store (iOS Native, Swift)Link to Google Play (Android Native, Kotlin) Working Experiences: Senior Software Engineer at CLUEClue app allows users to manage construction projects and equipment by providing real-time insights in one platform.Detailed achievements: Develop Clue application in React Native. Build a native Bluetooth module to track equipment using BLE. Work directly with CTO and Product Owner to research new features. Support to develop web app in React and back-end side in Python. Device Integration Engineer at Fossil Vietnam - MisfitDesign and implement software components to talk with Misfit/Fossil smartwatches, trackers and other wearable products.Detailed achievements: Develop advanced services and SDK (Software Development Kit) on iOS platform to work with Bluetooth Low Energy in Swift and Objective-C. Build iOS apps to demonstrate SDK’s functions. Analyzing and solving problems of the SDK by using Fabric, Firebase. Build an automation testing system: Support create test cases and run them automatically, then report the result in NodeJs and ReactJs. Continuously investigate new technologies and new frameworks to improve the library Former internship, Full stack developer, taembe.comWork with NodeJs and ReactJs.Detailed achievements: Work on implementing features and improving the back-end side in NodeJs. Work on Implementing and maintaining the front-end code in ReactJs. Work with database in CouchDB, PouchDB and MySQL. Former internship at Renesas Design VietnamWork on embedded system and embedded architecture.Detailed achievements: Develop and verify eight modules of RX chip series: I2C Bus Interface, CRC Calculator,D/A Converter, Data Operation Circuit, Data Transfer Controller, 8 Bit Timer, Compare Match Timer, Clock Frequency Accuracy Measurement Circuit. Technical Stacks: Solid computer science fundamentals with good knowledge of algorithms, data structure and design patterns. Proficiency in mobile development: React Native, iOS (Swift) and Android (Kotlin) Deep understanding of memory management and multi-threading, including GCD, blocks and dispatch queues. Familiar with iOS SDKs (UIKit, Cocoa Touch, Core Data, Core Location, Core Bluetooth). Deep understanding of RESTful API designs. Experience building web apps in NodeJs, ReactJs, and Python. Familiarity with continuous integration (Jenkins), application monitoring (Firebase, Sentry). Experience developing applications on EC2. Familiar with Alatsian, Jira and Agile software development.","link":"/about/index.html"}],"posts":[{"title":"Advanced iOS Concurrency: Async Operations [2]","text":"In the previous post, Advanced iOS Concurrency: Operations, we walked through the Operation concepts on iOS and made a demo application that fetches some posts of mine. After downloading the cover images, they will be applied to a simple filter, then be displayed in a table view. The application, however, has not been completed yet. There’s something that went wrong with our app making the app did not show downloaded images properly. In this tutorial, we will continue where we left off.Get ready! Operation life cycleTo find out why our app did not function properly, let’s review the current source code 123456789101112class DownloadImageOperation: Operation { override func main() { guard !isCancelled else { return } URLSession.shared.dataTask(with: self.url, completionHandler: { (data, res, error) in guard error == nil, let data = data else { return } self.outputImage = UIImage(data: data) }).resume() }} The following image describes the changes in states of operations. When the main method gets called, it will execute our asynchronous task and then exit immediately making the state of the operation switch to isFinish. At that point, our asynchronous task actually has not completed yet.Currently, we’re calling to download an image inside the main method of the Operation. The root cause is related to the Operation Life Cycle itself. Thus, to support asynchronous operations in our app, we need to manually manage states of operations. Key-Value ObservingBefore implementing our custom Async Operation class, we need to learn a new concept first: KVO. I assume that you’ve not heard about this concept so we will have a quick look at it first.Key-Value Observing, aka KVO, is one of the techniques for observing the state changes of an object in Objective-C and Swift. Whenever the value of the observed properties changed, the observing block of code will execute. At the heart of KVO, the main concept is based on the Observer Pattern.Swift classes that are inherited from NSObject class have methods to allow other objects to observe their properties. Key-value observing provides a mechanism that allows objects to be notified of changes to specific properties of other objects. It is particularly useful for communication between model and controller layers in an application. Let’s create a Playground to test it. 1234567891011121314151617181920212223242526272829class CreditCard: NSObject { @objc dynamic private(set) var number: Int = 1000 func increaseNumber(by value: Int) { self.number += value }}class Person: NSObject { let cretdit: CreditCard var kvoToken: NSKeyValueObservation? init(cretdit: CreditCard) { self.cretdit = cretdit kvoToken = self.cretdit.observe(\\.number, options: .new) { (credit, change) in guard let newNumber = change.newValue else { return } print(\"New number is \\(newNumber)\") } } deinit { kvoToken?.invalidate() }}let credit = CreditCard()let person = Person(cretdit: credit)credit.increaseNumber(by: 500) Here, I define two classes: CreditCard and Person. A Person object holds a CreditCard object as a property. What I want is whenever the number property of the credit card gets changed, the person will be notified. Here is KVO comes.Run the above code in the playground, you should see the log New number is \\(newNumber) print out on your console. Why should we need to know about KVO? The answer is because the Operation class uses KVO notification. Whenever the state of Operation changes, a KVO notification will be sent.Without KVO notifications, the OperationQueue won’t be able to observe the state of our operations so that it can not get updated correctly. Thus, when we manage the state of operation by ourselves, we must ensure those KVO notifications are sent properly. Async OperationLet’s create AsyncOperation class inherited from the Operation class. 12345678910class AsyncOperation: Operation { enum State: String { case ready, executing, finished var keyPath: String { return \"is\\(rawValue.capitalized)\" } } // The rest of code} Next, We declare a property to keep track the state of the object. 12345678910var state = State.ready { willSet { willChangeValue(forKey: newValue.keyPath) willChangeValue(forKey: state.keyPath) } didSet { didChangeValue(forKey: oldValue.keyPath) didChangeValue(forKey: state.keyPath) }} The Operation base class needs to know the changes of both the old state and new state.Take a specified case as an example, the state currently is ready, then we set the state to executing. There are 4 KVO notifications should be sent: Firstly, notify the willChangeValue for isReady. Then. notify the willChangeValue for executing. After that, notfiy the willChange for isReady. Finally, notfiy the willChange for executing. After that, We override the properties of states. 123456789101112131415override var isReady: Bool { return super.isReady &amp;&amp; state == .ready}override var isExecuting: Bool { return state == .executing}override var isFinished: Bool { return state == .finished}override var isAsynchronous: Bool { return true} It’s all for managing the state of Async Operation class. When adding an operation to an operation queue, the start method is what gets called first. then it will call the main method of the operation executing the main block of code you have assigned to the operation. 1234override func start() { main() state = .executing} Remember when I mentioned that Operation has killer features that make it surpass GDC? The first one is dependencies and the other one is the capability of canceling a running operation. It’s very useful in a case where we want to stop operations that are irrelevant at a certain time. For example, to cancel downloading data when the user scrolls the table making some cells disappear.Let’s add this feature to our Async Operation class.First, we need to modify the start method to check the isCancelled property before actually calling the main method. 123456789override func start() { if isCancelled { state = .finished return } main() state = .executing} And then override the cancel method to update the state to finished 123override func cancel() { state = .finished} At this point, we’ve finished implementing our Async Operation class. It’s time to mix everything together in our app. Adding this all togetherBecause the DownloadImageOperation class executes asynchronously, we can not set Operation class as its base class, we now set AsyncOperation instead. Kindly note that to support canceling in DownloadImageOperation class, we will keep the return value of creating a data task as a property of this class so that we can cancel this URLSessionDataTask later.The DownloadImageOperation class will look like below. 123456789101112131415161718192021222324252627282930class DownloadImageOperation: AsyncOperation { let url: URL var outputImage: UIImage? private var task: URLSessionDataTask? init(url: URL) { self.url = url } override func main() { self.task = URLSession.shared.dataTask(with: self.url, completionHandler: { [weak self] (data, res, error) in guard let `self` = self else { return } defer { self.state = .finished } guard !self.isCancelled else { return } guard error == nil, let data = data else { return } self.outputImage = UIImage(data: data) }) task?.resume() } override func cancel() { super.cancel() task?.cancel() }} Let’s back to our main ViewController. To cancel the running operations, we first add new dictionary as a property of ViewController which tracks all running operations for each table view cell at a corresponding index path. 1private var operations: [IndexPath: [Operation]] = [:] Inside the func tableView(_ tableView:cellForRowAt indexPath:) delegate, after adding two operations to the operation queue, we will also add them to the operations dictionary for tracking. Additionally, if there is an operation for this index path, cancel it before holding the new one. 123456if let existingOperations = operations[indexPath] { for operation in existingOperations { operation.cancel() }}operations[indexPath] = [grayScaleOpt, downloadOpt] When the user scrolls the table, some cells disappear and the delegate func tableView(_ tableView:didEndDisplaying cell:indexPath:) gets called. At that point, we’ll also cancel the running operations for that cell ensuring that only operations of visible cells are executing. 1234567func tableView(_ tableView: UITableView, didEndDisplaying cell: UITableViewCell, forRowAt indexPath: IndexPath) { if let operations = operations[indexPath] { for operation in operations { operation.cancel() } }} Now, you should see the app now works properly. Additionally, by starting and canceling the operations wisely, we’re saving the network traffic as well as reduce the battery consumption. Those things can make our app run faster. ConclusionThere are some benefits of Operation over GCD that keep our source code maintainable and reusable.The last to mention, please careful when using Operation or GCD because Concurrency sometimes introduces bugs that are not always transparent to find and fix. In Clean Code Book, Robert C. Martin states some important points when working with multiple threads There are some basic definitions we should know when we talk about concurrency and threads: Bound resources, mutual exclusion, starvation, deadlock, and livelock. Concurrency does not always improve performance. It sometimes incurs some overhead and bugs come from it are not usually repeatable. Limit the access of the data that is shared between more than two threads. Use copies of data if there is a chance. Keep the synchronized sections as small as possible because Locks create delays and add overhead. They are expensive. Multithreaded code behaves differently in different environments: Run tests in every potential deployment environment. You can find the final project via the linkThank you for reading. References Chapter 6: Operations, Concurrency By Tutorials - Multithreading in Swift with GCD and Operations, Raywenderlich, Chapter 7: Concurrency and Multitasking, iOS 8 Swift Programming Cookbook, O’Reilly.","link":"/2020/05/30/Advanced-iOS-Concurrency-Async-Operations-2/"},{"title":"ANCS: Apple Notification Center Service","text":"PrefaceANCS, stands for Apple Notification Center Service, is designed by Apple. It allows Bluetooth accessories that connect to iOS devices via BLE a simple way to access notifications that happend on iOS devices. Technical details","link":"/2018/09/20/ANCS-Apple-Notification-Center-Service/"},{"title":"Asynchronous Programming in Swift","text":"Promise Kit, one of the best frameworks to deal with asynchronous programming in Swift In this post, I will use these following third parties to complete the project: Alamofire: A HTTP networking framework in Swift. SwiftyJSON: To process JSON data. SwiftGifOrigin: An UIImage extension to display Gif files. Bolts-Swift: Was designed by Parse and Facebook, I use it to create asynchronous methods. PromiseKit: A framework helps us to simplify asynchronous programming. Giphy’s APIs for searching and downloading gif images. Getting Started Asynchronous methods, (Async for short), are the methods that not immediately returning results like most method, the async methods take some time to produce results.I often use callbacks to deal with asynchronous methods like scanning Bluetooth devices or retrieving some resources from the internet. In fact, callback is a bad programming technique. Callback will make our code hard to read, hard to debug and take much more time to maintain later. In the end, our code will turn into something that we call the callback hell.In this post, I will create a project using one by one technique to explain why I said callback is bad.Firstly, go ahead and create a project, named it as whatever you like, then install these Pod frameworks to your project. You also need to edit the NSAllowsArbitraryLoads key to YES in NSAppTransportSecurity dictionary in the info.plist file to specify which domains are excepted from the rules you define for App Transport Security. In our case, this is the giphy domain. Allow HTTP requests for only giphy domain 1234567891011&lt;key&gt;NSAppTransportSecurity&lt;/key&gt; &lt;dict&gt; &lt;key&gt;NSExceptionDomains&lt;/key&gt; &lt;dict&gt; &lt;key&gt;api.giphy.com&lt;/key&gt; &lt;dict&gt; &lt;key&gt;NSExceptionAllowsInsecureHTTPLoads&lt;/key&gt; &lt;true/&gt; &lt;/dict&gt; &lt;/dict&gt;&lt;/dict&gt; Or allow HTTP requests for all domains, it is not a good idea. 12345&lt;key&gt;NSAppTransportSecurity&lt;/key&gt;&lt;dict&gt; &lt;key&gt;NSAllowsArbitraryLoads&lt;/key&gt; &lt;true/&gt;&lt;/dict&gt; Let’s create a class named ImageLoader. This class contains two methods that help us to fetch and download gif images from the Giphy server. 123456789101112//// ImageLoader.swift//class ImageLoader { func fetchImage(keyword: String) { // Searching images that matched keyword on Giphy server } func downloadImage(url: URL) { // Download the image at url }} The first version: Using callbackFirstly, we need to define two callbacks, which will be passed to the fetchImage and downloadImage methods. 12public typealias FetchImageBlock = (URL?, Error?) -&gt; Voidpublic typealias DownloadImageBlock = (URL?, Error?) -&gt; Void Then, we implement these two methods: fetchImage takes a keyword and a callback as params, sends a request to the Giphy server to query all images that match the keyword, gets the first one and finally returns the download url via the callback. downloadImage takes an url and a callback as params, then uses the Alamofire framework to download the image. Finally, returning the destination url, where the image is saved, via the callback. 123456789101112131415161718192021func fetchImage(keyword: String, callback: @escaping FetchImageBlock) { let endPoint = \"http://api.giphy.com/v1/gifs/search?q=\\(keyword)&amp;limit=1&amp;api_key=q4N1oD5jw3xvH2hIOkFAyHXWTTrh0D30\" let headers: HTTPHeaders = [ \"Content-Type\": \"application/json\" ] Alamofire.request(endPoint, headers: headers).responseData { (response) in if let error = response.error { return callback(nil, error) } let jsonData = JSON.init(data: response.data!) let dataArray = jsonData[\"data\"].array if let dataArray = dataArray, dataArray.count &gt; 0 { let imagesList = dataArray[0][\"images\"] let downsized_large = imagesList[\"downsized_large\"][\"url\"].stringValue return callback(URL.init(string: downsized_large), nil) } else { return callback(nil, nil) } }} 123456789101112131415func downloadImage(url: URL, callback: @escaping DownloadImageBlock) { let destination: DownloadRequest.DownloadFileDestination = { _, _ in let documentsURL = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0] let fileURL = documentsURL.appendingPathComponent(url.lastPathComponent) return (fileURL, [.removePreviousFile, .createIntermediateDirectories]) } Alamofire.download(url, to: destination).downloadProgress(closure: { (progress) in print(\"\\(progress)\") }).responseData(completionHandler: { (response) in if let error = response.error { return callback(nil, error) } callback(response.destinationURL, nil) })} Inside the main view controller, let’s define a method called searchImageWithKeyword. This method takes a keyword as a param, then pass the param to the fetchImage method of an instance of the ImageLoader class. We also need to pass a callback to handle the results.Inside the fetchImage callback, let’s check if there are any errors. If it is, then we stop calling the next method, downloadImage. Otherwise, we call the downloadImage of the imageLoader object. Then pass the url and a callback as params.Inside the downloadImage callback, let’s check if there are any errors. If it is, then we stop calling the next one. Otherwise, we update the image view on the main view by calling the updateImageAtURL method. 12345678910111213141516171819202122232425262728func searchImageWithKeyword(keyword: String) { let imageLoader = ImageLoader() imageLoader.fetchImage(keyword: keyword, callback: {downloadLink, error in if let error = error { print(\"Error \\(error)\") } else { if let downloadLink = downloadLink { imageLoader.downloadImage(url: downloadLink, callback: {downloadedURL, error in if let error = error { print(\"Error \\(error)\") } else { if let downloadedURL = downloadedURL { self.updateImageAtURL(url: downloadedURL) } else { print(\"Error: downloadedURL is nil\") } } }) } else { print(\"Error: downloadLink is nil\") } } })} 123456789101112131415func updateImageAtURL(url: URL) { guard Thread.isMainThread else { DispatchQueue.main.async { self.updateImageAtURL(url: url) } return } do { let data = try Data.init(contentsOf: url) self.imgImage.image = UIImage.gif(data: data) } catch { print(\"Error \\(error)\") }} As you can see, the searchImageWithKeyword is quite complex with many if and else statements inside the method. We have to check errors in many lines of codes. Imagine how complex it would be if we had more than three methods inside itself? A callback hell in another language, Javascript Build and run the project. Enter a keyword you want to search on the Giphy server, press search button then you will see the first result. The async programming project A better solution: Using BoltsBolts is a framework that was designed by Parse and Facebook, I use it to create asynchronous methods, without using callback. Bolts framework lets we write code as a series of actions based on events. 123456789101112131415161718192021222324func fetchImage(keyword: String) -&gt; Task&lt;URL&gt;! { let mainTask = TaskCompletionSource&lt;URL&gt;() let endPoint = \"http://api.giphy.com/v1/gifs/search?q=\\(keyword)&amp;limit=1&amp;api_key=q4N1oD5jw3xvH2hIOkFAyHXWTTrh0D30\" let headers: HTTPHeaders = [ \"Content-Type\": \"application/json\" ] Alamofire.request(endPoint, headers: headers).responseData { (response) in if let error = response.error { return mainTask.set(error: error) } let jsonData = JSON.init(data: response.data!) let dataArray = jsonData[\"data\"].array if let dataArray = dataArray, dataArray.count &gt; 0 { let imagesList = dataArray[0][\"images\"] let fixed_height_still = imagesList[\"downsized_large\"][\"url\"].stringValue return mainTask.set(result: URL.init(string: fixed_height_still)!) } else { return mainTask.set(error: NSError.init(domain: \"myDomain\", code: 0, userInfo: nil)) } } return mainTask.task} 1234567891011121314151617181920212223func downloadImage(url: URL) -&gt; Task&lt;URL&gt;! { let mainTask = TaskCompletionSource&lt;URL&gt;() let destination: DownloadRequest.DownloadFileDestination = { _, _ in let documentsURL = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0] let fileURL = documentsURL.appendingPathComponent(url.lastPathComponent) return (fileURL, [.removePreviousFile, .createIntermediateDirectories]) } Alamofire.download(url, to: destination).downloadProgress(closure: { (progress) in print(\"\\(progress)\") }).responseData(completionHandler: { (response) in if let error = response.error { return mainTask.set(error: error) } if let destinationURL = response.destinationURL { return mainTask.set(result: destinationURL) } else { return mainTask.set(error: NSError.init(domain: \"myDomain\", code: 0, userInfo: nil)) } }) return mainTask.task} Let’s see how simple the searchImageWithKeyword would be by using Bolts. 12345678910func searchImageWithKeyword(keyword: String) { let imageLoader = ImageLoader() imageLoader.fetchImage(keyword: keyword).continueOnSuccessWith { (linkDownload) -&gt; Void in imageLoader.downloadImage(url: linkDownload).continueOnSuccessWith(continuation: { (downloadedURL) -&gt; Void in self.updateImageAtURL(url: downloadedURL) }) }.continueOnErrorWith { (error) in print(\"Error \\(error)\") }} Build and run the project, nothing changed. But the code is more readable than the first one, isn’t it? We gather all the errors in one place, also separate error handling and success code. A much better solution: Using PromiseKitOne thing I do not like about Bolts framework is the lack of documentation and example projects. When I first use Bolts framework, I was very hard to get used to with the APIs of the Task object.At the Swift Summit conference 2017, there was one speaker introduced a Framework to deal with async methods, PromiseKit. After the conference, I replaced the code using Bolts framework by PromiseKit at the projects in my company. I realize my code now more readable. I think PromiseKit’s writing will be more familiar to developers than Bolts’s writing, especially those who have worked with Javascript like me.An async method created by using PromiseKit returns a new generic Promise, which is the primary class provided by PromiseKit. Its constructor takes a simple execution block with two parameters: fulfill: A function to call when the desired value is ready to fulfill the promise. reject: A function to call if there is an error. Let’s apply PromiseKit to our project 12345678910111213141516171819202122func fetchImage(keyword: String) -&gt; Promise&lt;URL&gt; { return Promise { fullfil, reject in let endPoint = \"http://api.giphy.com/v1/gifs/search?q=\\(keyword)&amp;limit=1&amp;api_key=q4N1oD5jw3xvH2hIOkFAyHXWTTrh0D30\" let headers: HTTPHeaders = [ \"Content-Type\": \"application/json\" ] Alamofire.request(endPoint, headers: headers).responseData { (response) in if let error = response.error { return reject(error) } let jsonData = JSON.init(data: response.data!) let dataArray = jsonData[\"data\"].array if let dataArray = dataArray, dataArray.count &gt; 0 { let imagesList = dataArray[0][\"images\"] let fixed_height_still = imagesList[\"downsized_large\"][\"url\"].stringValue return fullfil(URL.init(string: fixed_height_still)!) } return reject(NSError.init(domain: \"myDomain\", code: 0, userInfo: nil)) } }} 12345678910111213141516171819202122func downloadImage(url: URL) -&gt; Promise&lt;URL&gt; { return Promise { fullfil, reject in let destination: DownloadRequest.DownloadFileDestination = { _, _ in let documentsURL = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0] let fileURL = documentsURL.appendingPathComponent(url.lastPathComponent) return (fileURL, [.removePreviousFile, .createIntermediateDirectories]) } Alamofire.download(url, to: destination).downloadProgress(closure: { (progress) in print(\"\\(progress)\") }).responseData(completionHandler: { (response) in if let error = response.error { return reject(error) } if let destinationURL = response.destinationURL { return fullfil(destinationURL) } reject(NSError.init(domain: \"myDomain\", code: 0, userInfo: nil)) }) }} And the final result, what a beautiful code! :)) 123456789101112func searchImageWithKeyword(keyword: String) { let imageLoader = ImageLoader() firstly { imageLoader.fetchImage(keyword: keyword) }.then { downloadLink -&gt; Promise&lt;URL&gt; in return imageLoader.downloadImage(url: downloadLink) }.then {downloadedURL -&gt; Void in self.updateImageAtURL(url: downloadedURL) }.catch { error in print(\"Error \\(error)\") }} A feature that I find very interesting in both frameworks, Bolts and PromiseKit, is that they allow our code run on a given thread (Main thread or background thread). This is a great feature as most of the work done in the view controller has been to update the UI. Sometimes, long-running tasks are best handled on a background thread, so as not to tie up the UI. For more details about this Thread feature, please refer to their documents: #Threading ConclusionSince I am working on CoreBluetooth, I often have to work with async methods. Too many callbacks make my project more difficult to understand and difficult to debug if errors occur. Promise make my code become a more beautiful girl ;).You can download the fully finished sample project here.Feel free to leave out your comments on my post.","link":"/2018/01/16/Asynchronous-Programming-in-Swift/"},{"title":"All About Alamofire","text":"If you ever have a chance to work with networking on iOS, you definately have heard about Alamofire, a networking library written in Swift for iOS and MacOS. It simplifies all of the common networking jobs in your app.If you have not meet Alamofire yet, no worries, this tutorial will introduce you all tasks that Alamofire can handle for you. If you’re familiar with it, never mind, take this post as a summarize and a centralize of your Alamofire handbook.Let’s drive in! Coming soon! Build your own serverDesign the networking layerDependencies SwiftyJSON, a library supports to deal with JSON data. [SnapKit][https://github.com/SnapKit/SnapKit], Swift based Autolayout. Advanced topicFinal thought","link":"/2020/07/12/All-About-Alamofire/"},{"title":"Best practice: Advanced BLE scanning process on iOS","text":"iOS developers are building applications that play both roles Peripheral and Central to exchange data with other copies apps. The data can be exchange a small of information via BLE packets or the signal strength indicator (RSSI) value from one to the others. However, keeping the app last forever in the foreground is impossible. Sooner or later, the app will enter to background mode by the user and finally will be suspended by the system depending on RAM available, power consumption and other factors. Thus, understanding the procedure of advertising and scanning on iOS devices helps you to build good applications that fit your expectations.At the end of this tutorial, we will build a simple application that acts as both a scanner and an advertiser. When two applications find each other, they will write a log record for analysis. Depending on the results, we will find out how effective our application is using Core Bluetooth.Let’s switch the gear! Foundational knowledgeAccording to the Getting Started With Bluetooth Low Energy book, the two main purposes of advertising packets are: To broadcast data for applications. To discover slaves and to connect them. The maximum size of payload each advertising packet is 31 bytes, along with the header information. Every elapsed interval, which ranges from 20ms to 10.24s, advertising packets are broadcasted blindly to notify its presence to other devices or applications. There are two types of scanning approaches: Passive Scanning: Scanners simply receives advertising packets without any further actions. Active Scanning: After receiving an advertising packet, the scanner performs a Scanning Request packet to the advertiser. After receiving the Scanning Request, the advertiser responds with a Scanning Response packet which allows the advertises to send extra data (Extra 31 bytes) to the scanner. To classify advertising packet types, we rely on three properties: connectability, scannability, and directability Adv packet type Connectability: Determines if a scanner can make a connection or not Scannability: Determines if a scanner can issue a scan request or not Directability: Determines if this packet is targeted at any particular scanners or not. ADV_IND Yes Yes No ADV_DIRECT_IND Yes No Yes ADV_NONCONN_IND No No No ADV_SCAN_IND No Yes No There are a lot more advanced topics that described in more detail in the Getting Started With Bluetooth Low Energy book, such as how data is organized in BLE devices and how to communicate with existing hardware, etc. If you want to know more, please refer to the book.Because of the scope of this post, understanding of the advertising process is good enough for us to move to the next section. Scanning and advertising on iOSSetting up the advertiser - PeripheralWe’re going to reuse my previous repo allowing an ios phone advertises as a peripheral using Core Bluetooth.First, I will generate 5 UUIDs as the services of the advertiser (Peripheral). 1234let kServiceUUID1 = \"1FA2FD8A-17E0-4D3B-AF45-305DA6130E39\"...let kServiceUUID4 = \"4FA2FD8A-17E0-4D3B-AF45-305DA6130E39\"let kServiceUUID5 = \"5FA2FD8A-17E0-4D3B-AF45-305DA6130E39\" Next, I will create a list of CBMutableService and then add them to the CBPeripheralManager object. 12345678910111213141516services.forEach { (each) in let cbService = CBMutableService(type: each.uuid.cbUUID, primary: true) var charArr = [CBMutableCharacteristic]() each.characteristics.forEach { (char) in charArr.append(CBMutableCharacteristic.init( type: char.uuid.cbUUID, properties: [.read, .write, .notify], value: nil, permissions: CBAttributePermissions(char.permissions.map { $0.cbAttributePermission } ))) } cbService.characteristics = charArr self.peripheralManager.add(cbService)} Finally, we start advertising the peripheral when its state gets ready. 12self.peripheralManager.startAdvertising([CBAdvertisementDataLocalNameKey: \"uynguyen\", CBAdvertisementDataServiceUUIDsKey: self.cbServices.map { $0.uuid }]) As the above code gets executed, we will see the following log are printed. 123456789101112Add service 1FA2FD8A-17E0-4D3B-AF45-305DA6130E39 Succeeded---&gt; Chars [&lt;CBMutableCharacteristic: 0x2802d4070 UUID = 463FED20-DA93-45E7-B00F-B5CD99775150, Value = (null), Properties = 0x1A, Permissions = 0x3, Descriptors = (null), SubscribedCentrals = ()&gt;, &lt;CBMutableCharacteristic: 0x2802d4380 UUID = 463FED21-DA93-45E7-B00F-B5CD99775150, Value = (null), Properties = 0x112, Permissions = 0x1, Descriptors = (null), SubscribedCentrals = ()&gt;, &lt;CBMutableCharacteristic: 0x2802d4620 UUID = 463FED22-DA93-45E7-B00F-B5CD99775150, Value = {length = 6, bytes = 0x486168616861}, Properties = 0x2, Permissions = 0x1, Descriptors = (null), SubscribedCentrals = ()&gt;]...Add service 5FA2FD8A-17E0-4D3B-AF45-305DA6130E39 Succeeded---&gt; Chars []===&gt; Start advertising Succeeded Setting the scanner - CentralThe next step is to set up our Central Manage - the scanner. As you might know from my previous tutorial, the code to scan nearby devices is quite simple. 1234private func startScanning() { self.centralManager?.scanForPeripherals(withServices: nil, options: [CBCentralManagerScanOptionAllowDuplicatesKey: true])} The nil value we pass to withServices param indicates that we will scan all nearby devices without specifying service uuids. The CBCentralManagerScanOptionAllowDuplicatesKey option specifies the scan should run without duplicate filtering. Once the central discover a peripheral, we will print its info including the local name and the CBAdvertisementDataServiceUUIDsKey value in the advertising packet. 12345public func centralManager(_ central: CBCentralManager, didDiscover peripheral: CBPeripheral, advertisementData: [String : Any], rssi RSSI: NSNumber) { print(\"Did found per \\(peripheral.name)\") print(\"CBAdvertisementDataServiceUUIDsKey adv value \" + advertisementData[CBAdvertisementDataServiceUUIDsKey])// ...} Let’s build and run the project, 12345Did found peripheral name: Optional(\"Uy Nguyen iPad\")CBAdvertisementDataServiceUUIDsKey adv value:Optional(&lt;__NSArrayM 0x282a79350&gt;( 1FA2FD8A-17E0-4D3B-AF45-305DA6130E39)) Looking at the log, can you spot what’s going wrong? There is a problem with the advertising packet: the CBAdvertisementDataServiceUUIDsKey value contains only 1 service, where are the other services from 2 to 5? Let’s print out full advertising packet to see what it contains. 1234[\"kCBAdvDataServiceUUIDs\": &lt;__NSArrayM 0x283460630&gt;(1FA2FD8A-17E0-4D3B-AF45-305DA6130E39), \"kCBAdvDataLocalName\": uynguyen, \"kCBAdvDataTimestamp\": 620013184.4512661, \"kCBAdvDataRxPrimaryPHY\": 0, \"kCBAdvDataIsConnectable\": 1, \"kCBAdvDataRxSecondaryPHY\": 0] Still no luck, we can not find the other services from &quot;2FA2FD8A-17E0-4D3B-AF45-305DA6130E39&quot; to &quot;5FA2FD8A-17E0-4D3B-AF45-305DA6130E39&quot;. Finding problemsIt turns out the advertising packet the Central receive depends on how we call scanForPeripherals method.If we change param withServices to an array of our service from &quot;1FA2FD8A-17E0-4D3B-AF45-305DA6130E39&quot; to &quot;5FA2FD8A-17E0-4D3B-AF45-305DA6130E39&quot; explicitly, we will see the differences. 12345678private func startScanning() { self.centralManager?.scanForPeripherals(withServices: [CBUUID(string: \"1FA2FD8A-17E0-4D3B-AF45-305DA6130E39\"), CBUUID(string: \"2FA2FD8A-17E0-4D3B-AF45-305DA6130E39\"), CBUUID(string: \"3FA2FD8A-17E0-4D3B-AF45-305DA6130E39\"), CBUUID(string: \"4FA2FD8A-17E0-4D3B-AF45-305DA6130E39\"), CBUUID(string: \"5FA2FD8A-17E0-4D3B-AF45-305DA6130E39\")], options: [CBCentralManagerScanOptionAllowDuplicatesKey: true])} Here is the log that comes to. 12345678910[\"kCBAdvDataIsConnectable\": 1, \"kCBAdvDataServiceUUIDs\": &lt;__NSArrayM 0x280708750&gt;(1FA2FD8A-17E0-4D3B-AF45-305DA6130E39), \"kCBAdvDataLocalName\": uynguyen, \"kCBAdvDataRxSecondaryPHY\": 0, \"kCBAdvDataHashedServiceUUIDs\": &lt;__NSArrayM 0x280708720&gt;(2FA2FD8A-17E0-4D3B-AF45-305DA6130E39,3FA2FD8A-17E0-4D3B-AF45-305DA6130E39,4FA2FD8A-17E0-4D3B-AF45-305DA6130E39,5FA2FD8A-17E0-4D3B-AF45-305DA6130E39), \"kCBAdvDataRxPrimaryPHY\": 0, \"kCBAdvDataTimestamp\": 620013608.239601] Now, we can see the new value contained inside the advertising packet, the kCBAdvDataHashedServiceUUIDs. But what is it?Let’s back to the Peripheral side, if you look closer to the definition of the advertising method of Peripheral object, you might know what it actually is. In short, when you make an iPhone advertise as a peripheral, if there is no space for any services UUIDs contained in the value of CBAdvertisementDataServiceUUIDsKey, these services will be moved to another space called overflow area. Another term, T_T What does exactly the overflow area mean?Basically, the overflow area is placed in the scan response packet. These service uuids are hashed by Apple alg and are discovered only by an iOS device explicitly scanning for them. In our case, because we pass our service uuids from 1F to 5F when start scanning, we will get this kCBAdvDataHashedServiceUUIDs value in the advertising packets. To verify this statement, I use a tool introduced by Apple for BLE debugging - (A New Way to Debug iOS Bluetooth Applications), to grab the advertising packet from our Peripheral for analyzing.And here is the result Advertising packet type: ADV_IND, which means the scanner can make a connection to it; and a scanner can issue a scan request; and its packets do not target at any particular scanners. The yellow box is the advertising data: (Data: 02 01 1A 11 06 39 0E 13 A6 5D 30 45 AF 3B 4D E0 17 8A FD A2 1F 09 09 75 79 6E 67 75 79 65 6E), length = 31 bytes; it contains CBAdvertisementDataLocalName (75 79 6E 67 75 79 65 6E &gt; “uynguyen”) and our first service uuid 1F A2 FD 8A 17 E0 4D 3B AF 45 30 5D A6 13 0E 39 (39 0E 13 A6 5D 30 45 AF 3B 4D E0 17 8A FD A2 1F). The scan response packet (SCAN_RSP) contains the other info that the advertising packet is not enough length to carry on. In our case, it contains the other services from 2F to 5F. Understanding this packet is quite complex to put in this tutorial so I will skip explaining it for now. I have another tutorial working on this packet later. In conclusion, what we have found here is: Advertising, while the app is in background, performs differently than when it is in the foreground. CBAdvertisementDataLocalNameKey is ignored. All service UUIDs contained in the value of the CBAdvertisementDataServiceUUIDsKey advertisement key are placed in a special “overflow” area; they can be discovered only by an iOS device that is explicitly scanning for them. TestingThe table below summarizes what we have investigated. 1* YES means the Central is able to find the Peripheral. Case 1 - Both Peripheral and Central’s screens turn on \\ Peripheral Background Peripheral Foreground Central Background Yes Yes Central Foreground Yes Yes Case 2 - Peripheral’s screen turn off (locked), Central’s screen turn on \\ Peripheral Background Peripheral Foreground Central Background Yes Yes Central Foreground Yes Yes Case 3 - Central’s screen turn off (locked), Peripheral’s screen turn on \\ Peripheral Background Peripheral Foreground Central Background No No Central Foreground No No Case 4 - Both Peripheral and Central’s screens turn off (locked) \\ Peripheral Background Peripheral Foreground Central Background No No Central Foreground No No From the above experiments, regardless of the state of the device playing Peripheral role, the screen of the device playing Central mode must turn on so that it can scan nearby peripherals. In other words, if we’re building an application that allows an iOS device to discover other nearby iOS devices, we have to run both Central and Peripheral modes on each device AND the most important, if two devices want to find each other, either the screen must be turned on.There is a technique (It’s likely a trick) to get over this issue, is that scheduling periodically to push notifications to your iOS devices, which immediately turn the screen on so that the Central can discover nearby Peripherals.While the app is in background, it performs differently than when it is in the foreground. One of them is the frequency of advertising packets to be sent may decrease. As a result, a Scanner in background finds nearby peripherals is slower compared to when it is in foreground. ConclusionCongratulation! We walked through a tutorial to get a deeper view of how CoreBluetooth on iOS works in both Central and Peripheral modes. Hope you find this post interested!If you have any comments, feel free to send me an email to uynguyen.itus@gmail.com or leave your questions on the comment box. Made with love.","link":"/2020/08/23/Best-practice-Advanced-BLE-scanning-process-on-iOS/"},{"title":"Best practice: Core Data Concurrency","text":"Some applications can survive without any data storage. Most other useful applications, however, save some state such as user configurations, user profile, goals, etc. on iOS, Apple provides Core Data as a framework to persist your valuable data. One thing to keep in mind that although CoreData can store data in a relational database it’s actually not a database engine.In this tutorial, I will share with you a bad experience I faced when I work with Core Data. Hopefully, after reading my sharing, you will avoid facing the same problem in your projects.Let’s get started. Three main components of core data stackFirst of all, I will list down the three main components of core data stack, you might or might not familiar with these terms but it’s better to get a deep understand of core data stack before digging deeper.The Core Data API, also called the stack, consists of three main components: NSManagedObjectModel: The data model describes an entity (object). NSManagedObjectContext: The objects when fetched from the persistent storage are placed in managed object context. It performs validations and keeps track of the changes made to the object’s attributes so that undo and redo operations can be applied to it, if needed. In a given context, a managed object provides a representation of a record in a persistent store. Depending on a situation, there may be multiple contexts, each containing a separate managed object representing that record. All managed objects are registered with a managed object context. NSPersistentStoreCoordinator: NSManagedObjectContext does not work directly with NSPersistentStore to store and retrieve data, but NSPersistentStoreCoordinator will do so. The main roles of NSPersistentStoreCoordinator are to managed the state of managed object context and to serialize calls to NSPersistenStore to avoid redundancy. You can find the main roles of each component by the following image We have enough knowledge of Core Data and its different components. Now, let’s move forward to the main section. Core data supports concurrencyCore Data supports multi-threading in an application, which means more than one thread can be executed in parallel to increase performance. Even some tasks can be performed in the background using a separate thread.As you might know, when working with CoreData, there are two ways to define a managed object context: NSMainQueueConcurrencyType and NSPrivateQueueConcurrencyType. It depends on us to decide which type of MOC we should create in our applications. Mainly we will work on the main one, but to avoid doing data processing on the main queue, as it might affect the user experience when doing heavy tasks on the main thread, we sometimes need to create a private queue context and perform those heavy tasks on this private context.Concurrency absolutely makes the app more effective as tasks now can do in parallel, but there are some strict rules defined by Apple we must follow otherwise we will face some unexpected behaviors, including crashes and losing data. Rule 1: Managed object contexts are stuck with the thread that they are associated with upon declaration. The first rule states that do not use the main queue context in a background thread. Most of the time, there are no-fail at all if we violate the rule. When it comes to production, however, you will soon face crashes on your dashboard, resulting in bad user experiences and more importantly, leading to losing data. Rule 2: Managed objects retrieved from a context are stuck with the same queue that the context associated with. That means do not pass any objects retrived from main context to private one and vise versa. Violate this rule will lead to the same result as rule 1. Crash, crash, crash! 😱It has been the first time I use CoreData to store valuable data of users in our app. On one hand, I did not take core data concurrency seriously at that time. On the other hand, I do not know there are some strick rules when working with concurrency in Core Data. As a result, when the app comes to production, the number of crashes had been reported to the monitor dashboard. At that time, I had no idea how they come. I could not reproduce these issues to find out the root cause was. Additionally, the crash reported by Firebase did not have enough information for an investigation. I tried reviewing the flow of my app, searching on StackOverFlow and then reading deeply Apple’s document of Core Data. Finally, the root cause comes from accessing Core Data from multiple threads. As I’m working with Core Bluetooth, the key point is that Core Bluetooth dispatches Bluetooth events in the main thread by default. However, I configurated the Bluetooth queue to a background queue to avoid locking the UI queue. Here crashes come as Core Data does not allow to access NSManagedObject among different queues strictly. To simulate this issue, I created a non-stop loop to run inserting and deleting actions in a background queue continuously. The following code illustrates how I performed the test. 1234567891011121314override func viewDidLoad() { super.viewDidLoad() // Do any additional setup after loading the view. self.doSomething()}func doSomething() { self.managedContext?.insert(person: self.person) self.managedContext?.delete(person: self.person) DispatchQueue.global(qos: .background).asyncAfter(deadline: .now() + 0.1, execute: { self.doSomething() })} Sooner or later, the crash will come to us. 1232019-10-13 12:31:55.497690+0700 CoreData-Concurrency[90636:1151728] [error] error: Serious application error. Exception was caught during Core Data change processing. This is usually a bug within an observer of NSManagedObjectContextObjectsDidChangeNotification. -[__NSCFSet addObject:]: attempt to insert nil with userInfo (null)CoreData: error: Serious application error. Exception was caught during Core Data change processing. This is usually a bug within an observer of NSManagedObjectContextObjectsDidChangeNotification. -[__NSCFSet addObject:]: attempt to insert nil with userInfo (null)2019-10-13 12:31:55.569306+0700 CoreData-Concurrency[90636:1151728] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[__NSCFSet addObject:]: attempt to insert nil' Here are some answers from the community you can find on Stackoverflow:https://stackoverflow.com/questions/36402366/core-data-crash-attempt-to-insert-nil-with-userinfo-nullhttps://stackoverflow.com/questions/55517083/ios-core-data-serious-application-error-attempt-to-insert-nil-in-less-than Avoid crashingTo avoid the crash, the are two techniques we can apply, both of them make sure that we do not violate concurrent-confinement rules. #1The first one is to ensure that the managedObjectContext is performed on the queue that it is associated with upon initialization, which is the main queue in this case. 1234567func doSomething() { self.managedContext?.insert(person: self.person) self.managedContext?.delete(person: self.person) DispatchQueue.main.asyncAfter(deadline: .now() + 0.1, execute: { // Dispatch to main queue self.doSomething() })} In case for some reason, we can not execute the actions on the main queue (e.g importing huge data to disk) we can create multiple contexts to solve this problem. Move to #2. #2Using Core data multiple context technique.A child managed object context (MOC) does not hold a reference to the persistent store coordinator (PSC). Instead, it keeps a reference to another (MOC) as its parent. Whenever a child performs saveContext, the changes will be pushed to its parent, and keep pushing to other parents (If had). It is only when the root parent MOC performs saveContext, the changes are saved to the PSC. Let’s create a private MOC inside our PersonManagedObject class. 1private let privateMOC = NSManagedObjectContext(concurrencyType: .privateQueueConcurrencyType) Then set its parent as the main MOC. 12345init?() { ... privateMOC.parent = self.managedObjectContext} From now on, all action will be performed on this privateMOC. The method performAndWait blocks the caller from returning until the block is executed.The perform(_:) method returns immediately and the context executes the block methods on its own thread. With the performAndWait(_:) method, the context still executes the block methods on its own thread, but the method doesn’t return until the block is executed. 12345678func insert(person: Person) { ... // Some code are obmitted self.privateMOC.performAndWait { self.privateMOC.insert(object) synchronize() }} Don’t forget to call saveContext method of the parent context to save the changes to PSC. 1234567891011121314private func synchronize() { do { try self.privateMOC.save() // We call save on the private context, which moves all of the changes into the main queue context without blocking the main queue. self.managedObjectContext.performAndWait { do { try self.managedObjectContext.save() } catch { print(\"Could not synchonize data. \\(error), \\(error.localizedDescription)\") } } } catch { print(\"Could not synchonize data. \\(error), \\(error.localizedDescription)\") }} After modifying the code by using either #1 or #2, I ran the program again in a long time but there were no more crashes! ConclusionCore data is a very useful framework and certainly is indispensable in most mobile applications today. To avoid the same bad situations as I just went through, make sure you dig into its components before starting your code, especially core data concurrency.You can find my completed project at Github - Core Data ConcurrencyThanks for reading. References[1] B.M. Harwani - Core Data iOS Essentials-Packt Publishing (2011)[2] Core Data, Multithreading, and the Main Thread[3] [Multiple context CoreData] https://www.cocoanetics.com/2012/07/multi-context-coredata/","link":"/2019/09/01/Best-practice-Core-Data-Concurrency/"},{"title":"Best practice: How to deal with Bluetooth Low Energy in background","text":"PrefaceWhen working with CoreBluetooth, have you ever concerned that how the BLE app on iOS can survive when it is terminated by the system? How can we bring it back to the background? Is there anything like a service on Android that can last forever? You can find the answer to all these questions in this post. Read on! Application life cycle on iOSBefore getting a deep understanding of how we can survive our app in the background, it’s good to start with the application life-cycle on iOS.As you might know, there are five main states of every iOS app.Not running The app either has not been launched or was running but was terminated by the system or the user.Inactive It is the initial state before the app actually transitions to a different state.Active The app is running in the foreground and receiving events from the user.Background The app is in the background and be invisible to the user. However, an app that requests extra execution time may remain in this state for a period of time. In addition, the app will transit into the inactive state before entering into the background mode.Suspended The app is in the background but it does not allow to execute any code. The app is moved to this state automatically by the system and it will not receive any events before the system does so. When the foreground apps need more memory, the system may terminate the suspended apps to make more space for the foreground apps. Note that we can not predict when the suspended app will be terminated by the system. After being terminated, the app returns to the not running state. BLE issues with the application life cycleAs mentioned, when the app enters to the background, the app might be terminated by the system if it need evict resources for other applications. Unlike Android OS, after being killed by the system, we can re-start a service to keep your app alive. On iOS, once the app is terminated by the system, there is no way to bring it back to the background. As a result, any Bluetooth events that dispatch from the device will never come to the app. It means your app might miss the indications that are triggered by users, such as play a track of music on their phone when pressing physical buttons from a BLE device. Apple gives out an example called “Smart door”. The main idea of this example is to have an automatic interaction between the app and the lock of the door. Imagine we’re developing an application that can automatically lock and unlock the door when the user goes in and go out their home, respectively. However, the main problem of this implementation is to keep the connection between the two, the phone and the lock of the door. While using their phone, users do a variety of actions on the phone: open / close applications, toggle the Bluetooth setting, enter the airplane mode, reboot the phone, etc. These interactions can lead to our app is killed by the system, forever. In this case, the app will not be able to reconnect to the lock when the user returns home, and the user may not be able to unlock the door. To deal with this issue, Apple provides a method called State Preservation and Restoration (CoreBluetooth background processing). State Preservation and Restoration is built-in to CoreBluetooth that allows our app can be relaunched into the background when it’s terminated by the system.At the bottom line, iOS takes a snapshot of all the Bluetooth-related objects that were going on in our app. Subsequently, if there is any Bluetooth event which related to the Bluetooth-related objects our app were interacting with comes to the phone, our app will be waked up from the grave. That’s amazing! Implement State Preservation and RestorationTo demonstrate State Preservation and Restoration technique on iOS, I’m going to reuse the source code from the previous post Play Central And Peripheral Roles With CoreBluetooth but we’ll add some more code to the projects to make it become magical.First, I set my iPad act as a Peripheral with a uuid “1FA2FD8A-17E0-4D3B-AF45-305DA6130E39”, which is generated via uuidgen command on Mac. Then, make it start advertising with local name “iPad”. If there is a connection established by a central manager, the in/out logs will print so we know whether the connection is made successfully. When the “Send Notify” button is touched, the app will notify a data string “Say something cool!” via the “463FED21-DA93-45E7-B00F-B5CD99775150” that is defined as an encrypted notifiable characteristic of the app to the connected central manager. The next thing we need to do is go back to the Central Manager app and create a Restore Identifier for the CBCentralManager objects to be taken over by the operating system when the application is terminated, I chose “YourUniqueIdentifierKey” string. Next, we will implement the willRestoreState provided by Apple. 123456789101112131415161718public func centralManager(_ central: CBCentralManager, willRestoreState dict: [String : Any]) { LocalNotification.shared.showNotification(id: \"willrestorestate\", title: \"Manager will restore state\", body: \"\", timeInterval: 1.0) let systemSoundID: SystemSoundID = 1321 AudioServicesPlaySystemSound (systemSoundID) if let peripherals = dict[CBCentralManagerRestoredStatePeripheralsKey] as? [CBPeripheral] { peripherals.forEach { (awakedPeripheral) in print(\"\\(Date.now). - Awaked peripheral \\(String(describing: awakedPeripheral.name))\") guard let localName = awakedPeripheral.name, localName == \"iPad\" else { return } self.connectedDevice = Device.init(peripheral: awakedPeripheral) } }} Here, when the centralManager(_:, willRestoreState) is called, I will play a soundtrack and show a pop-up with the name of awaked peripheral to inform that the app is actually awaked by the system. Inside the method, we also can get a dictionary full of state information. When we retrieved with the CBCentralManagerRestoredStatePeripheralsKey key, this holds things like an array of CBPeripheral, containing all peripherals that were connected or pending connection at the time the application was terminated by the system. Here, I iterate through the array of peripherals, check if there is my interested peripheral, then initialize a Device and set it back to the connectedDevice variable so that I can receive updated values from the peripheral. I also add the code that will popup a local notification at the appDidFinishLaunching delegate and at peripheral(:didUpdateValueFor:chacracteristic) method for testing. 123456func peripheral(_ peripheral: CBPeripheral, didUpdateValueFor characteristic: CBCharacteristic, error: Error?) { if let data = characteristic.value { let str = String.init(data: data, encoding: .utf8) ?? \"\" LocalNotification.shared.showNotification(id: \"DidUpdateValue\", title: \"Peripheral did update value from grave!\", body: \"\\(str)\", timeInterval: 1.0) }} 12345678func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -&gt; Bool { let _ = BluetoothManager.sharedInstance let _ = LocalNotification.shared LocalNotification.shared.showNotification(id: \"didfinishlaunch\", title: \"App did finish launching\", body: \"Options: \\(launchOptions?[UIApplicationLaunchOptionsKey.bluetoothCentrals] ?? \"nil\")\", timeInterval: 1.0) return true} It’s time to run our experiment! I’m going to use two methods to simulate background app termination by the system.The first one is using XCode. Run the app from Xcode. Stop the app by pressing the “Stop” button from Xcode. Restart the app from Xcode. The second one is doing the following steps: Press the home button to enter the app to background. Long press the power button until you see “slide to power off”. Release the power button and long press the home button for about 5s (until you see your home screen reappeared). In the below demonstration, you will see I use both of them for testing. Let’s see something cool happens! Here is the log printed from Xcode. 123456789102018-08-18 19:46:35.6560 App did finish lauching with option nil2018-08-18 19:46:35.6620 Manager will restore state2018-08-18 19:46:35.6650. - Awaked peripheral Optional(\"iPad\")2018-08-18 19:46:35.6660 Manager did update state 52018-08-18 19:46:35.6950 App did become active2018-08-18 19:46:35.7080 Found iPad2018-08-18 19:46:35.7100 Did connect.2018-08-18 19:46:51.5170 App will resign active2018-08-18 19:46:52.1100 App did enter backgroundMessage from debugger: Terminated due to signal 9 First, I connected to the iPad device, then simulated the termination by Xcode (Relaunch the app from Xcode), after that you see the centralManager(_:, willRestoreState) delegate is triggered by the popup. Later, I simulated the termination by using the second method, when the home screen reappeared, one thing for sure that the app was terminated. Next, I pressed the “Send notify” button from the iPad (Which was playing as a Peripheral) to send a BLE event to the app. Surprisingly, the centralManager(_:, willRestoreState) was called immediately as we can see a local notification showed up, then another one showed the BLE data received from the peripheral (The “Say something cool!” string). It really worked! The app now can last forever! But wait a minute, it’s not so simple as so. This approach still has some limitations that we will discuss later on this post. As you may notice that there is a difference between the two ways I used to simulate background termination, when the app was relaunched from the first way, the option value of the delegate application(application:didFinishLaunchingWithOptions:) always nil, while we could extract the [UIApplicationLaunchOptionsKey.bluetoothCentrals by using the second way (The value of launchOptions?[UIApplicationLaunchOptionsKey.bluetoothCentrals] will return “YourUniqueIdentifierKey” string). I don’t know the reason why it happened. But one thing for sure that the second approach is better than the first one since it matches with the Apple doc. *”When your app is relaunched by system, you can retrieve all the restoration identifiers for the central manager objects the system was preserving for your app”.* So, in application(application:didFinishLaunchingWithOptions:), we’re able to get a list of UUID that represent all of the CBCentralManager objects that were active when application was terminated and that Core Bluetooth and iOS took over while you were terminated. Use UIApplicationLaunchOptionsBluetoothCentralsKey to get any central we may have instantiated before being zapped. Loop through the array of centralManagerUUID and find the one matched the Restoration Identifier we’re interested in. LimitationsWhen the user force kill the app from the multiple task viewIf the user force quit the app from the multiple task view, there is no chance so that the app can wake up from the restoration event. But luckily, there is another technology we can leverage to put the app back into the background named “iBeacon”. In the next post, I will guide you how to implement this interesting technology into our app. When the user reboots phoneIf the user resets the phone, the app will be killed forever. By leveraging the CoreLocation, we can solve the problem. In the next part, I will show you how to do that. Final thoughtsIn this post, we walked through the iOS app life cycle, also I showed you how to keep the app survive even it was terminated by the system. The contents of this post are really interesting and they are formed from my real working experiments.Hope you will find this post useful.","link":"/2018/07/23/Best-practice-How-to-deal-with-Bluetooth-Low-Energy-in-background/"},{"title":"Best practice: iOS background processing - Background App Refresh Task","text":"Unlike Android, iOS has restrictions for the use of background processing in an attempt of improving battery life and user experience. When your apps enter to background mode, it’s time developers get out of control of their app. How and when your app gets a chance to execute your task totally depends on the system. At the heart of iOS, Apple uses its own internally-complex algorithm to determines which apps are allowed to run in the background, based on various factors such as the pattern of user activity, current battery state, etc.In this tutorial, we will learn how to request periodic execution time on iOS. After understanding how it works, we will apply this technique to a BLE-based app in some specific cases in the next tutorial.Let’s rock! Foundational knowledgeBefore taking deep dive into practice, it’s good to understand how iOS manages application states. It’s been the first time Apple officially announces a video that describes top factors contributing to the app launch times at WWDC (WWDC 2020 - Background execution demystified). To summarize, Apple designs iOS in a way allowing applications to keep its content up to date on one hand. On the other hand, iOS must adapt to its major goals: Battery life: allowing background execution while maintaining all-day battery life. Performance: ensure background execution does not have any negative effect on active usage. Privacy: Users should be aware of background tasks based on their particular usage patterns. Respecting user intent: if a user takes a certain action, make sure the system responds to correctly. With these goals in mind, here are the top 7 factors that play a role in system scheduling of background execution. Critical low battery: When the phone is about to run out of battery (&lt; 20%), background execution will be pause by the system to avoid battery usage. Low power mode: When users change to phone to low power mode, the user explicitly indicates that the system should preserve battery for critical tasks only. Background App refresh setting: The user can toggle the setting to allow or not a specified app can run background tasks. App usage: There is a limit of resources on the phone so that the system must priorities which apps it should allocate resources for. Typically, apps that the user uses the most. Apple also mentioned to “On-device predictive engine” that learns which apps the user often uses and when. The on-device predictive engine will rely on this information to priorities background execution. App switcher: Only apps are visible in App Switcher have opportunities to run background tasks. System budget: Ensure background activities do not drain battery and data plans, there is a limit of battery and data of background execution throughout the day. Rate limit: The system performs sone rate-limiting per launch. and some other factors: Airplane mode, device temperature, display, device lock state, etc. CapabilitiesMake sure your app has added these following capabilities Prior to iOS 13It’s quite simple to set up a background fetch prior to iOS 13.Inside the application(_:didFinishLaunchingWithOptions) method, we should add the following command. 1UIApplication.shared.setMinimumBackgroundFetchInterval(UIApplication.backgroundFetchIntervalMinimum) The setMinimumBackgroundFetchInterval specifies the minimum amount of time that must elapse between background fetch executions. However, the exact timing of the event is up to the system. Generally, UIApplicationBackgroundFetchIntervalMinimum is a good default value to use. Once your app has a chance to perform background tasks, the event application(_:,performFetchWithCompletionHandler) will be triggered. 1234func application(_ application: UIApplication, performFetchWithCompletionHandler completionHandler: @escaping (UIBackgroundFetchResult) -&gt; Void) { Logger.shared.debug(\"\\(Date().toString()) perfom bg fetch\") completionHandler(.newData)} Don’t forget to call completionHandler callback. If you do not call this callback, the system does not aware your task has been completed, which leads to limiting your app from waking up on the next events To simulate background fetch, from the tab bar &gt; Debug &gt; Simulate background fetch. Note that it works only when running on real devices. iOS 13+, Advance Background processing - WWDC 2019 and Background execution demystified - WWDC 2020At WWDC 2019, Apple introduced a new framework for scheduling background work: BackgroundTasks. This new framework does better support for tasks that are needed to be done in the background. There are two kinds of tasks supported by BackgroundTasks framework: BGAppRefreshTaskRequest, and BGProcessingTaskRequest. With the presence of the new framework, Apple marked deprecated on the old one from iOS 13, and no longer support on MacOS.Firstly, we have to register the identifiers of background tasks executed in our app. Open info.plist file, and add the following information. 12345&lt;key&gt;BGTaskSchedulerPermittedIdentifiers&lt;/key&gt;&lt;array&gt; &lt;string&gt;YOUR_REFRESH_TASK_ID&lt;/string&gt; &lt;string&gt;YOUR_PROCESSING_TASK_ID&lt;/string&gt;&lt;/array&gt; Forget the above step leading to a crash at runtime. 12020-10-11 08:24:40.648838+0700 TestBgTask[275:5188] *** Terminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'No launch handler registered for task with identifier com.example.bgRefresh' BGAppRefreshTaskRequest is used when you need to execute a task in the background in a short time.Refresh tasks like fetching social media feed, new emails, latest stock prices, etc are appropriate to schedule by BGAppRefreshTaskRequest. 30s is the time the system allows your task to execute per launch. Several minutes of run times to finish your work when you register a BGProcessingTaskRequest. Tasks such as Core ML training on the device should be registered by a BGProcessingTaskRequest. To register background tasks, inside the application(_:didFinishLaunchingWithOptions) method, we should add the following command. 1234567891011121314151617181920212223242526272829303132333435363738394041424344 func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool { if #available(iOS 13, *) { BGTaskScheduler.shared.register(forTaskWithIdentifier: appRefreshTaskId, using: nil) { task in Logger.shared.info(\"[BGTASK] Perform bg fetch \\(appRefreshTaskId)\") task.setTaskCompleted(success: true) self.scheduleAppRefresh() } BGTaskScheduler.shared.register(forTaskWithIdentifier: appProcessingTaskId, using: nil) { task in Logger.shared.info(\"[BGTASK] Perform bg processing \\(appProcessingTaskId)\") task.setTaskCompleted(success: true) self.scheduleBackgroundProcessing() } } } @available(iOS 13.0, *) func scheduleAppRefresh() { let request = BGAppRefreshTaskRequest(identifier: \"YOUR_REFRESH_TASK_ID\") request.earliestBeginDate = Date(timeIntervalSinceNow: 5 * 60) // Refresh after 5 minutes. do { try BGTaskScheduler.shared.submit(request) } catch { print(\"Could not schedule app refresh task \\(error.localizedDescription)\") } } @available(iOS 13.0, *) func scheduleBackgroundProcessing() { let request = BGProcessingTaskRequest(identifier: appProcessingTaskId) request.requiresNetworkConnectivity = true // Need to true if your task need to network process. Defaults to false. request.requiresExternalPower = true // Need to true if your task requires a device connected to power source. Defaults to false. request.earliestBeginDate = Date(timeIntervalSinceNow: 5 * 60) // Process after 5 minutes. do { try BGTaskScheduler.shared.submit(request) } catch { print(\"Could not schedule image fetch: (error)\") } }} One more thing that needs to be done. When the app enters to the background, we will start scheduling background tasks. 1234567func applicationDidEnterBackground(_ application: UIApplication) { Logger.shared.info(\"App did enter background\") if #available(iOS 13, *) { self.scheduleAppRefresh() self.scheduleBackgroundProcessing() }} As always, It’s important to call task.setTaskCompleted(success: true) as quick as possible.You might notice that after calling task.setTaskCompleted(success: true), we need to call self.scheduleAppRefresh() and self.scheduleBackgroundProcessing() again to re-schedule these tasks to the system. Simulate background task and background processingFortunately, Apple supports a way to trigger background execution.After submitting your task to the system, pause the application by any break point. Then, enter the following command to the Xcode console. 1e -l objc -- (void)[[BGTaskScheduler sharedScheduler] _simulateLaunchForTaskWithIdentifier:@\"YOUR_REFRESH_TASK_ID || YOUR_PROCESSING_TASK_ID\"] The output should be 12345672020-10-11 08:53:58.628667+0700 TestBgTask[381:17115] 💚-2020-10-11 08:53:58.628 +0700 Start schedule app refresh(lldb) e -l objc -- (void)[[BGTaskScheduler sharedScheduler] _simulateLaunchForTaskWithIdentifier:@\"com.example.bgRefresh\"]2020-10-11 08:54:01.927263+0700 TestBgTask[381:16973] Simulating launch for task with identifier com.example.bgRefresh2020-10-11 08:54:03.669153+0700 TestBgTask[381:17095] Starting simulated task: &lt;decode: missing data&gt;2020-10-11 08:54:07.560697+0700 TestBgTask[381:17095] Marking simulated task complete: &lt;BGAppRefreshTask: com.example.bgRefresh&gt;2020-10-11 08:54:07.560750+0700 TestBgTask[381:17012] 💙-2020-10-11 08:54:06.045 +0700 [BGTASK] Perform bg fetch com.example.bgRefresh2020-10-11 08:54:07.563846+0700 TestBgTask[381:17012] 💚-2020-10-11 08:54:07.562 +0700 Start schedule app refresh Expectation vs RealityYou might expect that background execution would be evenly distributes through out the day. However, here is what we observe in reality. Because of the 7 factors I introduced at the beginning of this tutorial, the “On-device predictive engine” learns the user usage pattern and understands that the user typically opens the app in the morning, lunchtime, and in the evening. That’s why the system will allow your background tasks to launch just before the user foregrounds the app. Other factors that affect the result are if the user toggled “Low power mode”, or if the phone fell into the critical low battery state. Best advices Background tasks will not be run until the first device unlocks after the reboot. We can check if the user is in low power mode:12ProcessInfo.processInfo.isLowPowerModeEnabledNSProcessInfoPowerStateDidChange We also can check the “background refresh setting” status.12UIApplication.shared.backgroundRefreshStatusUIApplication.backgroundStatusDidChangeNotification Minimize data usage: Using thumbnails instead of full images, and only download what’s really necessary. Minimize power consumption: avoid unnecessary hardware usage such as GPS, accelerometer, etc. Also, make sure you complete the task as soon as possible. Use BackgroundURLSession to offload the work from the app to the system. SummaryIn this post, we take a deep dive into what factors contributed to your background executions, and understand are key differences between BGAppRefreshTaskRequest and BGProcessingTaskRequest. We also take a demo project to see how it actually works in reality.Next time, you can choose what kind of request is most appropriate to your tasks, and how you can respond gracefully to your user’s intent.Hopefully, the information that this post brings in helps you build better applications: freshness and optimization.There is another technique to wake your app up, silent notification. We will talk about it in the next tutorial.Happy weekend! References Background execution demystified WWDC 2020 Advances in App Background Execution WWDC 2019","link":"/2020/09/26/Best-practice-iOS-background-processing-Background-App-Refresh-Task/"},{"title":"Beta Test and TestFlight","text":"As an iOS developer, you might have heard about TestFlight - a product of Apple that allows you to distribute your apps to beta users. So what can we do with it? Is it useful?In this tutorial, we will walk through steps uploading a build to TestFlight, and invite users to test your app.You also need to refer the previous post Shipping your app to Store to complete this tutorial.Let’s have fun! What is TestFlight?TestFlight is a product of Apple that allows developers to distribute their apps to beta users before rolling to production. With the latest update of TestFlight app on iOS 13, testers can give feedback directly from the app with screenshots, crashes and other useful information provided. Using TestFlight is a great way to help to test your apps and improve the performance before it goes live.TestFlight provides two types of testers: Internal Tester: It takes up to 25 members of your team who have been assigned a specified role to test your app. Each member can test on up to 30 devices. Once a beta build is submitted to App Store Connect and is available for testing, internal testers will be notified so that they can update the app. External Tester: You can invite up to 10,000 testers using just their email address or by sharing a public link. The main difference from the two is to let External Tester test your app, you must submit your app to Apple for review. The reviewing process is the same as an official submission but it’s usually going faster than normal app reviews. By contract, testing your app with internal testers does not require review by Apple. Select build for testingAfter completing the final step at Shipping your app to Store, your app is successfully submitted to App Store Connect. Now, navigate to your Apple developer page and sign in with your Apple Id, then select “My Apps” to see all available apps &gt; Select a specified app &gt; From the top toolbar &gt; Select TestFlight &gt; You will see all builds that are available for testing.The following image gives you a quick look of TestFlight dashboard From the main window, you can see all available versions of your app; when it expires; how many invitations sent; how many installations succeeded. etc.To add new users, click on “App Store Connect Users” at the left sidebar &gt; Press “+” button &gt; Then fill in your tester information including there App Id. After that, you can add your tester to your build. TestFlight AppTesters need install TestFlight app on their device. This app is free and available on App Store. After adding your testers to the build, testers will use their invitation email or a public link to enroll in the testing.Open the TestFlight app, the tester needs to sign in with their App Id. After that, they will see all available apps that they can install which just be the same as App Store. A small note that you will see a small orange dot near the name of the app to indicate this build installing from TestFlight. Easy, huh? From now on, whenever a build of this app is available, your tester will receive a notification and an email from TestFlight. They then can update this app via TestFlight and enjoy the latest version. After testingWhen you are done testing, you can stop the app from testing, and then go to publishing an app for the process of submitting your app to the App Store. Your beta build will become unavailable in TestFlight after 90 days by default.In this post, we had a quick look at TestFlight and how to distribute your beta test to your testers. In practice, beta testing is a common term in the software development process. Having knowledge of how to distribute your app will be useful in some situations.Happy coding!!!","link":"/2020/04/14/Beta-Test-and-TestFlight/"},{"title":"Bluetooth Integration with App Clips: A How-To Guide","text":"Nowadays, users demand quick and easy access to services they need, without downloading the full version of an app. App Clips - a feature introduced by Apple on iOS 14 - offers a solution to this demand by enabling users to access a small part of an app. By integrating your Bluetooth-enabled app to App clip, you can take user experience to the next level. This opens up new possibilities, such as allowing users to connect to nearby devices, perform a specific feature, and more. In this tutorial, I’ll guide you through integrating Bluetooth into your App Clip. Whether you’re a seasoned developer or a newbie, you will find everything you need to get started. So, let’s dive in! App Clips“An App Clip is a small part of your app that’s discoverable at the moment it’s needed and lets people complete a quick task from your app — even before installing your full app.”. App Clips are designed to be lightweight and fast, providing quick access to your app’s core features and services.There are many benefits of using App Clips. Firstly, it offers a lightweight part of your app for users to try out an app’s feature without committing to a full download. Secondly, Appclips can be launched through various channels such as NFS tags, QR codes, links from Safari, or Messages.Here are some use cases and example apps using AppClips: Ticketing: AppClip can be used to quickly purchase and access tickets for events such as concerts, movies, or sporting events. Ride-requesting: AppClip can be used to easily make a request for a ride service. E.g Lyft. Retail: App Clips can be used to quickly access product information, make a purchase, or redeem a coupon at a retail store Food ordering: users can quickly access the restaurant’s menu and place an order. E.g: Panera Bread. Parking: Users can simply scan a QR code or tap an NFS tag to launch the Appclipa and pay for their parking spot. Please be aware that an Apple paid account is required in order to develop an AppClip. ConfigurationOpen a hostingBefore launching the App Clip, the system ensures that the App Clip includes its code signature on your website. If you have your own website you can add the following lines to your Apple App Site Association (AASA) on your server and go to the next step. 1234567{ &quot;appclips&quot;: { &quot;apps&quot;: [ &quot;[YOUR_TEAM_ID].[YOUR_APP_CLIP_BUNDLE_ID]&quot; ] }} Firebase Hosting can be a great option for those who don’t have their own server. With Firebase Hosting, you can easily configure your site without any cost as it provides a free tier for hosting. Install the Firebase command-line tool via the following command sudo npm install -g firebase-tools Next, log in to your Firebase account firebase login After successfully logging in, navigate to the directory that contains the file you want to upload, and then run firebase init to select the hosting option. Add the following lines to firebase.json file. 1234567891011121314...&quot;headers&quot;: [ { &quot;source&quot;: &quot;/.well-known/apple-app-site-association&quot;, &quot;headers&quot;: [ { &quot;key&quot;: &quot;Content-Type&quot;, &quot;value&quot;: &quot;application/json&quot; } ] }],&quot;appAssociation&quot;: &quot;NONE&quot;,... Next, create public/.well-known/apple-app-site-association file. 1234567{ &quot;appclips&quot;: { &quot;apps&quot;: [ &quot;[YOUR_TEAM_ID].[YOUR_APP_CLIP_BUNDLE_ID]&quot; ] }} Finally, upload files to firebase firebase deploy Once the deployment is successful, you will be provided with the URL for your website. This URL will be used to configure the launch of your AppClip. Add Appclip targetFirst, open your Xcode project and navigate to the File menu. From there, select New and then Target. This will bring up a dialog box that allows you to choose the type of target that you want to create. Next, select the option for App Clip and click Next. This will take you to a screen where you can configure various settings for your App Clip, such as its name, identifier, and deployment target. Once you have configured these settings, click Finish to create the new App Clip target. This will add the necessary files and resources to your project and allow you to start developing your App Clip. To configure your AppClip to launch properly, you will need to follow a few simple steps.First, select your AppClip target from Xcode, then navigate to Signing &amp; Capabilities and select Associated Domains. From there, you can add your hosting URL to the list of domains that your AppClip is associated with. For example, let’s say that your hosting URL is awesomeapp-54431.web.app. In this case, you would add appclips:awesomeapp-54431.web.app to the list of domains. Once you have completed these steps, everything should be set up properly and you can begin implementing your AppClip functions. This may involve writing code to interact with various APIs, designing user interfaces, and more. The exact details will depend on the specific requirements of your AppClip and the features that you want to include. ImplementationI will develop a very simple application that allows to scan nearby Bluetooth devices and display them on a list when launching the Appclip to demonstrate how to utilize Bluetooth in Appclip. You may modify the application to fit your needs, such as automatically identifying a pre-selected device by address and automatically connecting to the device to execute a specific task. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950struct ContentView: View { // The rest are omitted ... var body: some View { NavigationView { VStack { Image(\"logo\").resizable() .scaledToFit() .frame(width: 120).padding(.top, 10) TitleLargeText(\"Awesome App\").padding(.bottom, 5).padding(.top, 10).padding(.bottom, 10) Spacer() LabelLargeText(\"Nearby Devices\").frame(maxWidth: .infinity, alignment: .leading).padding(.horizontal, 20) List(devices.map { $0.name ?? \"Unknown name\" }, id: \\.self) { deviceName in LabelMediumText(deviceName) } VStack { HStack { LabelMediumText(\"Powered By\") Link(destination: URL(string: \"https://uynguyen.github.io\")!, label: { LabelMediumText(\"Uy Nguyen\", underline: true) }) }.padding(.top, 5) } } .frame(maxWidth: .infinity, maxHeight: .infinity, alignment: .top) .background(Color.black).onContinueUserActivity(NSUserActivityTypeBrowsingWeb, perform: handleUserActivity) .navigationBarTitle(\"\") .navigationBarHidden(true) } } func handleUserActivity(_ userActivity: NSUserActivity) { // You can extract params from the url, validate if the url is valid, etc. guard let incomingURL = userActivity.webpageURL, let components = URLComponents(url: incomingURL, resolvingAgainstBaseURL: true), let queryItems = components.queryItems else { return } // Everything is ok, let's start scanning BluetoothManager.shared.config { device, rssi in if !(devices.contains(where: { $0.identifier.uuidString == device.identifier.uuidString })) { devices.append(device) } } } ...} TestingQR code &amp; NFCApple supports testing your Appclip without having to publish it by registering a Local Experience.To register local experience, go to phone Settings and select Developer. From there, you can access the Local Experiences menu and click on Register Local Experience.Once you have entered your URL prefix and Bundle ID, you will be able to start filling in the information for your App Clip Card. This is the section that will display to users when they click on the URL or scan the QR code associated with your App Clip.In the App Clip Card section, you will be able to provide users with important information about your App Clip, including its name, banner, and description. This information should be clear and concise so that users can quickly understand what your App Clip does and how it can be useful to them.In addition to this, you will also need to select the type of button that you want to use for your App Clip. There are three different types of buttons available: Open, View, and Play.The Open button is used to launch the App Clip and take users directly to its main interface.The View button is used to display specific content within the App Clip, such as a particular page or feature.Finally, the Play button is used to launch a media player within the App Clip, allowing users to listen to music or watch videos.By following these simple steps and providing users with a clear and engaging App Clip Card, you can help to ensure that your App Clip is successful and well-received by your target audience. In the video below, you can see a demonstration of how scanning the QR code associated with my website, automatically launch the App Clip and initiate the Bluetooth scanning process for nearby devices. This is a simple example of how App Clips can offer a convenient user experience that eliminates the need for users to navigate through multiple screens or download the full app. Notes: If you find that you no longer need an App Clip that you have previously installed on your iOS device, you can easily remove it by following a few simple steps. Simply go to your Settings and select the App Clips option. From there, you can select the App Clip that you want to remove and click on the option to delete it. If you are experiencing issues with your App Clip and it is failing to launch despite being configured correctly, The first things that you should try is invalidating the cache and re-registering your local experiences. This can be done by going to your Settings and selecting the Developer option. From there, you can access the Local Experiences menu and click on the option to Invalidate Cache. Once you have done this, you can then re-register your local experiences and try launching your App Clip again. Safari &amp; iMessageIn addition to launching App Clips via QR codes, Apple also offers support for launching your App Clip when a user shares a link to your website through the Messages app, or views the URL on Safari directly. The recipient can tap the link to instantly launch your App Clip to access your App Clip’s functionality quickly and easily. It’s important to note that Safari’s Smart App Banner and sharing via Messages are only available when the App Clip is published in the App Store. App Clip banner on Safari: requires the user’s device runs iOS 15+. App Clip banner on iMessage: requires the user’s device runs iOS 14+, and contains the sender as a contact in the Contacts app. To enable showing Appclip card in Safari and iMessage, config the following lines on your website. 1234&lt;meta name=&quot;apple-itunes-app&quot; content=&quot;app-id=YOUR_APP_ID, app-clip-bundle-id=YOUR_APP_CLIP_ID, app-clip-display=card&quot; /&gt;&lt;meta property=&quot;og:image&quot; content=&quot;BANNER_URL&quot; /&gt;&lt;meta property=&quot;og:title&quot; content=&quot;Awesome App&quot; /&gt;&lt;meta property=&quot;og:description&quot; content=&quot;Awesome App description&quot; /&gt; Best practice Keep it simple: The purpose of an App Clip is to provide a simplified version of your app’s functionality. Focus on providing only the key features that users are most likely to need in the context where they are using the App Clip. Optimize for speed: App Clips should be lightweight and fast-loading (Apple requires the size of Appclip must be less than 15MB, this is to ensure that App Clips can be quickly downloaded and launched, even on slower network connections.) to ensure that users can quickly access the functionality they need. Minimize the amount of content and assets that are loaded to ensure that the App Clip loads quickly and doesn’t consume too much data. It’s important to keep the number of parameters to a minimum and make sure they’re easy to understand. The more complex the parameters, the more difficult it will be for users to know how to use them. Limit the length of parameters: It’s best to limit the length of parameters to no more than 50 characters. This will help to ensure that users can easily read and understand the parameters. Validate parameters: Make sure that your App Clip validates all parameters that are passed to it. This will help to ensure that your App Clip functions properly and that users are not able to exploit any vulnerabilities. In addition to scanning QR codes, displaying on Safari, and sharing via iMessage, Apple offers several other methods to launch App Clips, such as tapping a link in the Maps app, location-based suggestions from Siri Suggestions, and NFC tags. To ensure that users can easily discover your App Clip, it is important to leverage the appropriate launch method and optimize for discoverability. By doing so, you can increase the chances of users finding and engaging with your App Clip. Next stepIn the upcoming tutorial, I will provide you with detailed instructions on how to publish your App Clip and configure it to run on Safari, Maps, and iMessage. However, please note that App Clips can only be launched when they are published in the App Store. Therefore, I cannot demonstrate the process until my App Clip passes Apple’s review process. 😝 ConclusionIn conclusion, App Clips offer a great opportunity to enhance user experience and simplify the app interaction process. With App Clips, users can quickly access a specified feature without the need to download the full application. This can be particularly useful for users who want to try out your app or have limited data plans or storage. Whether you are a restaurant owner, retail store manager, or any other type of business, you can leverage App Clip to create a better overall experience for your users.So what are you waiting for? Give App Clips a try and see the difference they can make for your app and your business. Refs https://developer.apple.com/app-clips/","link":"/2023/03/25/Bluetooth-Integration-with-App-Clips-A-How-To-Guide/"},{"title":"Big Endian vs Little Endian","text":"In computer science, a bit is the smallest piece of information. It represents a digit of the binary numeral system. A string of 8 bits called a byte. There are two ways to store a string of data in computers: Big Endian and Little Endian. If your tasks are working with data in a piece of bytes, you ought to know how to deal with bytes in these two formats. In this post, I will explain how data is stored in computers, what are the main differences between these two, then provide some useful code to work with bytes in Swift and Objective-C. Basic conceptsTo understand Big Endian and Little Endian, you need to know what the Least Significant Byte (LSB) and the Most Significant Byte (MSB) are. The LSB is the right-most bit in a string, it is called that because it has the least effect on the value of the binary number. In contrast, the left-most byte is the MSB that carries the greatest numerical value.After understanding these two, it is easy to distinguish between Big Endian and Little Endian: In Big Endian, the MSB of the data is placed at the byte with the lowest address. In Little Endian, the LSB of the data is placed at the byte with the lowest address. That’s all! The advantages of Big Endian and Little Endian in a computer architectureAccording to Wiki, Big endian is “the most common format in data networking”, many network protocols like TCP, UPD, IPv4 and IPv6 are using Big endian order to transmit data. Little endian is mainly using on microprocessors. But the point is why do they do that?Well, when working with byte order on iOS, I also ask the question to myself and my colleagues, “why do they do that?”, “Why do they choose Big Endian instead of Little Endian?”. After researching on the internet, and getting answers from a senior firmware engineer in my office, I gradually understand the up-side of these both order ways.The advantages of Little Endian are: It’s easy to read the value in a variety of type sizes. For example, the variable A = 0x13 in 64-bit value in memory at the address B will be 1300 0000 0000 0000. A will always be read as 19 regardless of using 8, 16, 32, 64-bit reads. By contrast, in Big Endian we have to know in which size we have written the value to read it correctly. It’s easy to cast the value to a smaller type like from int16_t to int8_t since int8_t is the byte at the beginning of int16_t. Easily to do mathematical computations “because of the 1:1 relationship between address offset and byte number (offset 0 is byte 0), multiple precision math routines are correspondingly easy to write.” Some main advantages of Big Endian are We can always test whether the number is positive or negative by looking at the byte at offset zero, so it’s easy to do a comparison. The numbers are also stored in the order in which they are printed out, so binary to decimal routines are particularly efficient. Byte order on iOSBoth Swift and Objective-C support methods that help us read and write data in the two ways Litte Endian and Big Endian. The following sections demonstrate how we use these methods to interact with data on memory. Byte order in Objective-C1234567891011121314NSString *strData = @\"001E653A\";NSData *data = [NSData dataWithHexString:strData];uint8_t *bytes = (uint8_t *)data.bytes;/* Functions for loading little endian to host endianess. */uint16_t firstInLittle = OSReadLittleInt16(bytes, 0); // 0x1E00 = 7680uint16_t secondInLittle = OSReadLittleInt16(bytes, 2); // 0x3A65 = 14949uint16_t firstInBig = OSReadBigInt16(bytes, 0); // 0x001E = 30uint16_t secondInBig = OSReadBigInt16(bytes, 2); // 0x653A = 25914 /* Functions for storing host endianess to little endian. */uint8_t byte16[2];OSWriteLittleInt16(byte16, 0, firstInLittle); // byte16 = [0x00, 0x1E] Byte order in Swift123456789101112let strData = \"3A651E00\"if let data = strData.hexadecimal() { let bytesArr = [UInt8](data) /* Functions for loading native endian values. */ let little = _OSReadInt16(bytesArr, 0) // 0x653A = 25914 let big = first.bigEndian // 0x3A65 = 14949 /* Functions for storing native endian values. */ let bytes = [UInt8](repeating: 0, count: 2) _OSWriteInt16(UnsafeMutableRawPointer(mutating:bytes), 0, second) // bytes = [0x65, 0x3A]} Final thoughtsIn this post, I showed you how differences between endianness formats and provided some useful code to work with bytes in iOS. If you have any suggestions, just let me know.Happy weekend.","link":"/2018/04/30/Big-Endian-vs-Little-Endian/"},{"title":"Building your personal page with Hexo","text":"As I build this personal site, my first aim is to enjoy my hobby of writing. I write whatever I learn on along with my daily working, and share it. I hope my share will help someone when they need it. In return, I will have a deep of understanding what I write, and sometimes, receive “a cup of coffee” (Buy me Coffee) from a friend I’ve never met. ☺️ Power is gained by sharing knowledge, not hoarding it Some friends come to me asking how to build a page like mine. I’m happy to share with you how I build it.After this tutorial, you can build your own site within 5 minutes.I hope to see your page launching soon! Set up toolsNodeJs for macNavigate to NodeJS page, download, and install NodeJs package for macOS.For those who don’t know what NodeJs is, NodeJs is an open-source, cross-platform (OS X, Window, Linux), Js runtime environment for writing service-side in Javascript.By using the non-blocking I/O model, NodeJS is a great choice for real-time applications, chat, data streaming, etc.With a large community, NodeJs package ecosystem is more and more various and efficiency making NodeJS become one of the best development trends in recent years. You can find more info of NodeJs on the internet if you find it interesting. HexoHexo is a blog framework powered by NodeJs. Simple and fast features of Hexo make it become a dominate among other blog frameworks such as Hugo, Wordpress, Grav, etc.I choose Hexo to build my blog because I get used to with NodeJS commands. Moreover, Hexo provides many themes that you can easily integrate to your blog with a full of customization.After installing NodeJs successfully, open your terminal and type these following lines 12345npm install hexo-cli -g [1]hexo init blog [2]cd blog [3]npm install [4]hexo server [5] Here is the step-by-step: Install hexo command line as a global command. Create your blog folder. Move to the folder. Install node dependencies. Run your server. Hexo will be run at localhost:4000 by default. Now open http://localhost:4000 in your browser to see the result. Personalize your websiteAt the root of your folder, there is a _config.yml file that contains your page configs. You can modify something like page title, page author, article format, etc. For more information, please refer to Hexo documents. Start writingTo create new artical, type 1hexo new \"My first blog\" Here, you create a post named “My first blog”. Reload your browser, you will see the result. Please note that Hexo uses Markdown syntax for editing, so please make sure you’re familiar with Markdown syntax. ThemesThe community of Hexo provides a lot of themes that you can choose by your favorite and personalize this theme as yours. It saves your time a lot thank to the great community.Navigate to Hexo themes and find the one you like, follow their instruction to download to your blog folder.Next, modify the _config.yml file, search and replace the themes config with your new theme name. 1theme: whatever DeploymentBy using the command line hexo generate, Hexo will automatically generate all your static files which you can upload to your server and distribute it to your users.In case you don’t own a server, no worry! There are a lot of free-host servers out there. You might have heard about Github page. Basically, Github page provides a free host and domain for your page, like mine “uynguyen.github.io”. If you want to use Github page as your host, please follow the instructions to create your github page repository.After having your own repository, install npm install hexo-deployer-git that allows you to deploy your site.Next, edit the _config.yml file, from the “deploy” section &gt; add your deployment target information 12345deploy: type: git repo: &lt;repository url&gt; branch: [branch] message: [message] From now on, once you finish writing, you can publish your posts via command 1hexo clean &amp;&amp; hexo deploy You can also use Heroku for deployment instead of using github. For more information, please refer to Hexo deployment ConclusionIf you want a simple - personal page to share your ideas and contents, Hexo and Github page become such a great tool for you. With its simplicity and its community, It’s easy to set up, allowing you to just focus on what matters: Your sharing.I hope you find this post useful.","link":"/2020/04/27/Building-your-personal-page-with-Hexo/"},{"title":"Chuyện ở Đại Học (Phần 1)","text":"Tối hôm qua vô tình lướt Facebook thì trang Confession của trường mình hiện lên bài post của một bạn k17, bạn tâm sự về chuyện học ở Đại Học.Bạn tâm sự rằng bạn đang stress và căng thẳng vì lượng kiến thức ở Đại Học quá nhiều làm bạn không theo kịp, trong khi đó các bạn cùng khoá lại có vẻ như tiếp thu nhanh hơn bạn. Điều đó làm bạn thêm tự ti và muốn bỏ cuộc.Trước giờ mình không có thói quen comment lên các Fan page hay Confession, mà vì đọc được bài post của bạn mình thấy sao giống với mình 5 năm về trước quá, vì vậy mình muốn viết một bài chia sẻ ngắn để chia sẻ với các bạn về con đường mình đã đi qua cách đây 5 năm, cũng là con đường mà các bạn sẽ đi, dù ít hay nhiều. 1. “Học Công Nghệ Thông Tin mà Visual Basic là cái gì mà cũng không biết thì nghỉ cha cho rồi!”Đó là câu trả lời của thằng bạn học Quốc Phòng với mình khi mình hỏi quyển sách dày cui nó cầm trên tay là sách gì. Lúc đó buồn lắm chứ, cảm giác như mình là sinh vật ngoài hành tinh khác rớt xuống chỗ này vậy.Sau đó vào kí túc xá, (Lúc này gặp thím Trương - Thằng này giỏi từ cấp 3, thi Tin trường quận huyện tỉnh gì đó nó thi hết rồi), nó hỏi mình chứ “Ông biết con trỏ hem, ông biết đệ quy hem, ông biết thuật toán Dijktra, chu trình Hamilton hem” (WTH !!!). Chả hiểu nó nói gì, mình chỉ biết nhe răng cười. :))Vào lớp học, (Lúc này gặp thím Tú), mình còn đang loay hoay debug cái Hello World thì thím Tú đã bay lên bảng code một cách thần thánh: i++, j++ (WTF !!!).“Ê mày, i++ là sao mày” - Uy said =]].Đó, background lập trình của mình là vậy đó :). Rồi mình cũng lê lết qua được 4 năm Đại Học đấy thôi, nên tin vui cho các bạn là dù biết hay không biết nên tảng lập trình, vào Đại Học thì mọi người sẽ cùng một điểm xuất phát lại hết nhé, chỉ là mấy bạn biết trước sẽ có nhiều lợi thế hơn thôi. Mà cũng phải thôi, tại những năm cấp 3 người ta đã bớt thời gian đi chơi, xem phim, la cà để chuyên tâm nghiên cứu rồi còn gì.Mình có một người bạn từng nói là mình giống như mục tiêu của nó vậy đó, nó sẽ cố gắn phấn đấu cho đến khi qua được mặt mình, để xem thử ai là người đạt được ước mơ của mình sớm hơn. Mình trả lời lại là *”Mình không lấy người khác ra để làm mục tiêu cho mình, mình có những mục tiêu riêng. Mặt khác, mỗi người sinh ra đã có những xuất phát điểm, những nỗ lực khác nhau rồi, tôi không biết con đường bạn đã đi như thế nào và bạn cũng vậy. Vậy sao lại so sánh được?”* 2. Những kiến thức nền ở Đại HọcSau đây là list những môn học đại cương trong 3 kì đầu. Toán đại cương: Toán rời rạc: Các bạn sẽ học về Vector, các phép toán trên Vector, đại số Bool, các bảng chân trị, bảng logic, khái niệm cơ bản về đồ thị … Xác suất thống kê: Các bạn sẽ được học về các phép toán tính xác suất, các phép đếm, thống kê … Đại Số B1, B2: Học về cách phép toán xử lý trên ma trận, định thức, không gian vector … Giải tích B1, B2: Học về vi phân, tích phân, đạo hàm … Những môn này cực kì quan trọng cho những môn khoa học máy tính sau này nên tập trung học cho chắc nhé. Toán rời rạc quan trọng nếu sau này bạn chuyên về thuật toán, giải thuật, lý thuyết đồ thị, automata, trình biên dịch, xử lý ngôn ngữ tự nhiên. Xác suất thống kê cần nếu bạn làm nhiều về trí tuệ nhân tạo, \bData Science, Machine Learning. Đại số tuyến tính ma trận, vector etc. có ứng dụng trong Cryptography, phân tích độ phức tạp thuật toán. Tin học đại cương: Điện Tử Căn Bản: Môn này học cái gì mình quên rồi, và cũng không biết tại sao mình lại qua môn. Lý Thuyết Mạch Số: Môn này học về các cổng logic AND, OR, XOR, NOT. Các hệ cơ số đếm, các phép toán xử lý trên bit bla bla. Nhập Môn Lập Trình: Môn này nhẹ nhàng thôi, học về mấy cái cực cơ bản như viết “Hế lô bà con”, học các syntax cơ bản: lặp, điều khiển, rẽ nhánh … Lý Thuyết Đồ Thị: Môn này là môn mình thích nhất trong 4 năm Đại Học vì được học với Cô Vân dễ thương. Các bạn sẽ được học về các phép duyệt đồ thị (BFS, DFS), các thuật toán tìm đường đi ngắn nhất (Dijkstra, Floyd + Bellman), các khái niệm về đồ thị (Liên thông, đẳng cấu bla bla), chu trình Euler và Hamilton … Bạn nên đọc thêm quyển: Introduction To Algorithm [THOMAS H. CORMEN, CHARLES E. LEISERSON, RONALD L. RIVEST, CLIFFORD STEIN] Nhập Môn Công Nghệ Thông Tin 1,2: Hai môn này chủ yếu “Cưỡi ngựa xem hoa” cho vui thôi, sẽ giới thiệu cho các bạn về ngành Công Nghệ Thông Tin, các chuyên ngành và các hướng nghiên cứu. Hai môn này nhẹ nhàng, đừng tạo áp lực làm gì. Cơ Sở Dữ Liệu: Học về các khái niệm cơ bản trong hệ thống thôn tin và cơ sở dữ liệu, các hệ thống CSDL và mô hình dữ liệu quan hệ, sử dụng SQL để truy vấn cơ sở dữ liệu, thiết kế cơ sở dữ liệu, phân tích chất lượng của một lược đồ cơ sở dữ liệu. Kiến Trúc Máy Tính và Hợp Ngữ: Học về các cách thiết kế kiến trúc của máy tính, tổng quan về máy tính, kiến trúc MIPS, x86, x32, cách thiết kế CPU của máy tính, các hệ cơ số và cách lưu trữ trên máy tính … Bạn nên tìm đọc thêm quyển Computer Architecture: A Quantitative Approach [John L.Hennessy and David A.Patterson] Hệ Điều Hành: Môn này quan trọng, các bạn cần học thật tốt môn này. Môn này các bạn sẽ được học về cách hệ điều hành làm việc, học về Kernel của OS, hệ thống tập tin FAT32 và FAT64, cách mà OS quản lý và điều phối các tiến trình, đồng bộ hoá giữa các tiến trình, quản lý bộ nhớ trên OS … Bạn nên tìm đọc thêm quyển Operating System Concepts [Silberschatz, Galvin, Gagne]. Mạng Máy Tính: Môn này quan trọng, nên đầu tư nhiều thời gian tìm hiểu. Môn này các bạn học về mạng máy tính, cách mà các hệ thống máy tính làm việc với nhau, cách một gói tin được truyền đi trong hệ thống mạng, các khái niệm về mạng máy tính (IP, subnet mark, …), mô hình 7 tầng OSI, sau đó học vào chi tiết từng tầng trong mô hình mạng. Bạn nên tìm đọc thêm quyển Computer Networking: A Top-Down Approach [7th Edition, Kurose &amp; Ross] Lập Trình Hướng Đối Tượng: Môn này các bạn bắt buộc phải nắm vững, học tốt môn này thì bạn có thể học nhanh bất kì ngôn ngữ lập trình nào. Và nên nhớ, sau cùng thì ngôn ngữ cũng chỉ là cái để hiện thực hoá cái ý tưởng của mình thôi. Không nên đặt nặng vấn đề ngôn ngữ lập trình lên hàng đầu mà bỏ qua cơ sở để xây dựng ngôn ngữ đó. Bạn nên tìm đọc thêm Head First Design Pattern [Head First],Design Patterns [Gang Of Four] Kỹ Thuật Lập Trình: Môn này sẽ dạy bạn các khái niệm trong lập trình (Con trỏ, vùng nhớ, ma trận, stack, heap …) và các chiêu thức lập trình rất hay (Quy hoạch động (Dynamic Programming), quay lui (Backtracking), mà cái mình thích nhất là vét cạn (Greedy)) Ahihi. Cấu Trúc Dữ liệu &amp; Giải Thuật: Môn này sẽ dạy bạn các loại cấu trúc dữ liệu trong lập trình (Tree, Stack, Heap, Queue …). Cách sử dụng từng loại dữ liệu trong từng trường hợp cụ thế. Đồng thời còn dạy bạn các giải thuật cơ bản (Sort, Search …), đánh giá độ phức tạp giữa các giải thuật. Khi nào dùng cái này, khi nào dùng cái kia, cái nào tốt hơn, phải đánh đổi cái gì bla bla. Để học tốt môn này thì ngoài giáo trình trên trường, mình nghĩ các bạn nên đọc thêm quyển Introduction To Algorithm [Steven S.Skiena] hoặc Introduction To Algorithm [THOMAS H. CORMEN, CHARLES E. LEISERSON, RONALD L. RIVEST, CLIFFORD STEIN] để tăng nội công. Ngoài ra để trở thành một lập trình viên có tâm, code ít bug, người khác đọc code của bạn không bị ức chế thì nên đọc thêm những quyển sau: Clean Code [Robert C.Martin], Code Complete [Steve McConnell], Refactoring [Martin Fowler, Steve McConnell], Pragmatic Programmer [Andrew Hunt, David Thomas]. 3. Việc chọn chuyên ngành:Sau 3 học kì đầu các bạn sẽ được chọn chuyên ngành phù hợp với nguyện vọng của mình.Các bạn sẽ ĐƯỢC CHỌN chuyên ngành chứ không bị ép buộc hay sợ hết slot gì hết nhé, vì có một số bạn inbox hỏi mình chỗ này nên nhân đây mình nói luôn.Khoa mình hiện có 6 chuyên ngành: Công Nghệ Phần Mềm (Software Engineering): Học về quy trình phát triển phần mềm; Học về cách phân tích yêu cầu phần mềm, thiết kế phần mềm, hiện thực hoá phần mềm và kiểm thử phần mềm. Hệ Thống Thông Tin (Information System): Học cách phát triển, xây dựng các hệ thống thông tin phức tạp, thông minh, tối ưu; Nghiên cứu bảo mật thông tin, rút trích thông tin đa ngôn ngữ. Mạng Máy Tính và Viễn Thông (Computer Networks and Telecommunication): Phát triển các ứng dụng mạng, hệ điều hành cho các thiết bị mạng, phát triển hệ thống. Khoa Học Máy Tính (Computer Science): Khai thác dữ liệu, phân tích và thiết kế thuật toán để tối ưu bài toán, phát triển các hệ thống trí tuệ nhân tạo (AI)… Công Nghệ Tri Thức (Knowledge Engineering): Nghiên cứu về xử lý ngôn ngữ tự nhiên (Giọng nói á) hoặc đa phương tiện (File âm thanh); nghiên cứu về mật mã và an ninh thông tin. Thị Giác Máy Tính và Khoa Học Robot (Computer Vision and Robotics): Tích hợp kỹ thuật trong đồ hoạ máy tính và xử lý ảnh số vào thiết bị di động và robot. Hỗ trợ phát hiện, nhận dạng, truy vấn, tái tạo các đối tượng trong các môi trường khác nhau. Đến giai đoạn này thì các bạn sẽ tự đăng kí môn học cho phù hợp với chuyên ngành của mình. Ví dụ bạn chọn chuyên ngành “Công Nghệ Phần Mềm” thì bạn phải tích luỹ đủ N tín chỉ thuộc các môn phần mềm và phải hoàn thành N môn học bắt buộc trong công nghệ phần mềm.Một lời khuyên cho các bạn là không nên chỉ chọn học những môn trong phạm vi chuyên ngành của mình, nên chọn học thêm những môn học ở những chuyên ngành khác mà nó hay, nó bổ ích, nó hỗ trợ cho chuyên ngành chính của mình. Ví dụ như bạn chọn Công nghệ Phần mềm thì có thể học thêm các môn khác của Khoa Học Máy Tính như “Phân Tích Độ Phức Tạp Thuận Toán”, “Phân Tích và Thiết Kế Giải Thuật” hay “Chuyên Đề Hệ Điều Hành Linux” hay “Bảo Mật Cơ Sở Dữ Liệu” hay “Khai Thác Dữ Liêu và Ứng Dụng” hay “Máy Học” … Chung quy lại là phải biết lựa môn mà học.Để tìm hiểu thêm về các chuyên ngành, các bạn tham khảo tại đây Chuyên ngành CNTT 4. Điểm số có thực sự quan trọng?*”Xuỳ, học là học kiến thức thôi chứ điểm thì có quan trọng gì.”*Mình nói thẳng luôn là câu này chỉ là câu nguỵ biện của mấy bạn lười làm bài thôi, nếu các bạn làm bài đầy đủ thì điểm của các bạn cũng sẽ xứng đáng với những gì bạn bỏ ra thôi.Quay lại vấn đề, điểm số ở Đại Học có thật sự quan trọng? Quan điểm của mình là nó không quá quan trọng, nhưng cũng không phải là thứ có thể phớt lờ.Điểm số, trong Đại Học, một mặt là để bạn khỏi bị đóng tiền học ngu rớt môn, mặt khác nó lại có ý nghĩa quan trọng hơn đối với những bạn cần học bổng để chi trả học phí hay sinh hoạt hàng tháng. Xa xôi hơn là để sau này các bạn có thể Apply các học bổng du học nước ngoài.Điểm số, ngoài Đại Học, là cái mà nhà tuyển dụng sẽ nhìn vào đầu tiên (Đối với người mới ra trường) để xem xét xem bạn có qua được vòng gởi xe không. Thử đặt mình vào vị trí nhà tuyển dụng, bạn mới ra trường, họ không biết gì về bạn, họ lấy gì để đánh giá năng lực và con người bạn? Mình không biết thật sự các nhà tuyển dụng sẽ đánh giá như thế nào, nhưng mình nghĩ điểm GPA sẽ phần nào nói lên con người bạn, rằng bạn có phải là một người có trách nhiệm (Với việc học) của mình không? Rằng bạn có đủ điều kiện để tới vòng test kỹ thuật, vòng phỏng vấn không? Điểm số giống như là tấm vé để bạn đi vào một hội trường, lúc đó năng lực thật sự của bạn sẽ được thể hiện. Mà ngay cả tấm vé mời bạn còn chưa có thì lấy cơ hội đâu để thể hiện bản thân?Vậy điểm số có quan trọng không? 5. Hoạt động ngoại khoá, có ăn được không?Nói về hoạt động ngoại khoá, mình nói thẳng là mình không tham gia quá nhiều hoạt động Đoàn - Hội. Mình chỉ lọc ra một vài hoạt động thật sự có ý nghĩa (Cho mình và cho người khác) để tham gia. Ví dụ như hiến máu nhân đạo, vui hội trăng rằm, về với ngoại thành … Đi mấy cái này vừa bổ ích, vừa có trải nghiệm lại giúp đỡ được người khác.Các hoạt động ngoại khoá này sẽ là điểm nhấn quan trọng trong hồ sơ xin học bổng học tập hoặc học bổng du học.Ngoài các hoạt đông trong trường, các bạn có thể tìm thêm các hoạt động khác từ các tổ chức từ thiện. Mình đã từng tham gia hoạt động từ thiện của tổ chức phi chính phủ Habitat kết hợp với ĐHQG TP.Hồ Chí Minh, tập đoàn POSCO Hàn Quốc và sinh viên Hàn Quốc để xây nhà tình thương cho người nghèo ở Vũng Tàu. Các hoạt động này rất ý nghĩa và còn giúp bạn có thêm bạn bè, các mối quan hệ sau này.Các bạn tham khảo thêm tại đây: Habitat for Humanity Vietnam. 6. Học bổng, kiếm ở đâu?Mỗi kì trường mình đều có rất nhiều học bổng hỗ trợ các bạn: Học bổng khuyến khích học tập dành cho những bạn có điểm học tập cao (Lấy từ trên lấy xuống đến khi hết chỉ tiêu). Hồi lúc năm nhất mình nhận thì giá trị của nó là 2tr5 thì phải, sau đó đến năm tư thì nó tăng lên được gần 4tr 1 kì (Chắc do lạm phát :))). Khoảng tiền này cũng đủ để các bạn chi trả (Phần nào) học phí.Thật ra để lấy được suất học bổng này mình nghĩ là không quá khó. Điểm trung bình của các bạn chỉ cần trên 8.0 là đã có cơ hội nhận rồi. Về vấn đề điểm rèn luyện. Mình nghĩ cũng không cần thiết phải dành quá nhiều thời gian để tham gia các hoạt động Đoàn - Hội làm gì, chỉ cần tham gia một vài hoạt động chính (Xem lại mục hoạt động ngoại khoá) và không vi phạm gì đến các ‘giới răng’ của trường (Vắng sinh hoạt công dân, xác nhận lưu trú bla bla gì đó) là đủ điều kiện rồi. Ngoài ra khoa mình cũng có liên kết với các doanh nghiệp để có các suất học bổng khác. Các công ty lớn như KMS, ELCA, CSC, Global Cybersoft, NTTData, GameLoft, VNG… đều có liên kết với khoa mình để trao học bổng hằng kì (Hàng năm) cho sinh viên khoa mình. Giá trị các suất học bổng dao động từ 3tr - 5tr tuỳ công ty.Để được các suất học bổng này thì điểm trung bình của các bạn không cần quá cao (Chỉ cần từ 7.5+). Thường thì các suất học bổng này nhắm tới các bạn sinh viên khó khăn trong khoa nên sẽ có yêu cầu (Optional) nộp thêm một giấy xác nhận gia đình có hoàn cảnh khó khăn ở địa phương. Giấy này thì bạn về UBND quê của bạn xin tờ giấy xác nhận nhé.Các suất học bổng này ngoài giá trị vất chất (Tiền đó), một số công ty còn offer cho bạn các cơ hội thực tập (KMS, theo mình biết), hoặc sẽ có thư mời bạn làm việc ngay sau khi tốt nghiệp. Quá sướng phải hem? Thêm thông tin cho các bạn là khoa mình cũng có Quỹ học bổng từ các cựu sinh viên trong khoa dành cho các bạn có hoàn cảnh thực sự khó khăn (Cái này hình như không yêu cầu điểm cao, 7.0+).Các bạn sẽ được phỏng vấn với các Thầy/Cô chủ nhiệm Quỹ học bổng, Thầy/Cô sẽ quyết định số phận của bạn :). Theo mình biết thì học bổng này được cấp hàng tháng trong suốt 4 năm học với yêu cầu là bạn phải hoàn thành tốt chương trình học hay sao đó.Để thêm thông tin thì bạn vào đây: Quỹ học bổng cựu sinh viên khoa CNTT. Phía sau là những suất học bổng lớn hơn, đòi hỏi bạn phải có nhiều thành tích hơn (GPA phải thật cao: 8.5+, English tốt: Essay, một số học bổng đòi hỏi bạn phải test kỹ thuật, cống hiến cho xã hội: hoạt động ngoại khoá, bonus thêm: Công trình nghiên cứu, bài báo khoa học, giải thưởng quốc tế bla bla).Lúc này những hoạt động ngoại khoá của bạn mới thực sự phát huy tác dụng, những hoạt động phục vụ xã hội, nhắm đến cộng đồng sẽ được ban điều hành đánh giá cao, phần nào biét được nhân cách con người bạn. Các học bổng lớn người ta nhìn nhận con người ở nhiều khía cạnh chứ không chỉ học không, kiểu giống như Tài và Đức phải đi với nhau vậy đó.Mình list dưới đây chỉ là những học bổng mình đã đạt được thôi nhé, trường mình còn rất nhiều các học bổng khác tương đương, bạn có thể tìm thêm trên trang web của trường: Odon Vallet Scholarship 2016 from Recontres du Vietnam – Vallet Foundation for students with outstanding achievements. (Giá trị 15tr) Sunflower Mission Engineering and Technology Scholarship from eSilicon Corporation and Sunflower Mission foundation. (Giá trị 300$) Pony Chung scholarship is sponsored by Pony Chung foundation, Hyundai Development Company and Vietnam National University. (Giá trị 500$ + Cơ hội được học bổng sau Đại Học ở Hàn Quốc) Lawrence S.Ting scholarship from Lawrence S.Ting Memorial Fund for students with outstanding achievements. (Giá trị 10tr)Phần Essay xin học bổng, để hôm nào rảnh mình viết về kinh nghiệm với Essay sau, giờ làm biếng rồi =]].3s quảng cáo bằng khen của Sunflower (Cái bằng khen này đẹp nên khoe :))): 7. Học như thế nào?Quan trọng nhất vẫn là chính bạn, sẽ không có một phương pháp học tập nào phù hợp với bạn hết. Bạn phải tự tìm ra nó.Nhưng lời khuyên của mình dành cho các bạn là nên có một nhóm học tập, đối với mình thì nhóm này không cần phải là những super trong lớp, chỉ cần các bạn chịu khó học chung với nhau (Nhớ nhé, học nhiều hơn chơi), chia sẻ kiến thức với nhau, lâu lâu cho copy code xí =]], vì lượng kiến thức ở Đại Học rất nhiều, đặc biệt là ngành của mình, nên bạn phải có đồng bọn để học chung, với rủ rê cúp học đi xem phim, đi hát Karaoke chẳng hạn. Hồi đó mình ở chung kí túc xá với thím Trương, nó cũng chịu học nên mình đu bám nó để nó chỉ bài cho; hai đứa cắm đầu chạy deadline ngày đêm, nhờ vậy mà cũng khá lên được. (y)Trong Software Engineering có một khải niệm gọi là Trade-off, nghĩa là bạn phải biết đánh đổi giữa được và mất, giữa chi phí bộ nhớ và thời gian, giữa môn này và môn kia, trong những hoàn cảnh cụ thể, bạn lựa chọn cái nào thì đó là quyết định của bạn :).*”You can not write perfect softwares. Because a perfect software does not exist. No one in the brief history of computing has ever written a piece of perfect software. It’s unlike that you’ll be the first. And unless you accept this as a fact, you’ll end up wasting time and energy chasing an impossible dream”* (Pragmatic Programmer).Các bạn cũng tập tư duy phản biện, tức là khi người ta đưa ra một bài toán hay một solution cho bài toán, các bạn phải biết đặt lại câu hỏi, “Tại sao phải làm cách này mà không phải làm cách kia?”, “Cách này có ưu, nhược điểm gì so với cách kia?”, “Làm như thế này sau này có dễ mở rộng hay dễ bảo trì không?”, “Có cách nào thông minh hơn không?” … đại loại là những câu hỏi như vậy.Việc đặt câu hỏi sẽ giúp bạn hiểu rõ hơn về vấn đề, người nói chuyện với bạn cũng biết là bạn đã hiểu rõ vấn đề nên mới có thể đặt câu hỏi ngược lại, chứ cứ ngồi dạ dạ rồi làm theo mà không biết đúng sai thì lúc đó bạn chưa có cái gọi là Critical thinking.Một vấn đề nữa là trước khi đặt câu hỏi, các bạn nên tự tìm hiểu thật kỹ về vấn đề này, khi nào tìm không ra hoặc không biết keyword để tìm thì mình mới nên đi hỏi người khác. Mình vừa tiết kiệm thời gian cho người khác (Nhiều khi hỏi ngu quá bị chửi thì cũng đừng trẻ trâu mà gân cổ lên cãi), vừa giúp mình tập tính tự nghiên cứu. Sau này ra đời, sếp giao cho cái task, không biết đường tìm hiểu thì đi hỏi ai? Quay lại hỏi thằng hồi đó học chung à? =]]Sau đây là một số kênh các bạn có thể tham khảo: Medium, Stack overflow, Quora. Ngoài ra còn có các group học tập trên facebook của khoa, các bạn nên follow các trang này để cập nhập thông tin.Phương pháp tiếp thu kiến thức trong 1 môn học: cố gắng học kiến thức cơ bản (thuật toán chạy như thế nào, giao thức chạy thế nào, ưu nhược điểm của từng loại cơ sở dữ liệu, …) thay vì tập trung nhiều vào syntax và thư viện.Và, phải dành thời gian đọc thêm sách, học trên trường kiến thức cho mọi người là như nhau. Vậy cái gì để phân biệt bạn với những người còn lại? Là kiến thức bạn tự lượm nhặt riêng ở ngoài lớp học. Đọc thêm sách sẽ giúp bạn có cái nhìn sâu hơn về vấn đề đã học trên lớp. Nhiều khi thầy trên lớp nói cũng chưa hẳn là đúng hết. Đọc sách thì chưa bao giờ là vô bổ cả :). Sách thì mình có list ra một vài cuốn nổi tiêng ở mục 2.Kiến thức nền ở Đại Học rồi.Nên nhớ mình là một Engineer chứ không phải là một Coder. 8. “Lương anh có đủ sống hem?”Câu này là câu hỏi cuối cùng sau khi các bạn đã moi hết các kinh nghiệm học tập của mình. Mình đều trả lời là “Hem” =]]Như thế nào là đủ? Đủ sống thôi hả? Vậy thì chắc đủ sống rồi vì mình vẫn còn sống mà viết cái bài này này.Có một câu nói mình thấy rất đúng đó là Theo đuổi đam mê, con nợ sẽ theo đuổi bạn “Theo đuổi đam mê, thành công sẽ theo đuổi bạn“. Khi bạn làm việc hết mình với năng lực của mình thì người khác sẽ nhận thấy nó, sẽ đánh giá đúng những gì bạn đã bỏ ra, và bạn sẽ nhận lại được những gì xứng đáng thôi.Lại thêm một câu chuyện từ một cuộc phỏng vấn, sau khi hỏi mình mức lương mình mong muốn nhận, chị nhân sự dễ thương mới chia sẻ với mình rằng: 1234Sự nghiệp mỗi người sẽ trải qua 3 giai đoạn:Mởi tốt nghiệp: Lúc này bạn hoàn toàn trắng tay, hãy tập trung lượm nhặt kiến thức, nâng cao trình độ, theo chân người giỏi để học cái trí, cái tài của người ấy. Tạo thương hiệu cá nhân riêng của mình, cái tên của bạn.Kiếm tiền: Khi đã có trong tay kiến thức, bạn bắt đầu lao mình vào kiếm tiền.Sống với đam mê: Lúc này tiền đối với bạn không còn quan trọng nữa, cái quan trọng hơn cả là được làm cái bạn thích, làm cái bạn đam mê, làm cái bạn sinh ra để làm. Sau cùng thì chị trả lời là “Mức lương em đưa ra cao quá công ty chị hem trả nổi” =]].Mình kể câu chuyện trên với đám bạn thân, chúng nó nói đấy là thuyết âm mưu để tẩy não sinh viên đó =]].Riêng mình thì thấy chị nói cũng đúng mà, “Follow your passion and success will follow you.”Vào ngày tốt nghiệp các bạn sẽ được thầy trưởng Khoa cam kết 100% sẽ tìm được việc sau khi tốt nghiệp nhé, nên các bạn khỏi lo thất nghiệp hay lương bổng nhé (Việc đó cũng có thể là đánh văn bản dạo không chừng :3) 9. KếtNói chung, quãng đường Đại Học mà mình đã đi qua, và các bạn sẽ đi qua có lẽ là quãng thời gian đẹp nhất của đời người.Lúc trước mình vẫn hay nghe các anh khoá trên nói “Đi làm buồn hơn đi học” hay “Giờ ước gì được quay lại 1 tháng lúc học Quốc Phòng, chắc lúc đó quẩy banh cái TT. Quốc Phòng”. Lúc đó mình cũng “Dạ, em cũng thấy vậy”, mà lúc đó đã có trải nghiệm gì đâu mà Dạ như đúng rồi =]].Bây giờ, đã qua rồi cái thời sinh viên đó, giờ mới thật sự hiểu được tâm trạng của người nói.Nói dài nói dai, nói tóm lại là 4 năm sẽ trôi qua rất mau, nên các bạn cứ sống chậm lại thôi, từ từ mà tận hưởng deadline với bạn bè. Sau cùng nhìn lại thì nó cũng chẳng là gì cả. NOT A BIG DEAL !!! Cái mà các bạn có được là kỉ niệm thời sinh viên đầy nhiệt huyết :).By the way, một phút mặc niệm cho sự đóng góp của các thanh niên: Đạp Xích Lô (DevOps &amp; Security Engineer), Cảnh Nguyễn (Back-end Engineer) đã góp ý chỉnh sửa bài viết.","link":"/2017/09/25/Chuyen-o-Dai-Hoc-Phan-1/"},{"title":"Bluetooth Low Energy On iOS","text":"The Core Bluetooth (CB) framework allows iOS and MacOS apps communicate with BLE devices. Your apps can discover, explore, and control the BLE devices, such as heart rate monitors, trackers or hybrid watches. Image 1. BLE devices (Source from Google) On MacOS 10.9 and iOS 6, Mac and iOS devices also play the roles of BLE peripherals to serve data to other devices, including other Mac and iOS devices. In this tutorial, I will introduce the key concepts of the Core Bluetooth framework and how to use the framework to discover, connect, and retrieve data from compatible devices. Feel free to leave out your comments on my post. ## At a glance BLE was introduced in early 2010 and based on Bluetooth 4.0 specification. BLE uses the same 2.4 GHz radio frequency as classical Bluetooth. In theory and in ideal conditions (Without obstacles), BLE’s range get over 100m but in fact, the maximum distance is 10m. Image 2. BLE in reality (Source from Google) This technology is power-friendly because it uses less power than other wireless technologies. Thanks to its low power consumption, BLE is used to integrate into electrical devices that required less power consumption such as heart rate monitors, trackers, watches, shoes to make them smarter.So, what are the cons of BLE technology? It’s data transfer rate. In order to decrease power consumption, BLE chips only transmit data in some time called interval (Whereas Classical Bluetooth can transfer data at any time they want), and the amount of transferred data in an interval is also limited in a few dozen of bytes. Some more information about maximum throughput on iOS and MacOS (Provided by PunchThrough) iPhone 6, 6+, 6S, 6S+: 12Normal Connection Interval of 30mSecs: 2,667 bytes/secConnection Interval for HID Over GATT is Present 11.25mSecs: 7,111 bytes/sec MacBook Pro - OS X (Varies on models): 1Maximum Connection Interval range of (11.25 - 15mSecs): 7,111 bytes/sec - 5334 bytes/sec To get more technical details about Bluetooth technology, please refer to Bluetooth Special Interest Group (SIG). Basic Concepts1. The playersThere are two major roles involved in all BLE communication: The Central and The Peripheral: Peripheral: are devices having data that is needed by other devices. Central: typically use the information served up by a peripheral to accomplish some tasks. For examples, reading heart rate or temperature information from monitors (A peripheral).Image 3. The Central and the Peripheral (Source from [Apple doc](https://developer.apple.com/library/content/documentation/NetworkingInternetWeb/Conceptual/CoreBluetooth_concepts/AboutCoreBluetooth/Introduction.html)) 2. The connection parametersThe connection parameters for a BLE connection is a set of parameters that determine when and how the Central and a Peripheral perform data transferring. The Central will actively set the connection parameters used, but the Peripheral can send another parameter that the Central can then accept or reject. Both sides will continue to request connection parameters until they find a reasonable number that they accept.There are 3 different parameters: Connection interval: This value determines how often the Central and the Peripheral transfer data to each other. Slave latency (Latency, shortly): If we set a non-zero latency value, the Peripheral can skip requests from the Central when the Central asks for data up to the slave latency number of times. However, if the Peripheral want to transmit data to the Central, it can send data at any time. This allows a peripheral to stay sleeping for a longer time to decrease power consumption. Connection supervision timeout: This value determines the timeout from the last package exchange until the transference is considered lost. The Central will not start trying to reconnect before the timeout has passed. For example, if you set {interval, latency, timeout} = {15, 0, 720} as connection params for the peripheral: In every 15 (ms), the peripheral will be wake-up and listen to requests from the central, also transmit data if needed. Latency equal 0, it means that the Peripheral have to answer the Central at any time the Central requests in an interval (15 ms). After 720 (ms) from the last packet was sent, if the Central still does not receive the packet, the Central will determine that the packet was lost and requests the Peripheral re-send the last packet. 3. Bluetooth Low Energy Protocol StackCoreBluetooth hides many of the low-level details of the specification from developers, making it much easier to develop apps that interact with BLE devices. Advertising and General Advertising Profile (GAP)BLE devices let other devices know that they exist by advertising using the GAP. Advertising packets contain some basic information such as device name, serial number, or RSSI value, and also a list of the services it provides. The limited size of advertising packets is 128 bit.RSSI stands for Received Signal Strength Indicator. RSSI value represents the strength of the transmitting signal. We can estimate the current distance between the central and the peripheral based on the value. The greater the value, the closer the device is. Image 4. Advertising and discovery in BLE General Attribute Profile (GATT)GATT is the layer that defines services and characteristics which is used to transmit data between the Central and the Peripheral, also enables read, write, notify operations on them.In most case, the Peripheral is also called GATT server since it provides the services and the characteristics whereas the Central is the GATT client. ServicesServices are identified by unique numbers known as UUIDs. Standard services like Device Information Service (0x180A), which exposes manufacturer and basic information about the device (Firmware version, serial number, model number), have a 16-bit UUID and custom services have a 128-bit UUID. (E.g: 0x3dda0000957f7d4a34a674696673696d, etc.) CharacteristicsA characteristic contains a characteristic declaration, characteristic properties (ReadWrite, ReadOnly, Notify, WriteWithoutResponse and so on), and a value. Characteristics allow us to access the value and the information that they contain. A service can have more than one characteristic.The following picture shows the relationship between Profile, Services, Characteristics. Image 5. Relationship between Profile, Services, Characteristics 4. Bluetooth Concepts and CoreBluetooth on iOSIn the CoreBluetooth framework A Central is represented by the CBCentralManager class and is used to discover, establish a connection and control the peripheral. A peripheral is represented by the CBPeripheral class, the services relating to a specific peripheral are represented by the CBService class and characteristics of a peripheral’s service are represented by the CBPeripheral class. The following image shows the structure of a Services and its Characteristics on iOS: Image 6. Relationship between CBPeripheral, CBService and CBCharacteristic objects on iOS SummaryBLE is a revolutionary technology of Classical Bluetooth. In reality, BLE is used to integrate into small devices like lockers, trackers, watches, shoes and some kind of jewelry (rings) to make them smarter, towards IoT environment.In the next section, I will guide you how to use CoreBluetooth to create your own services on an iOS device, also use CoreBluetooth on another device to discover, connect and control your BLE services. If you liked this post and would like to see more in the future, please let me know. References[1] Bluetooth Special Interest Group[2] Apple document: Core Bluetooth Concepts[3] Maximizing BLE Throughput on iOS and Android","link":"/2017/10/13/Bluetooth-Low-Energy-On-iOS/"},{"title":"Core Bluetooth on WatchOS","text":"Ever thought about adding a Watch App to your product? Wondering how to make CoreBluetooth work on your Watch App? You’re in the right place! This tutorial is your go-to guide. In this post, we’ll take you step by step through the process of smoothly bringing in data from Bluetooth gadgets into your Apple Watch apps. Discover how to harness the potential of Bluetooth devices to enhance your Apple Watch user experience. We’ll also provide insights into overcoming common challenges when dealing with Core Bluetooth on watchOS. Whether you’re a seasoned professional or a beginner, this tutorial simplifies the process for you. Environments: XCode 15.0.1, iOS 17.0.3, WatchOS 10.1.1, Swift 5. Set up projectStart by going to your project settings, then select File &gt; New Target &gt; Watch OS &gt; App, and fill in the required fields. Once done, Xcode will seamlessly integrate a new watch app project into your existing workspace. Bluetooth configEssentially, all methods and Bluetooth events on WatchOS closely resemble those on iOS. If you already have a BluetoothManager class that handles various Bluetooth functions, such as initiating scanning or connecting to a peripheral, and manages Bluetooth delegates, you’re in good shape. 123456789101112131415161718192021class BluetoothManager : NSObject, CBCentralManagerDelegate { private var central: CBCentralManager! override init() { super.init() central = CBCentralManager( delegate: self, queue: nil, options: [:] ) } func startScanning() { central.scanForPeripherals(withServices: nil, options: [CBCentralManagerScanOptionAllowDuplicatesKey: true]) } func connect(periperal: CBPeripheral) { central.connect(periperal) } // The rest omitted} To save time and avoid duplicating code, you can easily share the file containing the BluetoothManager class with both your iOS and watch app targets. With this setup, you can seamlessly use the BluetoothManager class in your watch app just like you would in your iOS app. 1234567891011121314struct ContentView: View { var body: some View { VStack { Image(systemName: \"globe\") .imageScale(.large) .foregroundStyle(.tint) Text(\"Hello, world!\") } .padding() .onAppear(perform: { BluetoothManager.shared.startScanning() }) }} Important notes To test your project’s Bluetooth functionality, it’s essential to run it on a real Apple Watch since the simulator doesn’t support Bluetooth. Keep in mind that the connection time on the Apple Watch can be influenced by the device’s battery status, even if low power mode is not enabled. Ensure that you manually add the necessary capability to the Watch App plist file. This step is crucial; otherwise, your app won’t be able to scan, connect, or execute any Bluetooth commands when it’s in the background. 1234&lt;key&gt;UIBackgroundModes&lt;/key&gt;&lt;array&gt; &lt;string&gt;bluetooth-central&lt;/string&gt;&lt;/array&gt; Unlike Bluetooth on iOS, where you can leverage State preservation and restoration to awaken the app if it has been terminated by the system due to Bluetooth events (see Best practice: Best practice: How to deal with Bluetooth Low Energy in background), it’s important to note that there is no equivalent State preservation and restoration mechanism on watchOS. The connection time on iOS and WatchOS is quite equal. I measured the Connect API by performing 200 calls (same devices, same testing environment). The average on iOS is approximately 0.69 seconds, while on WatchOS, it is 0.78 seconds. ConclusionIn a nutshell, by learning how to connect your Apple Watch to Bluetooth devices, you’ve boosted your watch’s features. This tutorial has guided you through using Core Bluetooth on watchOS, handling common problems along the way. Whether you’re a pro or a beginner, we’ve broken it down for you. Now, your Watch App not only works well but also impresses users. As you keep making apps, use these skills to create cool and smooth experiences. Happy coding! References[1] WWDC 2021[2] WWDC 2022[3] Core Bluetooth in watchOS Tutorial","link":"/2024/03/23/Core-Bluetooth-on-WatchOS/"},{"title":"Crash early in Swift","text":"Last night, I read a chapter of a book as one of my favorite books: &quot;The pragmatic programmer&quot; (By Andrew Hunt and David Thomas). This chapter discusses how to use assertion to make the code easier for debugging. We all know that assertion is an essential tool for writing tests, but It does more than that. Let’s go with me to meet this guy: Assertion. Crash, don’t trashDo you ever have one of the following conversations to yourself or with your colleagues in a technical discussion? “This case will never happen so we don’t need to process this one.” “This class must be “Dog”, it can never be “Cat”, let’s force unwrap this object.” “This error will never occur, just ignore it.” “You idiot! why do we handle this case when your code never reach out to this line?” But what if “this case” happen somehow? Does the app still response in the way that we expect? Is there any chance that the unexpected situation will damage our essential database?At the very beginning of this chapter, the author introduces some situations that I can see myself in those examples: “This code won’t be used 30 years from now, so two-digit dates are fine.” “This application will never be used abroad, so why internationalize it?” “count can’t be negative.” “This printf can’t fail.” 1IF IT CAN'T HAPPEN, USE ASSERTIONS TO ENSURE THAT IT WON'T If we believe something cannot happen, or something true, use assertions to ensure your belief is true! If the condition of assertion is not met, it will immediately crash the app. It’s very useful during development because it leads us exactly to the problems. Before to continue, let’s talk about the Swift Optimization levelsDepend on whether the build is in Release mode or Debug mode, the Swift compiler will turn on or off the assertions (Lines with assert statements are omitted), it’s good to know the Swift optimization levels before we continue.There are 3 types of optimization level for a build in Xcode None (Onone): The default for debug builds. Compile without any optimization. Fast (O): The default for release builds. Compile with optimizations. Unchecked (Ounchecked): Compile with optimizations and remove runtime safety checks, including checking array out of bounds, unwrapping nil, precondition and preconditionFailure. That’s why we should not use the Ounchecked mode in release build because it can lead to memory corruptions and the app might behave inappropriately. Updates: As you can see there is no longer the -Ounchecked mode in Xcode10, instead a new option introduced Optimize for Size. The main difference between the O mode and Osize mode is “When compiling with -O the compiler tries to transform the code so that it executes with maximum performance. However, this improvement in runtime performance can sometimes come with a tradeoff of increased code size. With the new -Osize optimization mode the user has the choice to compile for minimal code size rather than for maximum speed” (swift.org) Apply Assertion to SwiftTruly to say, before reading this chapter of the book, I thought “Assertion” only used when writing unit test. The fact that developers use Assertion in developing to make the developing process safer and easier for tracing a bug.Swift provides 5 types of assertion function that differ from each other in terms of how they affect the flow of codes: assert() &amp; assertionFailure(): Use them when we want to verify our code, but if it is actually an issue, it wouldn’t necessarily exit the app. The compiler will ignore assert() and assertionFailure() statements for a release version (In -O mode). For example, I use assert to ensure there are no unexpected requests in my business flow. By doing so, I guarantee that if there is a “strange guy” appears in my flow, the flow will be broken and the app will be terminated. Also, the debugger will lead me directly to the problem so that I can identify logic problems and clear out bugs as early as possible. precondition() &amp; preconditionFailure(): Use these functions to detect a condition that must be fulfill before continuing to process, even in release version (-O mode). For example, let’s say that we need to load a config file when the app launch. If there is no config file, then we should stop the app immediately rather than continuing the execution.123guard let fileConfig = Bundle.main.path(forResource: \"config\", ofType: \"json\") else { preconditionFailure(\"Unable to load config file.\")} fatalError(): The same as precondition() and preconditionFailure() functions, except fatalError() works for all optimisation levels in all configurations, it means your app ALWAYS be terminated if the fatalError line is reached. In the following example, I use fatalError() to force every inherited class must override the parseData(files:) from its super class. Highlighted advice from the author &quot;All errors give you information. You could convince yourself that the error can't happen, and choose to ignore it. Instead, Pragmatic Programmers tell themselves that if there is an error, something very, very bad has happened.&quot; If an error happens, can we recover it? If we can not handle some unexpected problems, then crash early to protect our vital data (Especially in banking apps that require high security for database). &quot;Don't put assertion in the code of real error handling.“ It is a misunderstanding if we put assertion everywhere around the code, particularly in the code of real error handling. Assertion is not supposed to be used this way. If we simply to terminate a running program, it will affect to the user experiences, resulting in users will no longer open your app. The simplest principle to check if we should exit the program when errors occur is When your code discovers that something that was supposed to be impossible just happened, your program is no longer viable. Anything it does from this point forward becomes suspect, so terminate it as soon as possible. A dead program normally does a lot less damage than a crippled one. &quot;The condition passed to an assertion should not have a side effect&quot;. It is embarrassing if we put a code to check errors actually causing to other errors. 😖 For example, the following code (In Java) is added assert to make sure the next element is not nil, but it actually creates a new error. Can you find it?12345while (iter.hasmoreElements () { Test.ASSERT(iter.nextElements() != null); object obj = iter.nextElement(); // ....} ConclusionIn this article, we walked through these five methods for an early exit in Swift. In general, the right way to pick which one to use depends on the context of the error: Whether the error can be recoverable or not? If the answer is no, then crashing is the best way we can do to protect our app from unpredictable behaviors. Sometimes, the app is in a situation where it would be too dangerous to continue.Hope you found this post useful then you can apply this idea to your next project.Thanks for reading! 🚀","link":"/2019/01/19/Crash-early-in-Swift/"},{"title":"Dark Hat - v1.0 has been released 🎉","text":"After years of working in BLE technology, I found that despite there are many applications helping to test BLE devices but none of them performs their roles well. That’s why I decided to implement a BLE application on my own - Dark Hat. The core objective of this application is to share a better tool with you - an engineer working in BLE field. Main FeaturesDiscover nearby devices with multiple filters supported to only show devices which mater to the user. Filter by RSSI. Filter by device name. Filter by service UUID: Only retrieve and scan devices having your service UUID. Support many options in a setting that allows users to customize the app to meet their requirements. State management: Auto reconnect when the connection is lost. Preservation and Restoration: The user now can opt-in to test “Preservation and Restoration”. For more detail about this technique, please refer to Best practice: How to deal with Bluetooth Low Energy in background Steps in the connection flow are now controlled by the user: connection timeout, set notification state and more. The main screen shows all info and services that really matter to you.The inline log view helps you have a better observation of what’s happening on your device.The app also offers an option that allows the user to set his own name for characteristics for better visualization, on | off notification, copy UUID to clipboard, and more. The app supports a smart editor that automatically suggests all recent commands - a small improvement but it helps to reduce your time on testing.The characteristic detail screen now offers an option allowing show all responses from multiple characteristics which helps you to catch the whole flow while testing. Easy for sharing: Share your result just in 1 click. ArchitectureAt the heart of this application is an SDK called BLEFramework - implemented by me - that wraps all logic working with Apple’s BLE framework and provides simple interfaces for high-level layers - the application. By doing this way, we can separate the complex logic from the UI application, making it easy for development and maintenance.Additionally, I plan to move all UI views to a cross-platform technology (maybe React Native) to support Android in a unique, single view layer. All I just need to do is create another SDK supports for Android platform. Next stepsI have a road map to add more amazing features to the app, to name a few: realtime streaming data, speed measurement, multiple connections, control by script, iBeacons.Can’t wait to deliver all these cool features to users.If you have any idea or feedback, feel free to kick an email to uynguyen.itus@gmail.com or dark.hat.ble@gmail.com, I would love to hear from you.","link":"/2021/07/25/Dark-Hat-v1-0-has-been-released-yay/"},{"title":"Design patterns","text":"","link":"/2018/06/01/Design-patterns/"},{"title":"Create and Distribute Private Libraries with Cocoapods","text":"CocoaPods is a dependency manager for Swift and Objective-C projects. This tool not only allows us to easily integrate those dependencies but also allows us to create our own libraries. In this post I’m going to guide you how to create a private library and distribute it to your private team without publishing the library. Init repositoriesGo to Github or Bitbutket, then create two repositories. One for our source code that is shared between our team, the other one for Podspec, which defines all the information about that Pod. Image 1. Create Github repo to store our source code Image 2. Create Github repo to store our Podspec files Following the instructions on Github page, it guides you how to add your project to these repositories. 123456$ echo \"# MyAwesomeKit-Spec\" &gt;&gt; README.md$ git init$ git add README.md$ git commit -m \"first commit\"$ git remote add origin git@github.com:uynguyen/MyAwesomeKit-Spec.git$ git push -u origin master Create our own libraryOpen XCode and create a new Cocoa Touch Framework named MyAwesomeKit. After that, create a simple class called HaHaHaManager, this class defines our public methods for clients. To make it easier, I define a simple method, which takes 2 numbers as arguments then return their addition: 123456public class HaHaHaManager { public init() { } public func awesomeFunction(a: Int, b: Int) -&gt; Int { return a + b }} Note: Since we are creating a public Framework, we have to overide the default constructor of the HaHaHaManager class, make it become public. Otherwise, our clients who use this Framework can not create an instance of this class because the default scope of classes in Swift is internal. After then, push our code to the repository that we created at the first step. Make sure you add a tag as a version for this commit. 1234$ git add .$ git commit -m \"Our first commit\"$ git tag MyAwesomeKit_1.0.0$ git push -u origin master --tags Add your Private Repository to your CocoaPods InstallationUse the following command to create your new private repository to your CocoaPods 1$ pod repo add REPO_NAME SOURCE_URL 1$ pod repo add MyAwesomeKit https://github.com/uynguyen/MyAwesomeKit Make sure you have the correct access rights to the repository. You can config ssh to access the repo via ssh key. See also: Generating a new SSH key and adding it to the ssh-agentTo check if your installation is successful, use the following commands: 12$ cd ~/.cocoapods/repos/MyAwesomeKit$ pod spec lint . --allow-warnings This command is used to validate specifications. --allow-warnings flag indicates that we skip all warnings when validate the Pod file. (Missing some options such as lisence, author or description). Generate our Podspec fileType the command to generate our Podspec file. This file contains all information about our code, including git repository, the version of the library, dependencies, etc. 1$ pod spec create MyAwesomeKit You will see something like this 123456789101112131415Pod::Spec.new do |s| s.name = \"MyAwesomeKit\" s.version = \"1.0.0\" s.summary = \"An awesome KIT can do anything for you\" s.homepage = \"https://github.com/uynguyen/MyAwesomeKit\" s.author = { \"Uy Nguyen\" =&gt; \"uynguyen.itus@gmail.com\" } s.source = { :git =&gt; \"git@github.com:uynguyen/MyAwesomeKit.git\", :tag =&gt; \"MyAwesomeKit_#{s.version}\" } s.platform = :ios, '8.0' s.requires_arc = true s.dependency 'AFNetworking', '~&gt; 3.1.0' [1] s.source_files = \"MyAwesomeKit/**/*.{swift}\" [2] s.frameworks = 'UIKit', 'CoreText' [3] s.library = 'z', 'c++' s.module_name = 'MyAwesomeKit'end Here’s what’s going on: 1: Your other Podspecs depenencies. For more than one dependency, add new line to define it. 2: The source files that will be included. (Replace it by .m, .mm, .c or .cpp if you need) 3: The framewords that are linked with your library. For other options, please refer to Podspec Syntax Reference Push to Spec Repo 1$ pod repo push MyAwesomeKit MyAwesomeKit.podspec --allow-warnings The structure of your folder will be like 12345.├── MyAwesomeKit-Spec └── MyAwesomeKit └── 1.0.0 └── MyAwesomeKit.podspec Whenever you update the library, you have to run the update command to update your Pod repos 1$ pod repo update Use our awesome KitIt’s time to use our powerful Kit. Open XCode and create new project named MyAwesomeApp. After that, type the below command to init the Pod file 1$ Pod init Open the Pod file, add the following code to install our library. 123456789101112131415161718# Uncomment the next line to define a global platform for your projectsource 'git@github.com:uynguyen/MyAwesomeKit-Spec.git'source 'https://github.com/CocoaPods/Specs.git'platform :ios, :deployment_target =&gt; '8.0'target 'MyAwesomeApp' do # Comment the next line if you're not using Swift and don't want to use dynamic frameworks use_frameworks! pod 'MyAwesomeKit', '1.0.0' # Pods for MyAwesomeApp target 'MyAwesomeAppTests' do inherit! :search_paths # Pods for testing end target 'MyAwesomeAppUITests' do inherit! :search_paths # Pods for testing endend Let see our results (Pray and hope to it works well) ConclusionWe have just published our first private Pod to our team. From now on, our team can use this library privately. Moreover, it’s easy to update and distribute the library when it gets upgrade. Thanks to CocoaPod!If you have any questions or comments about the post, feel free to kick an email to me. References[1] Private Pods","link":"/2017/09/25/Create-and-Distribute-Private-Libraries-with-Cocoapods/"},{"title":"Documenting a Software Architecture","text":"It’s clear that documenting architectures is one of the most boring important tasks of Software Engineering. A two-sided activityThere are many good reasons why we have to document our software projects: Other members can understand and evaluate the design of this software. We can understand what we implemented when we return to it after a certain of time. We can do analysis on the design to evaluate the performance of this system, prevent errors occur before we start the implementation phase. Documenting architectures also have some downsides, like: The documents will gradually out of date with the code. Keeping the architecture documentscurrent is often an overlooked activity, especially under the pressures in a project. Documenting is time consuming and expensive. So when should we document software architectures?There are a lot of factors to consider if we need to document or not. Projects with little prospect of a long life probably don’t need a lot of documentation. The other factor to consider when documenting is the needs of project stakeholders, including the various roles like developers, testers, managers, etc. In a small team, the documentation can be minimal and can be replaced by interpersonal communication, it saves our time. In a large team, however, the documentation becomes more important for describing the system, especially companies that work in multiple countries and in many offices. Therefore, it is important to think carefully before documentation because it takes time to develop and maintain along with projects.In this post, I will introduce you to the most popular language to document software architectures: Unified Modeling Language. Unified Modeling Language (UML)UML is a modeling language of Software Engineering. It provides a standard way to visualize the design of a system or an application. UML includes both structural and behavioral diagrams for representing a software system: A structual diagram describes static architectures of its system. A behavioral diagram shows the interactions between entities inside a system. Note that I have never used Component diagrams, Package diagram, Deployment diagrams, Profile Diagram, Composite Structure diagrams, Communication diagrams, Interaction Overview diagrams and Timing diagrams so I’m going to skip these diagrams in this post. Structual diagramsClass diagramsA class diagram describes the structure of a system by showing relationships between its classes. It also shows attributes and methods of each class. The main purpose of class diagrams is to get the general overview of the system. Where vis = visibility Syntax Visibility type + Public If a variable or a method is static, it has to be underlined. # Protected - Private ~ Package The following lines introduce some major replationships in Class diagrams. Mark Meaning Implementation Class B implement the behaviors that are defined in Class A. Inheritance Class B has IS-A relationship with class A, or we can say Class B is a type of Class A. Dependency It exists between two elements if changes to the definition of one element may cause changes to the other. Association A binary association (with two ends) is normally represented as a line. It indicates that Class A contains one or more properties belonged to class B, or vice versa. Aggregation It is a special case of Association. We can say Class A is aggregated with Class B if Object X as an instance of class A is destroyed but Object Y as an instance of class B is still exist. Here, the lives of both Employee and Department are independent of each other. Employees may exist without a department. Composition It is a special case of Aggregation but it is stronger than Aggregation relationship. If Object X as an instance of class A is destroyed, the Object Y as an instance of class B will also be destroyed. We also say Composition is HAS-A relationship. Here, If we delete the verhicle object then all the engines are automatically deleted. The engines do not have their independent life cycle, it depends on the verhicle object’s life. A class diagram example. Instance diagrams (Object diagrams)Basically, an instance diagram is similar to the class diagram which it depends upon. However, an instance diagram is just a snapshot of the system at some point in time, and it shows what values those objects contain at this specified time. Instance diagrams are often used to make prototypes of a system, and to get more understand the system in a practical view.Symbols and notations of instance diagrams can be utilized in class diagrams. Example Transfer from a class diagramt to an instance diagram. Behavioral diagramsActivity diagramsAn activity diagram shows the flow from one activity to another activity (An activity is a function performed by the system). Note that messages are not included in activity diagrams.An activity diagram is often used to describe the high level of the system, mainly for business users or non-technical persons. It can also describe the steps in a use case diagram.Basic symbols and components: Basic Symbol Meaning Start point It represents the initial action state. Activity It represents an activity of the process. Condition Use this symbol when an activity requires a decision prior to moving on to the next activity Synchronization It indicates that multiple acitivies are performed synchronously. Time event This refers to an event that stops the flow for a time. Interrupting Edge An event that interrupts the flow. End Point It represents the final action state. Sequence diagramsA sequence diagram shows how objects and components interact with each other to complete a function.Basic symbols and components: Basic Symbol Meaning Actor It shows entities that interact with the system. Object It represents an object in UML. Activation box It represents the time needed to complete a task. Loop It indicates loop statements. Alternative It indicates condition statements. Parallel Each task in the frame represents a thread of execution done in parallel. Synchronous message The sender must wait for a response to a message before it continues. The diagram should show both the call and the reply. Asynchronous message The sender does not need to wait for a response to a message before it continues. Return message Messages are replied to calls. Delete object It indicates that the object will be detroyed. State Machine diagramsThe main purpose of state machine diagrams is to show the state changing of an object during its lifetime. Basic Symbol Meaning State A state represents a situation during the life of an object. Initial State The object’s initial state. Final State The object’s final state. The following example shows the transition state of an order. Use Case diagramsAn use-case diagram shows how the users or other external applications interact with the system. It also shows the scope of the system. Basic Symbol Meaning Actors They represent the users or external systems that interact with our system. Use cases They represent the different uses that a user might have. Associations There are two types of associations: Actor-use case and use case - use case. an Actor - use case association indicates which actors are associated with which use cases. An Use case - Use case association shows the relationship of two use cases: - Include: A use case “include” another if it is a required action by the use case. - Extend: A use case “extend” another if it is an optional use of the use case. - Generalization: The use case inherits the structure, behavior, and relationships of another. Have you ever heard about Business Process Model and Notation (or BPMN)?“Business Process Model and Notation (BPMN) is a standard for business process modeling that provides a graphical notation for specifying business processes in a Business Process Diagram (BPD).” (Wiki).The main objectives of BPMN are: To provide a set of standard notation that is understandable by business stakeholders. Often used to defined business logic because it has more complete concepts of events and it supports asynchronous message exchanges, which are important in business processing. BPMN is similar to activity diagram from UML. An Example of BPMN. A shopping process described by using BPMN (Source from Google image) ## Differences between UML and BPMN, which one to use? We use BMPN to describe the system on a high level, not care too much about computational details. In contrast, UML is used to define the details of this system, how is it constructed? how is it organized? how does it interact with other components? how is data processed? etc. ConclusionIn this post, I showed you the general ideas of some popular UML diagrams, and showed you the main difference between the UML and the BPMN. Of course, there’re still a lot of purposes and notations of those diagrams that I can not list out here because of the scope of this post.If you are interested in UML, you can download the full document of UML here (The latest version of UML is 2.5.1).Thanks for reading. References[1] Essential Software Architecture (2011, Springer-Verlag Berlin Heidelberg)Ian Gorton (auth.), Chapter 8 Documenting a Software Architecture.","link":"/2018/04/11/Documenting-a-Software-Architecture/"},{"title":"Fork and publish your custom lib to npm - React Native Wheel Picker","text":"When developing a new feature of our software, we tend to search if there is a “similar” library or framework available in the community to reuse it. No one like to reinvent the wheel, dont you? 😉 However, the lib that most fits our requirement sometimes does not support a feature you need or just a custom property. You can open a pull request to the original repo, but it might take time and depend on the author whether he approves your changes or not. In that case, you can create your own library from the original one, we named it “Fork” process.In this post, I will shortly summarize steps to publish a library to npm, and tell you about a story that I faced when using React Native Wheel Picker library. It’s quite simple to publish a lib to npm. Just need to do the following steps: Make sure you have a npm account. Go to https://www.npmjs.com to sign up for an account if you don’t have one. Next, sign in to your account on your computer via the command line npm login. To check which user is signed in, use npm whoami. The lib I use for my project support a Wheel Picker component, but it has been deprecated, and it does not support setting the color of the selected item on Android. Besides, I want to create my own lib so that I can easily add more features later. So I decided to fork and custom my own wheel picker. To fork a lib, go to the repo of the lib you want to modify, then press the fork button on the top right corner. After forking successfully, you should see the repo from on your dashboard. Next, clone the code to your computer, and add your new features.In my case, I need to add a new feature that supports setting the color for the selected item (Refer to this PR) When finishing your modification, commit your changes. Update the repo info at the package.json file if needed (Author, version, description, etc.). Finally, run npm publish --access public to deliver your awesome lib. It’s time to check the new lib. If you install the new lib @uynguyen505/react-native-wheel-picker and try to use it, you should see the result as below. Happy weekend! Refs Creating and publishing scoped public packages Forking, Modifying, and Publishing NPM Packages — For those almost-perfect packages","link":"/2022/03/26/Fork-and-publish-your-custom-lib-to-npm/"},{"title":"Grand Central Dispatch in Swift","text":"Grand Central Dispatch, or GCD for short, is a low-level C APIs for managing concurrent tasks. It helps us improve our app performance by executing a block of code in reasonable threads, like perform computationally expensive tasks in the background. GCD provides several options for running tasks such as synchronously, asynchronously, after a certain delay, etc.In this post I will explain more details about GCD and how it works, also provide some interesting points when we work with GCD. Let’s start. IntroductionAt the heart of GCD are dispatch queues which are pools of threads managed by GCD. Apple creates GCD to make developers don’t need to care too much about these queues, they just simply dispatch a block of code to a given queue without caring about which thread is used. GCD ConceptsConcurrencyConcurrency is achieved when more than two tasks are executed at the same time. In fact, the word “Concurrency” does not exactly mean “at the same time” or “happen in parallel”. Under the hook, CPU gives every task a certain time slice to do its works. For example, if there are 5 tasks to be executed in one second, with the same priority, the OS will divide 1,000 milliseconds by 5 (tasks) and will give each task 200 milliseconds of the CPU time. As a result, they will appear to have been executed concurrently. Serial queue and concurrent queueA serial queue will execute its tasks in a first-in-first-out (FIFO) fashion. It’s mean that they can only execute one block of code at a time. They do not run on the main thread, therefore, they do not block the UI.In contrast, a concurrent queue allows to execute multiple tasks in parallel. It means tasks can finish in any order and you won’t know the time it will take. Synchronously (sync) and asynchronously (async) methodsWhen you dispatch a task to a queue, you determine whether the block run synchronously or asynchronously. There are some main differences between the two techniques: A synchronous method returns control to the caller only after the task is completed whereas an asynchronous method returns control to the caller immediately. Since asynchronous methods return control immediately so they don’t block the current thread. Note that the world “synchronous” does not mean the program have to wait for the code to finish before continuing. It just means that the concurrent queue will wait until the task has finished before it executes the next block of code on the queue.The code below demonstrates how to use async and sync executions.1234567891011121314151617DispatchQueue.global().sync { [1] print(\"A\") DispatchQueue.global().async { for i in 0...5 { print(i) } }}DispatchQueue.global().sync { [2] print(\"B\") DispatchQueue.global().async { for i in 6...10 { print(i) } }} Generally, we can not predict the output when we run the code above because everytime we run the program, the numerous of different outputs will be printed. We can only say that “B” will always be printed after “A” as the caller need to wait for the block [1] returns control so that it can execute the next block [2].If we edit these inner blocks to sync, we guarantee that the output will always be A 0 1 2 3 4 5 B 6 7 8 9 10.Three main types of queuesThere are three main types of queues in GCD: Main queue: Tasks are dispatched to this queue will be performed on the main thread, where UI-related works are called. The Main queue is a serial queue. Important note, the sync method can not be called on main thread because it will block the thread completely and lead the application to deadlock. Therefore, all tasks submitted to the main queue must be submitted asynchronously. 1234567override func viewDidLoad() { super.viewDidLoad() let mainQueue = DispatchQueue.main mainQueue.sync { // -&gt; This code will lead to Deadlock print(\"Inner block called\") }} Global queues: They are concurrent queues and are shared by the system. We use global queues for any task that does not involve the UI. For example, downloading an image from the internet then display it to the user after it is downloaded, fetching database from a server, etc.When we work with global queues, we don’t specify the priority but we use a Quality of Service (QoS) to help the GCD determine the priority of the tasks. It is important to keep in mind that apps use various resources like CPU, memory, network interface, etc. Thus, we should choose the right QoS of the queue in order to remain responsive and efficient of the app. The OS will base on the given QoS to make smart decisions about when and where to execute them.There are four types of QoS: User-interactive: This indicates that the tasks need to be executed immediately in order to remain responsive on UI. We use it for UI updates or performing animations. User-initiated: Work that the user has initiated and requires immediate results (In a few seconds or less). We use it to perform an action when users click something in the UI. Utility: the tasks may take some time to complete and does not require an immediate result (Takes a few seconds to a few minutes) such as downloading data. Background: This represents tasks that the user is not directly aware of. Normally, we use it for fetching data or any tasks that don’t require user interaction. Custom queues: When you create a custom queue, you can specify which type of queue it is (Serial or concurrent). By default, they’re serial queues. DeadlockThe word Deadlock refers to a situation in which a set of different threads sharing the same resource are waiting for each other release the resource to finish its tasks.When working with the GCD, if we do not fully understand the GCD’s concepts, we may create a deadlock in our code. For example, the code below is making a deadlock. 123456789func deadLock() { let myQueue = DispatchQueue(label: \"myLabel\") myQueue.async { myQueue.sync { print(\"Inner block called\") } print(\"Outer block called\") } } First, we create a custom queue with a given label. Then we dispatch asynchronously a block of code calling another block of code synchronously. It is clear that the inner and the outer blocks are executing on the same queue. By default, a custom queue is serial so the inner block will not start before the outer block finishes. On the other hand, the outer block can not finish because the inner block is holding the control of the current thread (Synchronously). Hence, a deadlock occurs.There are two ways to fix the problem. The first one is changing the type of the queue to concurrent. By doing this way, we ensure that the inner block does not have to wait for the outer block has finished so that it can start. 1let myQueue = DispatchQueue(label: \"myLabel\", attributes: .concurrent) The second one is changing the inner block to async. This time, the outer block will not wait for the inner block has completed so that it can start. 123456myQueue.async { myQueue.async { print(\"Inner block called\") } print(\"outer block called\")} There is a recommend on Apple document about Deadlock at Dispatch queues and thread safety chapter&quot;Do not call the dispatch_sync function from a task that is executing on the same queue that you pass to your function call. Doing so will deadlock the queue. If you need to dispatch to the current queue, do so asynchronously using the dispatch_async function.&quot; LivelockThere is another lock concept besides deadlock called Livelock. Unlike deadlock, the livelock does not block the current thread. They’re just unable to make further progress. Or to more accurately, livelock is “a situation in which two or more processes continuously change their states in response to changes in the other process(es) without doing any useful work”.There is a good human example of livelock on StackOverflowA husband and wife are trying to eat soup, but only have one spoon between them. Each spouse is too polite, and will pass the spoon if the other has not yet eaten.There are other types of lock when we work with concurrency like bound resources, mutual exclusion, starvation. Because of the scope of this post, I will not explain all of them here. Please refer to other sources for more details. Important notes On iPhones, discretionary and background operations, including networking, are paused when Low Power Mode is enabled. When using Xcode 9 with iOS 11, a warning will be emitted when a user-interface object is accessed from a non-main thread. The user interactive priority should be rare in your program. If everything is high priority, nothing is. ConclusionIn this post, I showed you some interesting points about GCD in Swift. In next post, we will discuss more about other advanced concepts of concurrent programming like DispatchGroup, Operation Queue, Group Tasks, etc. Then we will implement a tiny project to mix them together.If you have any comments, don’t be hesitate to contact me. References[1] Apple’s documentation: Concurrency Programming Guide[2] iOS 8 Swift Programming Cookbook by O’Reilly, Chap.7: Concurrency and Multitasking.","link":"/2018/01/04/Grand-Central-Dispatch-in-Swift/"},{"title":"Drag and Drop","text":"","link":"/2019/09/02/Drag-and-Drop/"},{"title":"Integrate Google Drive to iOS app","text":"At Fossil, I’ve had the chance to experiment with Google Drive integration, as a cloud bases storage. The main advantage of using Google Drive is to share with other members easily, with a good web-based UI to modify the contents of folders, and it’s free. However, I struggled when trying to make Google Drive work due to lack of documents and articles related to Google Drive APIs, especially in Swift. Additionally, the code and examples on Google’s sites are out of date. Therefore, I decided to write this article with a hope of saving your time when you want to integrate Google Drive to your apps. Let’s get started. Create your app and Google API accessIn order to use Google APIs, firstly we have to go to Google Console Dashboard to create a project. So head to Google cloud console, click the drop-down menu to create a new project.Your Google Drive API is disabled by default when you create new projects. To enable Google Drive API manually, click on “APIs &amp; Services” item on the left bar side, it will lead you to another page where you can enable Google services for your apps.Click “Enable APIs and services” button, then type to search for “Google drive”, next select Google Drive from results, finally click “Enable” to activate the app.That’s all you need to create an app using Google API. Add credential for your iOS appCredentials allow your iOS to access your enabled APIs. Click to “Credentials” button on the left sidebar to add your iOS app. Next, input your app information including your app name and bundle id, please note that you need to type exactly the bundle id, otherwise it will not work.After creating new credential successfully, you should be able to download the plist file that will contain the keys necessary for setting up your Xcode project. Keep this file in a safe place, we will use it in the next step. 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;&lt;plist version=\"1.0\"&gt;&lt;dict&gt; &lt;key&gt;CLIENT_ID&lt;/key&gt; &lt;string&gt;YOUR_CLIENT_ID&lt;/string&gt; &lt;key&gt;REVERSED_CLIENT_ID&lt;/key&gt; &lt;string&gt;YOUR_REVERSED_CLIENT_ID&lt;/string&gt; &lt;key&gt;PLIST_VERSION&lt;/key&gt; &lt;string&gt;1&lt;/string&gt; &lt;key&gt;BUNDLE_ID&lt;/key&gt; &lt;string&gt;com.example&lt;/string&gt;&lt;/dict&gt;&lt;/plist&gt; Project configurationGoogle APIs Client Library is a library written by Google for accessing Google APIs. Go ahead and add the following library to your Pod file. 12pod 'GoogleAPIClientForREST/Drive', '~&gt; 1.2.1'pod 'GoogleSignIn', '~&gt; 4.1.1' You will find YOUR_REVERSED_CLIENT_ID and YOUR_CLIENT_ID in the client configuration plist file that you downloaded previously. Select your target project, go to “Info” tab, add a new item at the “URL Types” section, then input YOUR_REVERSED_CLIENT_ID at the “URL Schemes” box.In case you don’t know what URL Schemes use for, every each item in the URL Schemes section allows you to define a custom URL scheme for your app. For example, your app might let users tapping a custom URL in an email to launch your app in a specified context. By default, Apple supports common schemes associated with system apps like mail, sms, facetime, etc. For more information, please refer to Defining a Custom URL Scheme for Your AppIf you don’t add YOUR_REVERSED_CLIENT_ID as a custom URL scheme, your app will get the following crash when trying to authorize with Google API. So make sure you don’t miss this important step.Next, open the AppDelegate.swift file, add your client id to Google Sign In instance. 1234func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool { GIDSignIn.sharedInstance().clientID = \"YOUR_CLIENT_ID\" return true} Then, open your ViewController where you allow user to sign in with their Google account and implement the two delegate GIDSignInUIDelegate and GIDSignInDelegate from Google Sign in. 123456789101112131415extension ViewController: GIDSignInDelegate { func sign(_ signIn: GIDSignIn!, didSignInFor user: GIDGoogleUser!, withError error: Error!) { if let _ = error { } else { print(\"Authenticate successfully\") } } func sign(_ signIn: GIDSignIn!, didDisconnectWith user: GIDGoogleUser!, withError error: Error!) { print(\"Did disconnect to user\") }}extension ViewController: GIDSignInUIDelegate {} Finally, assign Google sign in delegate to your view controller. 123456private func setupGoogleSignIn() { GIDSignIn.sharedInstance().delegate = self GIDSignIn.sharedInstance().uiDelegate = self GIDSignIn.sharedInstance().scopes = [kGTLRAuthScopeDrive] GIDSignIn.sharedInstance()?.signInSilently()} You might notice the GIDSignIn.sharedInstance().scopes line of code. This line of code defines which permissions the user grants for your app to access their data when authenticating. In this case, we use the kGTLRAuthScopeDrive scope that allows our app to view and manage all the files in the user’s Google Drive, including team drive. The signInSilently method will attempt to sign in a previously authenticated user silently. If you do all the above steps properly, you should be able to authenticate your app with Google API. ![](/Post-Resources/GoogleDrive/GoogleSignIn.png \"Google Sign in\") ![](/Post-Resources/GoogleDrive/GrantPermission.png \"Grant permission\") Common APIsWork with “My Drive”Searching12345678public func search(_ name: String, onCompleted: @escaping (GTLRDrive_File?, Error?) -&gt; ()) { let query = GTLRDriveQuery_FilesList.query() query.pageSize = 1 query.q = \"name contains '\\(name)'\" self.service.executeQuery(query) { (ticket, results, error) in onCompleted((results as? GTLRDrive_FileList)?.files?.first, error) }} Listing12345678 public func listFiles(_ folderID: String, onCompleted: @escaping (GTLRDrive_FileList?, Error?) -&gt; ()) { let query = GTLRDriveQuery_FilesList.query() query.pageSize = 100 query.q = \"'\\(folderID)' in parents and mimeType != 'application/vnd.google-apps.folder'\" self.service.executeQuery(query) { (ticket, result, error) in onCompleted(result as? GTLRDrive_FileList, error) }} Uploading123456789101112131415private func upload(_ folderID: String, fileName: String, data: Data, MIMEType: String, onCompleted: ((String?, Error?) -&gt; ())?) { let file = GTLRDrive_File() file.name = fileName file.parents = [folderID] let params = GTLRUploadParameters(data: data, mimeType: MIMEType) params.shouldUploadWithSingleRequest = true let query = GTLRDriveQuery_FilesCreate.query(withObject: file, uploadParameters: params) query.fields = \"id\" self.service.executeQuery(query, completionHandler: { (ticket, file, error) in onCompleted?((file as? GTLRDrive_File)?.identifier, error) })} Downloading12345678910111213public func download(_ fileItem: GTLRDrive_File, onCompleted: @escaping (Data?, Error?) -&gt; ()) { guard let fileID = fileItem.identifier else { return onCompleted(nil, nil) } self.service.executeQuery(GTLRDriveQuery_FilesGet.queryForMedia(withFileId: fileID)) { (ticket, file, error) in guard let data = (file as? GTLRDataObject)?.data else { return onCompleted(nil, nil) } onCompleted(data, nil) }} Deleting123456789public func delete(_ fileItem: GTLRDrive_File, onCompleted: @escaping ((Error?) -&gt; ())) { guard let fileID = fileItem.identifier else { return onCompleted(nil) } self.service.executeQuery(GTLRDriveQuery_FilesDelete.query(withFileId: fileID)) { (ticket, nilFile, error) in onCompleted(error) }} Work with “Team Drive”The only thing we need to do in order to work with “Team Drive” is to set the corpora param of the query to teamDrive. By default, the user corpora is applied. That means the query only applied to the folders onwed by the user. By setting to teamDrive, we indicate that the query will affect to team drive of the user. We can combine multiple corpora in a single query if you need to do so. Final thoughtsGoogle Drive is an ideal storage to integrate with our applications. In this article, we covered how to config Google Drive API and how to execute common APIs. I hope you learned something today.You can find all the source code demo on my Github 🙂 References[1] Google Developer https://developers.google.com/drive/api/v3/about-sdk","link":"/2019/02/15/Integrate-Google-Drive-to-iOS-app/"},{"title":"Integrate Google Sign In on MacOS App in Swift","text":"As an iOS developer, you might have chances to write applications on Mac os. And sometimes, your applications require users to authenticate before they can use your app. Enabling Google Sign in helps you save a lot of time to implement authentication flow. Unfortunately, it is a lack of documentation on how to integrate Google Sign in on Macos app, particularly in Swift. I once had a chance to implement this feature to my app. Now I want to share with you how we can do it. Let’s get started. Setting upLet’s first create your mac os application, name whatever you like. Then, run pod init command to init the Pod workspace.Next, add the following line to your Pod file. 123456use_frameworks!pod 'GTMAppAuth' # GTMAppAuth is an alternative authorizer to GTMOAuth2, supports for authorizing requests with AppAuth.pod 'SwiftyJSON' # JSON parserpod 'PromiseKit' # Make async requestspod 'Kingfisher' # Cached imagepod 'SnapKit' # Autolayout Then run pod install to download all these dependencies. Get an OAuth client IDBefore getting started to the example, firstly go-ahead to Google Console and create a new project. Then press the “Create credentials” &gt; “OAuth client ID” &gt; “Other” application type &gt; Follow the instructions to get your credentials.After you create the OAuth client ID, take note of the client ID and the client secret, which you will need to configure Google Sign-in in your app. You can optionally download the configuration file containing your project information for future reference. Config projectMake sure that you configure your app to allow incoming and outcoming network by going to Signing &amp; Capabilities &gt; App Sanbox &gt; Check both Incoming Connections &amp; Outcoming Connections. If you do not do that, you will get the following error because your app does not have permission to perform requests. 122019-12-11 22:22:49.472046+0700 GoogleSignInDemo[3955:65750] Metal API Validation Enabled2019-12-11 22:22:51.444494+0700 GoogleSignInDemo[3955:66166] dnssd_clientstub ConnectToServer: connect() failed path:/var/run/mDNSResponder Socket:11 Err:-1 Errno:1 Operation not permitted Next, open the Info.plist and add a new value for CFBundleURLTypes, which reverses DNS notation form of your client ID. Safari will use this DNS notation to open your app after authentication process is performed successfully. 1234567891011&lt;key&gt;CFBundleURLTypes&lt;/key&gt;&lt;array&gt; &lt;dict&gt; &lt;key&gt;CFBundleTypeRole&lt;/key&gt; &lt;string&gt;Editor&lt;/string&gt; &lt;key&gt;CFBundleURLSchemes&lt;/key&gt; &lt;array&gt; &lt;string&gt;com.googleusercontent.apps.REPLACE_BY_YOUR_CLIENT_ID&lt;/string&gt; &lt;/array&gt; &lt;/dict&gt;&lt;/array&gt; Making authorizationLet’s first create our service object, class GoogleSignInService, which handles all requests related to Google Sign in. It also contains all of your project’s credentials. 123456789class GoogleSignInService: NSObject, OIDExternalUserAgent { static let kYourClientNumer = \"REPLACE_BY_YOUR_CLIENT_ID\" static let kIssuer = \"https://accounts.google.com\" static let kClientID = \"\\(Self.kYourClientNumer).apps.googleusercontent.com\" static let kClientSecret = \"REPLACE_BY_YOUR_CLIENT_SECRET\" static let kRedirectURI = \"com.googleusercontent.apps.\\(Self.kYourClientNumer):/oauthredirect\" static let kExampleAuthorizerKey = \"REPLACE_BY_YOUR_AUTHORIZATION_KEY\" // The rest omitted} Discover Google service’s endpoint and define a request. 1234567891011OIDAuthorizationService.discoverConfiguration(forIssuer: URL(string: Self.kIssuer)!) { // The rest omitted let request = OIDAuthorizationRequest(configuration: config, clientId: Self.kClientID, clientSecret: Self.kClientSecret, scopes: [OIDScopeOpenID, OIDScopeProfile, OIDScopeEmail], redirectURL: URL(string: Self.kRedirectURI)!, responseType: OIDResponseTypeCode, additionalParameters: nil) // The rest omitted} Take a look at the scopes param, this param defines which user’s info your app can access to. Google Sign In offers 5 different scopes, including: NSString *const OIDScopeOpenID = @”openid”; NSString *const OIDScopeProfile = @”profile”; NSString *const OIDScopeEmail = @”email”; NSString *const OIDScopeAddress = @”address”; NSString *const OIDScopePhone = @”phone”; You can select which ones fit your app’s requirements.Finally, start the authentication process. 1234567OIDAuthState.authState(byPresenting: request, externalUserAgent: self, callback: { (state, error) in guard error == nil else { seal.reject(error!) return } // You got the OIDAuthState object here}) After the authentication process performs successfully, you will get an OIDAuthState object which will be used as a param to init the GTMAppAuthFetcherAuthorization object.Normally, you should save this GTMAppAuthFetcherAuthorization object to a key chain and re-use it for the next REST API calls. 123456private func saveState() { // The rest omitted if auth.canAuthorize() { GTMAppAuthFetcherAuthorization.save(auth, toKeychainForName: Self.kExampleAuthorizerKey) }} Making requestsAfter saving the service object to the key chain, you now can retrieve it to make any requests. I will make a request to fetch the current user profile. 12345678910111213func loadProfile() -&gt; Promise&lt;GoogleSignInProfile&gt; { return Promise { (seal) in // The rest omitted if let url = URL(string: \"https://www.googleapis.com/oauth2/v3/userinfo\") { let service = GTMSessionFetcherService() service.authorizer = auth service.fetcher(with: url).beginFetch { (data, error) in // Process the data here // data = [\"locale\", \"family_name\", \"given_name\", \"picture\", \"sub\", \"name\", emai] } } }} Troubleshoot After logging in, if your Safari can not redirect back to your app. Just clean up your project (Shift + Cmd + K) then run again. Other web browsers (Chrome, Firefox, etc) can not open your app so that make sure you launch the sign-in web on Safari.1NSWorkspace.shared.open([url], withAppBundleIdentifier: \"com.apple.Safari\", options: .default, additionalEventParamDescriptor: nil, launchIdentifiers: nil) { Final thoughtsYou can find the completed demo hereNow you can use Google Sign in inside your macOS to reduce your efforts for authentication. To get the full source code, please download via the Github link.In case you have any problems do not hesitate to contact me.","link":"/2019/12/11/Integrate-Google-Sign-In-on-MacOS-App-in-Swift/"},{"title":"Play with Android Things","text":"","link":"/2019/02/07/Play-with-Android-Things/"},{"title":"Protobuf In Practice","text":"I have worked on Bluetooth products, including wearable devices and smart locks, in many years. Facilitating the transfer of messages between system components is a crucial aspect due to differences in programming languages, the necessity for consistency, and limitations on data transfer size. To address these challenges, we utilize Protocol Buffers.Protocol Buffers, also known as Protobuf, is a free and open-source cross-platform data format used to serialize structured data developed by Google. It is designed to be efficient, extensible, and user-friendly. In this tutorial, we will cover the basics of creating a simple Protocol Buffers message, defining a schema, and generating code in various programming languages. InstallationTo install the protobuf compiler, follow the instructions outlined in protobuf-compiler-installation.The basic usage can be summarized by the image below. Steps to set up: Install the protobuf compiler. On Mac, use brew: brew install protobuf Validate if the installation completed successfully: protoc --version. Installing the Code Generator Plugin: Protobuf supports several different programming languages. You need to find and install the code generator for the specific language depending on which programming languages are used in your project. For example, for Swift, use swift-protobuf: brew install swift-protobuf. For JavaScript, use npm install -g protoc-gen-js. Define your schemes: Visit Programming Guides to learn how to use the protocol buffer language to structure your protocol buffer data example.proto12345message Person { optional string name = 1; optional int32 id = 2; optional string email = 3;} Compile .proto files to generate code for specific languages. 1234nguyenuy@192  ~/Desktop/protobuf  protoc --js_out=. example.protonguyenuy@192  ~/Desktop/protobuf  protoc --java_out=. example.protonguyenuy@192  ~/Desktop/protobuf  protoc --cpp_out=. example.protonguyenuy@192  ~/Desktop/protobuf  protoc --dart_out=. example.proto Distribute (import) the generated files into your projects. Install the runtime plugin. For instance, in an iOS project, include the SwiftProtobuf framework in the Podfile. For Flutter projects, add protobuf to the pubspec.yaml file. For ReactJS projects, include google-protobuf in the package.json file. Implement serialization and deserialization:Example in Python 12345678910111213person = example_pb2.Person()# Set valuesperson.name = \"Uy Nguyen\"person.id = 1person.email = \"uynguyen.itus@gmail.com\"# Serialize the message to bytesserialized_data = person.SerializeToString()# Parse the bytes back into a messagenew_person = example_pb2.Person()new_person.ParseFromString(serialized_data) Example in Java 1234567891011Person person = Person.newBuilder() .setName(\"Uy Nguyen\") .setId(1) .setEmail(\"uynguyen@gmail.com\") .build();// Serialize the message to bytesbyte[] serializedData = person.toByteArray();// Parse the bytes back into a messagePerson newPerson = Person.parseFrom(serializedData); Example in Swift 12345678910var p = Person()p.id = 1p.email = \"uynguyen.itus@gmail.com\"p.name = \"Uy Nguyen\"// Serialize the message to byteslet data = try? p.serializedData()// Parse the bytes back into a messagelet converted = try? Person(serializedData: data!) Below is how the generated files look in different languages. Pros Binary Format: Protobuf uses a binary format for serialization, which is more compact than JSON text-based format. This results in smaller message sizes, making it more efficient in terms of both bandwidth and storage. Performance: Due to its binary format and efficient encoding, Protobuf serialization and deserialization processes are generally faster than JSON. This can be particularly important in scenarios with high-throughput or low-latency requirements, such as systems applying BLE. Code Generation: Protobuf relies on code generation to create data classes in various programming languages based on the defined schema. This can lead to type-safe and efficient code, reducing the chances of runtime errors related to data structure mismatches. Support for Multiple Languages: Protobuf supports code generation in a variety of programming languages, making it suitable for projects with different technologies. This allows different services written in different languages to easily communicate using the same data structures. Cons Human Readability: Protobuf binary format is not human-readable, which can make debugging and troubleshooting more challenging compared to JSON. JSON plain text format allows developers to inspect the data easily. Debugging Complexity: Due to the binary nature of protobuf, debugging can be more complex when compared to JSON. Specialized tools are often needed to inspect the content of protobuf encoded messages. Less Common in Web Technologies: JSON is more prevalent in web development and is natively supported by many web APIs. If interoperability with web technologies is a top priority, JSON might be a more natural choice. Complexity in Nested Structures: Dealing with nested structures in protobuf messages can sometimes be less intuitive than in JSON. Care must be taken when designing nested structures to avoid unnecessary complexity. SummaryIn summary, while protobuf offers significant advantages in terms of efficiency and performance, its adoption should be considered based on the specific requirements and constraints of the project. It’s essential to consider the pros and cons and choose the serialization format that best aligns with your project’s goals and constraints. Ref Protocol Buffers Documentation","link":"/2024/01/12/Protobuf/"},{"title":"Memory leak","text":"As a Software Engineer, you definitely have heard about the Memory leak concept. Memory leak is a situation where blocks of memory are located by the program remain in the memory despise they are no longer referenced. Leaks waste space by filling up pages of memory with inaccessible data. As a result, the size of memory using in your apps keep increasing, affect the user experiences and the performance of your app. Even worse, your app will be crashed randomly because a process will be terminated by the system if it consumes too much memory.In this topic, we will discuss how the memory is managed in iOS and how to use the memory efficiently. Read on. Automatic Reference CountingARCMost of the modern programming languages (such as Java, C#, Go, etc.) have a built-in process which automatically finds unused objects and deletes them to free up memory. The primary purpose of this technology is to reduce memory leak and let programmers focus on their business logic without caring too much about memory management.As a high-level programming language, Swift also has Automatic Reference Counting (ARC) to manage memory using in our apps. How ARC worksWhenever we create a new instance of a class, ARC will allocate a space of memory to store information about that instance. This memory holds information about the type of the instance, any stored properties associated with that instance. Especially, this memory holds the information of how many properties, constants, and variables are currently referring to that instance. ARC will never deallocate that instance as long as at least one active reference to that instance still exists.Once the number of objects referring to that instance comes to zero, ARC will deallocate that instance and free the memory held by that instance.By applying this technique, Apple ensures that class instances do not keep holding space in memory when they are no longer needed, generally avoids the problem of memory leaks. Memory leakIn most cases, ARC does its job well. We don’t usually worry about memory management. However, leaks still happen in iOS by accident. This is when two objects hold strong references to one another so that each object keeps the other one from being deallocated. Let’s take an example, there are two classed named Person and Car. 1234567891011121314151617181920212223242526272829class Person { let name: String var car: Car? lazy var greeting: () -&gt; String = { return \"Hello, my name is \\(self.name). I have \\(self.car?.name ?? \"no cars\")\" } init(name: String) { self.name = name } deinit { print(\"Person \\(self.name) is being destroyed.\") }}class Car { let name: String var owner: Person? init(name: String) { self.name = name } deinit { print(\"car \\(self.name) is being destroyed.\") }} Every Person instance has a name property of type String and an optional Car property that initially nil because a person may not always have a car.Likewise, every Car instance has a name property of type String and an optional Person property that initially nil because a car may not always have an owner.Next, let’s define two variables called Foo and BMW of Person and Car classes, respectively. Now, we link the two instances together so that the person has a car, and the car has an owner. 123456# Main blockvar foo: Person? = Person(name: \"Foo\")var car: Car? = Car(name: \"BMW\")foo!.car = carseat!.owner = fooprint(foo!.greeting()) The next code snippet will release these two instances by setting them to nil. 12foo = nilseat = nil As you might know, once setting a variable to nil, it means there are no references to this class instance, ARC will deallocate the space of this object to free up memory. As an expectation, we should see the deinit methods of Student and Car are called. However, those two methods are never called, there are no any messages, indicates objects are released, printed to the console. This means that the foo and the car are never deinitialized.The reason why these two objects are not released because these two objects hold strong references to one another so that each object keeps the other one from being deallocated, resulting in they are never deinitialized. This situation is called strong reference cycle in programming. Break strong reference cyclesThere are two ways to break strong reference cycles in Swift. Depending on which situation we are facing, we will choose a sensible approach to solve the problem. Both methods let an instance reference to one another without keeping a strong hold on it. Weak referenceWeak references should be used when the object it refers to might become nil in the future. As such, the captured objects are optional types.In the example above, it’s appropriate for a car to be able to have no owner at some point in its lifetime, and so a weak reference is an appropriate way to break the reference cycle in this case.Let’s make some changes to make the magic happen 123456789101112class Car { let name: String weak var owner: Person? init(name: String) { self.name = name } deinit { print(\"Car \\(self.name) is being destroyed.\") }} Let’s run the code, there are still no messages printed to the console, it means the two objects are not released. What the heck!Let’s trace back to our code to check what’s wrong with it.Do you see that? There is another problem with the code: The closure. Unowned referenceIn the above example, the Person class not only creates a strong reference cycle with the Car class but also between itself and the greeting closure. Here is how the cycle looks:To resolve this problem, we will use “Unowned reference”. Unowned references should be used when the closure and the object it refers to will always have the same lifetime as one another. This means the two objects will be deallocated at the same time. As a result, an unowned reference can never become nil.Let’s make some changes to make the magic happen (Again). 12345678910111213141516class Person { let name: String var car: Car? lazy var greeting: () -&gt; String = { [unowned self] in return \"Hello, my name is \\(self.name). I have \\(self.car?.name ?? \"no cars\")\" } init(name: String) { self.name = name } deinit { print(\"Person \\(self.name) is being destroyed.\") }} Let’s run the code, you should see the following messages printed to the console. 123Hello, my name is Foo. I have BMWPerson Foo is being destroyed.Car BMW is being destroyed. The two objects foo and car have been released and the leak has been resolved.Here is how the cycle looks so far: Tools to detect strong reference cyclesEncountering memory leaks is usually a nightmare for an iOS developer because it is too difficult to figure out the root cause. Luckily, we have multiple tools are supported by Apple to track down memory leaks. Allocations and Leaks InstrumentFrom the toolbar of XCode, choose Product &gt; Profile &gt; Allocations to start a new instrument profile for tracking memory allocations. Allocations instrument tracks all of the objects that app allocates during its lifetime.Now, press the red button on the top left in the panel to start recording.There is so many information related to memory mapping showed in the tool. To identify memory leak, we just need to focus on two main columns: #Persident and #Transident. Persident column: keeps a count of the number of objects of each type that currently exist in memory. Transident column: shows the number of objects that have existed but have since been deallocated. As you can see, the #Persident column keep increasing whenever you press to the “Create a leak” button to execute the main block. When you see something like this happend to your app, it’s time to revise your classes to find out where the leak is. Debug Memory GraphDebug Memory Graph is a tool first introduced in Xcode 8. It is able to grab leaks such as retain cycles.From the debug navigator, click debug mode &gt; View Memory Graph Hierarchy to visualize the memory mappingYou should see somethings like this.From the visualization, we can see there are two strong reference cycles come from the Person-Car relationship and from inside the Person itself. ConclusionEvery iOS developer should have a deep understanding of how ARC works to avoid memory leaks. Undeniably, a good management of memory contributes to the app performance and the user experience. Hopefully, all of the concepts we walk through in this article will help you build apps that have the best performance. Feel free to leave your comments here. References[1] The Swift Programming Language (Swift 4.0.3), App Inc., Automatic Reference Counting chapter.","link":"/2018/09/12/Memory-leak/"},{"title":"React Native In My Real World","text":"React Native was introduced in January of 2015 at React.js Con: The first public preview. In March of 2015, React Native is open and available on Github. After releasing, React Native quickly becomes popular and is constantly updated by thousands of developers in the world. Currently, React Native is one of the most stars repositories on Github. ThreadsPerformanceNative modules123$ react-native run-ios --simulator 'iPad Pro (9.7 inch)'$ react-native run-ios --device 'qa'$ react-native run-ios --configuration Release --device 'qa' 123456789#import &lt;React/RCTBridgeModule.h&gt;@interface RCT_EXTERN_MODULE(SDKWrapper, NSObject)RCT_EXTERN_METHOD(supportedEvents)RCT_EXTERN_METHOD(startScanning)RCT_EXTERN_METHOD(stopScanning)RCT_EXTERN_METHOD(playAnimation)RCT_EXTERN_METHOD(connectToDevice:(NSString *)serialNumber:(RCTPromiseResolveBlock)resolve:(RCTPromiseRejectBlock)reject) //PromiseRCT_EXTERN_METHOD(disConnectToDevice:(RCTPromiseResolveBlock)resolve:(RCTPromiseRejectBlock)reject) //Promise@end 123456789101112public class SDKWrapper extends ReactContextBaseJavaModule { public SDKWrapper(ReactApplicationContext reactContext) { super(reactContext); } @Override public String getName() { return \"SDKWrapper\"; } @ReactMethod public void startScanning() {. . .}} 123456import {NativeModules} from 'react-native'; const {SDKWrapper} = NativeModules; ....SDKWrapper.doSomething();SDKWrapper.saySomething();.... Pros and consPros Native performance Learn once, run everywhere Flex box Hot reloading Platform detection in code Cons Not stable, hard to keep up Lack of documentation Single dedicated device thread Calling callback Conclusion","link":"/2017/12/01/React-Native-In-My-Real-World/"},{"title":"Remote Notification","text":"Push notification allows your app to reach users more frequently, and can also perform some tasks. In this tutorial, we will learn how to config apps to get remote notifications, display contents and then perform some actions when the user presses in.Let’s get started. APNsAPNs, which stands for Apple Push Notification service, is a service that delivers messages to your applications. The notification information sent can include badges, sounds, custom content, or custom text alerts. Note that you need a paid developer account so that you can configure your app with the Push Notification capability. You also need a physical device for testing if you want to launch remote notifications as push notifications are not available in the simulator. You only can simulate notifications on simulators. ConfigurationFirstly, you need to add the push notifications entitlement to your project,Head over the Project Setting &gt; Signing Capabilities &gt; + Capability &gt; Add Push Notification If you want to send notifications to real devices, you need to do some extra steps to have a notification key: Sign in to Apple developer Under the Keys section &gt; Add new keys &gt; Enter your key name &gt; Select Apple Push Notifications service (APNs) &gt; Continue. Download the key and store it to any location you want to save this key. Notice the file name of the key file has a pattern AuthKey_[Key ID].p8 Request user permissionsNext, the app needs to ask the user to get permission to show notifications.Open the AppDelegate.swift and add the following code 123456789101112131415161718192021222324func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool { // The rest omitted self.registerPushNotifications() ...}func registerPushNotifications() { UNUserNotificationCenter.current() .requestAuthorization(options: [.alert, .sound, .badge]) { granted, error in guard granted else { return } // If the user allows showing notification, then register the device to receive a push notification self.registerForRemoteNotification() }}func registerForRemoteNotification() { UNUserNotificationCenter.current().getNotificationSettings { settings in guard settings.authorizationStatus == .authorized else { return } DispatchQueue.main.async { UIApplication.shared.registerForRemoteNotifications() } }} If the process complete successfully, the didRegisterForRemoteNotificationsWithDeviceToken: callback will be called including your device token (A unique value to identify your device, note that it is different every time you re-install the app).If an error occurs, the didFailToRegisterForRemoteNotificationsWithError: will be triggered. 12345678func application(_ application: UIApplication, didRegisterForRemoteNotificationsWithDeviceToken deviceToken: Data) { print(\"Did register remote notification successfully \\(deviceToken.hexadecimalString)\")}func application(_ application: UIApplication, didFailToRegisterForRemoteNotificationsWithError error: Error) { print(\"Did failed register remote notification \\(error.localizedDescription)\") // e.g Did failed register remote notification no valid “aps-environment” entitlement string found for application} Notice the Alert, sound, and badge is the common combination when requesting authorization.There are other options you can find on Apple doc.Another warning is that if you run your app in a simulator, you will get the didFailToRegisterForRemoteNotificationsWithError event as remote notification are not supported on simulators. Handle notifications while the app is in foregroundAfter registering to remote notification successfully, if you want to handle notifications while your app is in the foreground, you need to implement the userNotificationCenter:willPresent:withCompletionHandler in your class. 1234public func userNotificationCenter(_ center: UNUserNotificationCenter, willPresent notification: UNNotification, withCompletionHandler completionHandler: @escaping (UNNotificationPresentationOptions) -&gt; Void) { ... completionHandler([.alert, .sound, .badge])} If you do not implement this function, notifications will not show if your app is in the foreground. It’s time to send notificationThere are 2 ways to test your implementation. If you don’t have a physical device, don’t worry, you still can simulate notifications in a simple way, or you can send real notifications to real devices. Simulate APNsCreate a file with ext .apns. eg. SimulateNoti.apns, then copy your content to this file 1234567891011{ \"Simulator Target Bundle\": \"YOUR_APP_BUNDLE_ID\", &lt;--- CHANGE TO YOUR APP BUNDLE ID \"aps\": { \"alert\": { \"title\" : \"Your title\", \"subtitle\" : \"Your subtitle\", \"body\" : \"Your body\" }, \"sound\": \"default\" }} Dragging and dropping this onto the target simulator will present the notification Push to real devicesFirst, you need a remote notification client tool that helps you to push a notification. A great tool to test is Push notification tester. Let’s navigate to this website to download and launch the app. After launching the app successfully, Switch to TOKEN tab in Authentication section. Press SELECT P8 and select your P8 file which is downloaded from the previous step, then Fill in the rest information KEY ID, TEAM ID. The KEY ID is a part of the P8 file name AuthKey_[Key ID].p8. For the TEAM ID, you can find it on your membership page. In Body section, fill in your app bundle Id (e.g com.example.yourapp) and your device token which is generated from didRegisterForRemoteNotificationsWithDeviceToken: callback. Compose your content. Here is a common body for push notification.e.g 12345678910{ \"aps\": { \"alert\": { \"title\" : \"Your title\", \"subtitle\" : \"Your subtitle\", \"body\" : \"Your body\" }, \"sound\": \"default\" }} For all available options in a notification, please refer to Apple doc: generating_a_remote_notification Press the Send button to deliver your notification to the selected device. A message will be appeared on the top of the button to show the result. Silent notificationFrom my perspective, the most interesting feature of Push notification is “Silent notification”, which can wake your app up to perform some tasks while your app is in the background, even if your app was terminated by the user. Many engineers out there are finding a way to keep their app lives in the background as many as they can. There are several ways to achieve it by using restoration and preservation, core location, iBeacon. Silent push notification is one among of them. I will have another post talking about silent notification and my experiment so we will have more details and info. To send a silent notification, simply change the JSON content to 12345{ \"aps\": { \"content-available\": 1 }} After pressing the Send button, there is no notification showing on your app. Final thoughtBy using push notifications wisely, you can engage users coming back to your app again. However, if you overdo the notifications, it can lead to negative effects such as users turn off permissions to your app or rate your app 1* with complaints on the store (Same as our story in the past :)).Notifications not only help to deliver your messages to users but also can be used for other advanced purposes like wake your app up by using silent notifications. In the next post, we will have a deep look at this amazing feature.If you have any doubts or comments, let me know.Happy sharing! Refs Apple doc: Generating a remote notification Raywenderlich: Push notification tutorial","link":"/2021/04/08/Remote-Notification/"},{"title":"Review book: Building Applications With iBeacon","text":"In the previous post, I basically give you a quick look at iBeacon - A Bluetooth protocol built on top of BLE by Apple, and made a simple demo of how iBeacon can wake up an application after being terminated by the user. However, I did not mention other foundation concepts in Beacon, it also did not give you a deep look at the advantages and disadvantages of this powerful technology.Today, I would like to introduce you to a good book giving a solid knowledge in Beacon field, especially iBeacon: Building Applications With iBeacon published by O’Reilly.After reading this book, I ensure that you will get a good knowledge in iBeacon field and your mind will be more open to the next coming up ideas.Let’s drive-in! Main contentThe book mainly focuses on developers who are looking for an efficient way to integrate beacon protocol to their applications. To use the book efficiently, I recommend you should have some BLE background knowledge as iBeacon is built on top of BLE.In the beginning, the book describes a brief history of proximity technologies in particular. It also explains why and when to use in some specified circumstances.The two key main why using iBeacon are, first and foremost, GPS technologies struggle to do better than a few meters, and GPS is often limited indoors. iBeacons can enable a determination within centimeters. The second one is iBeacons offer high precision micro-location, along with the ability to act on what a mobile device is near. No other technology yet offers that combination.To convince the reader, the book compares GPS versus Beacon, in other word location versus proximity; giving some limitations of current GPS technology, the writer makes some area in which Beacon is far superior to GPS.Next, the book explains how Beacon protocol works under the hook; introduces you to the foundational terms, and how they interact with each other.Finally, in some chapters, the book guides you on how to set up your own beacons on Mac OS, mobile devices, or tiny computers such as Ras. Pi or Arduino. Key concepts The relationship between iBeacons, generic beacons, BLE beacons, and BLE devices is described as below iBeacons are a subset of the BLE beacon specification, All iBeacons are BLE beacons, and all BLE beacons are BLE devices. However, there are beacons that are not Bluetooth-based, and there are BLE devices that do not beacon. An iBeacon needs to be configured with its identifying numerical tuple (UUID, major number, and minor number).Beacon identifier = UUID + Major + Minor. In Core Location, a region is a space in which a specified combination of UUID, major number, and minor number are received. Core Location supports three types of filtering a region: UUID only: any installed iBeacon that matches the uuid. UUID plus major number: Like the UUID-only option, it is likely to match several iBeacons, most likely installed at one particular location. UUID plus major and minor numbers: This option will match only one specific iBeacon. The following code illustrates how to define those three regions in Swift, respectively.123let region1 = CLBeaconRegion(uuid: \"uuid1\", identifier: \"Your region's name 1\")let region2 = CLBeaconRegion(proximityUUID: \"uuid2\", major: 1, identifier: \"Your region's name 2\")let region3 = CLBeaconRegion(proximityUUID: \"uuid3\", major: 1, minor: 0, identifier: \"Your region's name 3\") iOS and iBeacon: Apple provides two main actions when working with iBeaconMonitoringMonitoring provides a capability of subscription on the appearance of a region, which is combined with one or more beacons.An event in and out will be fired when a device enters or exits a region, respectively. Performed in both the foreground and the background on iOS, is used to determine when a device has entered or left an iBeacon’s coverage area. One of the most benefits of using beacon is regions are tracked by the operating system, not the application. Even when applications are not running (terminated by the OS or force stop by the user), the OS can relaunch the app to handle the events. After bringing back to the background, the app has a few seconds to execute its tasks (Around 10s). The location manager defines a method for didEnterRegion, which is called when a device crosses the boundary to enter a region The location manager defines a method for didExitRegion, which is called when a device crosses the boundary to leave a region. Monitoring limitation iOS can only monitor for up to 20 regions in one single app as describes in Apple documentation Regions are a shared system resource, and the total number of regions available system-wide is limited. For this reason, Core Location limits to 20 the number of regions that may be simultaneously monitored by a single app” Apple doc. The system also takes some time to trigger the exit event, in practice it is around 30 ~ 40s. RangingUses its transmissions to estimate the distance from a mobile device to a beacon. A common use of ranging operations is to determine which iBeacon is closest to this area.The location manager will trigger the didRangeBeacons method after ranging successfully, a list of iBeacons that have ranging data will be passed to the delegated method, along with the region in which they were detected. It also provides the received signal strength indicator (RSSI) to estimate a range in meters (It is a property of the CLBeacon object). Ranging limitation: One main downside of ranging operations requires much more activity in the Bluetooth hardware and consume significant power, because the Bluetooth interface is much more active when ranging What I like I never thought iBeacon topic would be written as a whole book but the author did it very well: The book describes iBeacon in a deep explanation. Make clear of foundational terms that are commonly used in beacon technology. Analyses the pros and cons of iBeacon with examples. Introduce other applications of beacon that I never thought about before, which opens my mind a lot: Indoor Location and Proximity: Map replacement, transit assistance, indoor direction finding, where is my car?, museum guides, retail store enhancement. Proximity-Triggered Actions: Mobile advertisements, ticket validation, treasure hunt, patient information integration. Queue management: Queue measurement, restaurant table pager, transaction completion in retail. Easy to understand: the content is well-organized, it’s easy to follow the content flow. What I dislikeThere is nothing to complain about the book, from content to form. GenerallyMany technologies exist to help phones interact with the world around them. This book introduces you to iBeacons, a Bluetooth technology that allows a device to discover nearby subjects with relatively high accuracy. There is no doubt that the applications of beacon are increasingly widely applied in many fields, especially in marketing and advertising.From my point of view, you should read the book so that you can unlock your mind about iBeacon. Maybe your next startup is built on top of Beacon, who knows?In the next tutorial, I will take you into practice with iBeacon on iOS, also will introduce you to some techniques to deal with iBeacon in deep analysis.If you have any questions or comments on this post, feel free to contact me!","link":"/2020/06/14/Review-book-Building-Applications-With-iBeacon/"},{"title":"Review book: RxSwift Reactive Programming with Swift","text":"In the ever-evolving world of iOS development, mastering reactive programming can set you apart as a developer. One of the best resources to dive into reactive programming with Swift is the book “RxSwift: Reactive Programming with Swift.” This comprehensive guide provides everything you need to understand and leverage RxSwift in your applications. Let’s explore what makes this book an essential read for Swift developers. What is Reactive Programming?Reactive programming is a paradigm that allows you to work with asynchronous data streams and events in a declarative manner. Instead of manually managing callbacks and state changes, reactive programming enables you to declare how data should flow and respond to events. This results in cleaner, more maintainable code, especially for complex applications. Getting Started with RxSwiftThe book starts with the fundamentals of reactive programming, introducing core concepts such as Observables, Subscribers, and the Observer Pattern. It guides you through setting up RxSwift in your project using popular dependency managers like CocoaPods and Swift Package Manager. Core ConceptsThe book delves deeply into RxSwift’s core concepts: Observables and Observers: Learn how Observables emit items and how Observers subscribe to these streams. This is the backbone of reactive programming. Operators: RxSwift provides a rich set of operators for transforming and combining streams. The book covers various operators, including: Creation Operators: create, just, from Transformation Operators: map, flatMap, concatMap Filtering Operators: filter, distinctUntilChanged, throttle Combination Operators: merge, combineLatest, zip Subjects: Understand different types of Subjects such as PublishSubject, BehaviorSubject, ReplaySubject, and AsyncSubject and their use cases. Advanced Topics and Best Practices Once you’re comfortable with the basics, the book introduces more advanced topics: Schedulers: Manage concurrency and thread management with RxSwift’s schedulers, including MainScheduler and ConcurrentDispatchQueueScheduler. Error Handling: Discover strategies for handling errors within reactive streams using operators like catchError and retry. Memory Management: Learn best practices for managing subscriptions and avoiding memory leaks with tools like DisposeBag. Integrating RxSwift with UIKit: One of the strengths of RxSwift is its ability to integrate seamlessly with UIKit. The book demonstrates how to bind RxSwift Observables to UIKit components such as UITableView and UICollectionView. It also covers handling user inputs reactively, making your UI code more responsive and easier to manage. Testing and Debugging: Testing and debugging reactive code can be challenging. “RxSwift: Reactive Programming with Swift” provides practical advice on writing unit tests for RxSwift code and using tools like TestScheduler. It also offers tips for debugging reactive streams, helping you ensure your applications run smoothly. Real-World Applications: The book is filled with real-world examples and case studies. You’ll see how RxSwift can be applied to practical problems like network requests, form validation, and managing complex UI interactions. These examples help solidify your understanding and show how to use RxSwift effectively in your projects. Pros Clear Explanations: The book is praised for its clear and structured explanations, making complex reactive programming concepts more accessible. Practical Examples: It provides a range of practical examples that help in understanding how to use RxSwift effectively. Comprehensive Coverage: Covers both basic and advanced topics, catering to readers with varying levels of experience. Cons Swift Version: Depending on the publication date, some content might be based on older versions of Swift or RxSwift, which might require some adjustments if you’re using the latest versions. Depth of Coverage: Some readers might find that while the book covers a lot of ground, certain advanced topics might require additional resources to fully master. ConclusionThis is an invaluable resource for iOS developers looking to master reactive programming. With its clear explanations, practical examples, and comprehensive coverage of both basic and advanced topics, it’s a must-read for anyone serious about using RxSwift in their applications. Whether you’re new to reactive programming or looking to deepen your knowledge, this book will guide you every step of the way.","link":"/2020/09/26/Review-book-RxSwift-Reactive-Programming-with-Swift/"},{"title":"Review Book: Clean Code","text":"This is a book I have been gifted a long time ago from an old colleague, also he is one of my close friends. This is one of the software books that I like the most but have no chance to buy when I was a student. IntroductionAbout the author, Robert C. Martin, he is considered one of the oldest engineers in the software industry. He has many years of experience working in the software field from various positions, from a developer, manager, to CEO. He is best known for writing software guides that describe software principles, software patterns, and practices of software. He has published many books like Clean Coder, Clean Code, Clean Architecture, etc. Clean Code is one of the software books that many software engineers in the world encourage reading.The author said that *”Over time the mess becomes so big and so deep and so tall, they can not clean it up”*. We need to read, think a lot before writing code. We should avoid writing the code in a hurry. Hurry to write the lousy code will lead to spending more time later for maintaining. Clean Code focuses on the technical aspects: instructing the programmer how to organize the code and write clean code. You won’t be learning any new frameworks, but it will provide you with a fundamental set of coding style rules. It’s worth reading the book. The book contentsThe contents of the book are divided into three parts: The first chapters will explain the principles, patterns, and practices of writing clean code. The second part consists of many case studies, each case study is an exercise in transforming the code that has some problems into code that has fewer problems. The last part is the play-off. Why clean code?Bjarne Stroustrup (Inventor of C++): Elegant, Efficiency.Grady Booch (Author of Object Oriented Analysis): Readability.David Thomas (Founder of OTI): Easy for other people to enhance it.Warn Cunningham (Inventor of Wiki): Make the language look simple.Me: To be able to remember what you write in a month ago. Clean code evaluation criteriaGeneral Don’t repeat yourself: Duplication may be the root of all evil in software. Many principles and practices have been created for the purpose of controlling or eliminating it. Sometimes we can use Template method pattern to remove higher-level duplication. Naming variables, methods, arguments, classes, files The name of a variable, function or class should answer the question why it exists, what it does and how it is used. Use searchable names. Classes and objects should have noun or noun phrase names. Methods should be a verb or verb phrase. Inconsistency: Be careful with the conventions you choose, and once chosen, continue to follow them. Comments Comments should say things that the code can not say for itself: Explain the idea in code, if it can not, then write comments. Comments should be reserved for technical notes about the code and design. Use correct grammar and punctuation. Don’t comment-out code, delete it. Functions Functions should be small: Fewer than 100 lines. It makes the function easier to read and understand. Functions should do only one thing. Functions should have a small number of arguments (Fewer than 4 arguments). Don’t pass boolean values as arguments. Functions that are never called should be deleted. Separate error processing from normal processing. Encapsulate conditionals. Error handling Error handling is important, but if it obscures logic, it’s wrong. Don’t return Null: Consider throwing an exception or returning a SPECIAL CASE object instead. If you code this way, you will minimize the chance of NullPointerException and your code will be cleaner. Don’t pass Null as arguments. Boundaries Wrapping third-party APIs: Minimize your dependency upon it. When there are new releases of the third-party package, we should run the test to see whether there are behavioral differences. Avoid letting too much of our code know about the third-party particulars: Let’s use an Adapter to deal with it. Classes A class should be small: We measure it by responsibilities. (We know it as SRP principle) A code should be placed where a reader would naturally expect it to be. (Where should be the PI constant go? Should it be in the Match class? Or maybe in the Circle class?). Be aware when creating static methods. A static method does not operate on a single instance. All the data that method uses come from its arguments, and not from any instances of this class. Also, make sure that there is no chance that you want it to behave polymorphically. Concurrency There are some basic definitions we should know when we talk about concurrency and threads: Bound resources, mutual exclusion, starvation, deadlock, and livelock. Concurrency does not always improve performance. It sometimes incurs some overhead and bugs come from it are not usually repeatable. Limit the access of the data that is shared between more than two threads. Use copies of data if there is a chance. Keep the synchronized sections as small as possible because Locks create delays and add overhead. They are expensive. Multithreaded code behaves differently in different environments: Run tests in every potential deployment environment. What I like The knowledge in this book is useful. It totally could be applied to reality. After reading the book, my coding style has changed a lot. The book is easy to understand and follow. You will read a lot of code, you will have challenges to think about what’s right about that code and what’s wrong with it. After each chapter, the author summarizes the main ideas. It helps me remember the main points longer. What I dislike The author uses Java code as examples in the book. Sometimes to understand the author’s ideas we have to find out more about Java concepts. (Spring framework, JUnit framework, type of exceptions, etc.) The author’s ideas are duplicated in some chapters. GenerallyOf course, in the scope of the article, I can not fully describe the ideas of ​​the author. This is a good book that I recommend, especially for junior developers who recently graduated. Since at the school, teachers may not teach us how a code is called clean, your coding styles are not evaluated. In fact, Your code can run properly but is not clean.If you can afford to buy this book so that you can refer to when you need, it will be very useful.“You are reading this book for two reasons. First, you are a programmer. Second, you want to be a better programmer.”","link":"/2017/10/20/Review-Book-Clean-Code/"},{"title":"Play Central And Peripheral Roles With CoreBluetooth","text":"IntroductionAs I mentioned in the previous post, CoreBluetooth allows us to create applications that can communicate with BLE devices such as heart rate monitors, body sensors, trackers, or hybrid devices.There are two roles to play in the CoreBluetooth concepts: Central and peripheral. Central: Obtain data from peripherals. Peripheral: Publish data to be accessed by a central. We can make a Bluetooth device plays as a peripheral from either firmware-side or software-side. In this post, I will show you how to create a peripheral by using our own identifiers. Also using another device, as a central, to connect and explore our services. Let’s get it started. Set up a PeripheralTo create a service, you need to have a unique identifier called UUID. A standard service has a 16-bit UUID and a custom service has a 128-bit UUID. Go ahead and type the following command to generate a unique uuid from your terminal. 1$ uuidgen As you can see, the command returns an uuid in hexa format (128 bit): A56E51F3-AFFE-4E14-87A2-54927B22354C. We will use this string to set up our own service. 123456789101112131415161718192021class ViewController: UIViewController, CBPeripheralManagerDelegate { let kServiceUUID = \"A56E51F3-AFFE-4E14-87A2-54927B22354C\" // Other properties ... override func viewDidAppear(_ animated: Bool) { super.viewDidAppear(animated) peripheralManager = CBPeripheralManager(delegate: self, queue: nil) [1] } func peripheralManagerDidUpdateState(_ peripheral: CBPeripheralManager) { print(\"peripheralManagerDidUpdateState \\(peripheral.state.rawValue)\") if peripheral.state == .poweredOn { let serviceUUID = CBUUID(string: kServiceUUID) [2] self.service = CBMutableService(type: serviceUUID, primary: true) [3] } // Other code }} Here is what these methods do: [1] You create an instance of PeripheralManager class, which will play as a peripheral in our example. Note that there is a queue param in the constructor. The events of the peripheral role will be dispatched on the provided queue. If we pass nil, the main queue will be used. [2] To set up a service, we need to create an instance of CBUUID class. The constructor gets a unique uuid as a param, which differentiates our service among others. [3] We create an instance of CBMutableService class. The constructor receives two params: The first one is our unique uuid, which was defined at [2]; the second param indicates that whether our service is primary or not. If not, our service will not be found when the app is in the background. Note that you can add services as many as you want. To be simple, I only create one service in this post.OK, let’s move to the next step. We will define characteristics for our service by using the below code. 12345let characteristic = CBMutableCharacteristic.init( type: CBUUID(string: kCharacteristicUUID), [1] properties: [.read, .write, .notify], [2] value: nil, [3] permissions: [CBAttributePermissions.readable, CBAttributePermissions.writeable]) [4] Here is what’s going on: [1] Like a service, a characteristic also needs a unique uuid to be differentiated among others. [2] We set up properties for the char. There is a variety of characteristic permissions, but I often use some of them: Read: Used for characteristics that don’t change very often, e.g version number. Write: Modify the value of the characteristic. Indicate and notify: The peripheral continuously notify the updated value of the characteristic to the central. The central does not have to constantly ask for it. IndicateEncryptionRequired: Only trusted devices can enable indications of the characteristic value.For other properties, please refer to Apple document [3] The value of the characteristic. Important note: If you provide a value for a characteristic, the characteristic must be read-only. Otherwise, you will get a run-time exception look like.2018-03-03 12:48:32.938615+0700 Peripheral[4238:3046876] *** Terminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'Characteristics with cached values must be read-only'Therefore, you must specify the value to be nil if you expect the value to change during the lifetime of the published service (write). [4] All characteristic should include the “readable” permission so that centrals could read its value. If we want a central can send commands to peripherals, we need to set the “writeable” permission to the characteristic. Now we have one service and one characteristic. Let’s publish it. 1234self.service?.characteristics = []self.service?.characteristics?.append(characteristic)self.peripheralManager.add(self.service!) After adding a service to the peripheral manager, the delegate method peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?) will be called. 1234567func peripheralManager(_ peripheral: CBPeripheralManager, didAdd service: CBService, error: Error?) { if let error = error { print(\"Add service failed: \\(error.localizedDescription)\") return } print(\"Add service succeeded\")} We’re almost done, just one more step: Start advertising the peripheral so that it can be found by other centrals. 12peripheralManager.startAdvertising([CBAdvertisementDataLocalNameKey: \"TiTan\", CBAdvertisementDataServiceUUIDsKey : [self.service!.uuid]]) After advertising, the delegate method peripheralManagerDidStartAdvertising will be triggered to indicate whether the peripheral did advertise successfully or not. 1234567func peripheralManagerDidStartAdvertising(_ peripheral: CBPeripheralManager, error: Error?) { if let error = error { print(\"Start advertising failed: \\(error.localizedDescription)\") return } print(\"Start advertising succeeded\")} At this point, we’ve already defined and published our service(s). From now on, the peripheral can be discovered by centrals via CoreBluetooth. Set up a CentralFirst, we need to create an instance of the CBCentralManager class. 12345678class ViewController: UIViewController, CBCentralManagerDelegate, UITableViewDelegate, UITableViewDataSource, CBPeripheralDelegate { override func viewDidLoad() { super.viewDidLoad() // Do any additional setup after loading the view, typically from a nib. centralManager = CBCentralManager(delegate: self, queue: nil) ... }} Like a peripheral manager, there is a queue param in the constructor. The events of the central role will be dispatched on the provided queue. If we pass nil, the main queue will be used.We need to wait for the central manager to be ready, then we will start scanning nearby devices. 1234567func centralManagerDidUpdateState(_ central: CBCentralManager) { print(\"peripheralManagerDidUpdateState \\(central.state.rawValue)\") if central.state == .poweredOn { self.centralManager.scanForPeripherals(withServices: nil, options: nil) }} If it find a peripheral, the delegate method func centralManager(_ central: CBCentralManager, didDiscover peripheral: CBPeripheral, advertisementData: [String : Any], rssi RSSI: NSNumber) will be called. 123456789101112func centralManager(_ central: CBCentralManager, didDiscover peripheral: CBPeripheral, advertisementData: [String : Any], rssi RSSI: NSNumber) { if let name = peripheral.name { if (!checkIfExisted(name)) { let tupleDeviceInfo = (device: peripheral, rssi: RSSI) self.scannedDevices.append(tupleDeviceInfo) } DispatchQueue.main.async { self.tbvScannedDevices.reloadData() } }} Inside the method, we will check if the peripheral is valid, after that we will add it to the current list, then reload the table view. Note that the RSSI value represents the strength of the transmitting signal. We can estimate the current distance between the central and the peripheral based on the value. The greater the value, the closer the device is.Build and run the project, you will see the list of discovered devices like this. Now, let’s connect to our peripheral (The “Titan” device) by clicking on the corresponding row.Once a connection is made successfully, the delegate method func centralManager(_ central: CBCentralManager, didConnect peripheral: CBPeripheral) will be called. Otherwise, the method centralManager(_ central: CBCentralManager, didFailToConnect peripheral: CBPeripheral, error: Error?) will be triggered. 123456func centralManager(_ central: CBCentralManager, didConnect peripheral: CBPeripheral) { self.centralManager.stopScan() peripheral.delegate = self self.peripheral = peripheral self.peripheral?.discoverServices(nil) [1]} 123centralManager(_ central: CBCentralManager, didFailToConnect peripheral: CBPeripheral, error: Error?) { // Fail to connect peripheral} Notice that after connecting to the peripheral, we need to discover the services of the peripheral to use it ([1]).The delegate method func peripheral(_ peripheral: CBPeripheral, didDiscoverServices error: Error?) will be called after discovering services. 1234567891011func peripheral(_ peripheral: CBPeripheral, didDiscoverServices error: Error?) { if let err = error { print(\"didDiscoverServices fail \\(err.localizedDescription)\") return } // [1] Start discovering all chars for service in (peripheral.services)! { peripheral.discoverCharacteristics(nil, for: service) }} We did not finish yet =.= After discovering services, we also need to discover all characteristics of the services at [1].Like others, the method func peripheral(_ peripheral: CBPeripheral, didDiscoverCharacteristicsFor service: CBService, error: Error?) will be called after discovering characteristics for a service. 123456789101112func peripheral(_ peripheral: CBPeripheral, didDiscoverCharacteristicsFor service: CBService, error: Error?) { if let error = error { print(\"didDiscoverCharacteristicsFor Error \\(error.localizedDescription)\") return } for char in service.characteristics! { if char.properties.contains(.notify) { peripheral.setNotifyValue(true, for: char) [1] } ... }} As you can see, we need to set notify to the characteristic that contains the notify property to receive updates from it. [1]Finally, we’ve done for setting up a connection between the peripheral and the central. Now let’s explore the data. Read and write data from peripheralYou have to specify which characteristic you want to read. 1self.peripheral?.readValue(for: discovererChars[kCharacteristicUUID]!) From the peripheral side, you will receive a read request inside the method 12345func peripheralManager(_ peripheral: CBPeripheralManager, didReceiveRead request: CBATTRequest) { print(\"Read request\") request.value = myValue.data(using: .utf8) peripheral.respond(to: request, withResult: .success)} After the peripheral response to read requests, the delegate method func peripheral(_ peripheral: CBPeripheral, didUpdateValueFor characteristic: CBCharacteristic, error: Error?) will be called from the central side. 1234 func peripheral(_ peripheral: CBPeripheral, didUpdateValueFor characteristic: CBCharacteristic, error: Error?) { let value = String.init(data: characteristic.value!, encoding: .utf8)! ...} If the value is successfully retrieved, you can access it through the characteristic’s value property, like above.Sometimes we want to write the value of a characteristic, which is writeable. We can write the value to it by calling the peripheral’s writeValue method like this. 1self.peripheral?.writeValue(data, for: discovererChars[kCharacteristicUUID]!, type: .withResponse) There is an argument called type, you specify what type of write you want to perform. In the example above, the write type is .withResponse, which instructs the peripheral to let your app know whether or not the write succeeds.From the peripheral side, you will receive a write request inside the method 1234func peripheralManager(_ peripheral: CBPeripheralManager, didReceiveWrite requests: [CBATTRequest]) { print(\"Write request\") peripheral.respond(to: requests[0], withResult: .success)} After the write request receives the response, the method peripheral(_ peripheral: CBPeripheral, didWriteValueFor characteristic: CBCharacteristic, error: Error?) will be called. 12345func peripheral(_ peripheral: CBPeripheral, didWriteValueFor characteristic: CBCharacteristic, error: Error?) { if let err = error { print(\"Did write value with error \\(err.localizedDescription)\") }} Encypted characteristic valuesSometimes we want to secure sensitive data. We can config the appropriate characteristic properties and permissions. Something like this 12345let encryptedChar = CBMutableCharacteristic.init( type: CBUUID(string: kCharacteristicUUID), properties: [.read, .notify, .notifyEncryptionRequired], value: nil, permissions: [.readable]) By doing this way, we ensure that only trusted devices have permissions to access these data.In my example, once a connection is made, CoreBluetooth tries to pair the peripheral (iPad) with the central (iPhone) to create a secure connection. Both devices will receive an alert indicating that the other device would like to pair. After paring, the central can access to the encrypted characteristic values of the peripheral. Some important notes The client-server model of BLE is called a publish and subscribe model. The peripheral only consumes power when it’s advertising its services, or receiving or responding to a central’s request. You can pass a list of service UUIDs inside the scanForPeripherals method. When you specify a list of service UUIDs, the central manager returns only peripherals that advertise those services, allowing you to scan only for devices that you may be interested in. You need to grant permissions to let your app uses Bluetooth LE accessory, and acts as a Bluetooth LE accessory for peripheral sides. (Go to project -&gt; Capabilities for setting). You also need to add one more information property to your info.plist, let’s add an entry with key Privacy - Bluetooth Peripheral Usage Description and value App communicates using CoreBluetooth (Or whatever you want to describe). A quick look to my appLet’s try some light exercise from my example. Summarize the programming flow for BLETo summarize the general programming workflow of CoreBluetooth on iOS, please take a look at the picture below. Final thoughtsIn this post, I guided you how to use the CoreBluetooth to create a peripheral as well as how to create a central to connect and obtain data from a peripheral. In the future, we can see that all devices around us are connected together via Bluetooth, towards the IoT world.You can download the completed project of the central here or the peripheral here.If you have any questions or comments, feel free to leave it on my post. Any comments are welcome. References[1] Core Bluetooth Programming Guide from Apple","link":"/2018/02/21/Play-Central-And-Peripheral-Roles-With-CoreBluetooth/"},{"title":"Review book: Swift Apprentice - Raywenderlich","text":"While I was searching for a book to boost my iOS development skill, I found this Swift Apprentice book on Raywenderlich’s book store. Take a quick look at the content of the book, I decided to add the book to my library.Generally, If your iOS skill is mid-level or senior, you’re so confident with your master programming skill, this book is not for you. But if you’re looking for a book to strengthen your knowledge, or you just want to make sure everything you understand about Swift language is right - as my purpose, then take this book with you.You’ll learn about very basic things like function, method, constants, control statement, etc. You’ll also have a chance to get in-depth knowledge about Stack/Heap allocation, protocol-oriented programming, and generic programming, which make your daily job more convenient, and you will find yourself like a master in Swift language.Let’s drive-in! About the authorFor those who don’t know who Raywenderlich is, it is a community site focused on creating programming tutorials and books (Mainly focus on mobile development on Android and iOS). Their content covers all levels from beginning to advanced topics.I often access Raywenderlich site to get example code and to make my knowledge up to date. Their tutorials are extremely great, technically accurate and are updated to the newest technologies.Swift Apprentice is one of their collection of iOS programming. Keynotes Lazy property: If you have a property that might take some time to calculate, you don’t want to slow things down until you actually need the property, let’s use the lazy stored property. It is useful for such things as downloading a user’s profile picture or making a serious calculation. The heap vs. the stack:The Stack is used to store anything on the immediate thread of execution; it’s managed and optimized by the CPU. When a function creates a variable, the stack stores that variable and then destroys it when the function exits. Since the stack is so strictly organized, it’s very efficient, and thus quite fast.The heap, on the other side, is used to store instances of reference types. The heap is generally a large pool of memory from which the system can request and dynamically allocate blocks of memory. Lifetime is flexible and dynamic. It doesn’t automatically destroy its data (the stack does so). Additional work is required to free the memory on the Heap, which makes creating and removing data on the heap a slower process, compared to on the stack.When an instance of a class is created, your code requests a block of memory on the heap to store the instance itself.When an instance of a struct is created (that is not part of an instance of a class), the instance itself is stored on the stack, and the heap is never involved. When to use a class versus a struct: Values vs. objects: Use structures as values and classes as objects with identity. To make it simple, just keep in mind that there are no two objects are considered equal simply because they hold the same state. In contrast, instances of value types, which are values, are considered equal if they are the same value. e.g, no two students are considered equal, even if they have the same name; Two points (x, y) are equal if x1 and y1 the same to x2 and y2, respectively, so we implement Point as a struct.Speed: If these instances will only exist in memory for a short time — go towards using a struct. If your instance will have a longer lifecycle in memory, let’s think of a class.Another approach is to use only what you need. If your data will never change or you need a simple data store, then use structures. If you need to update your data and you need it to contain logic to update its own state, then use classes. Often, it’s best to begin with a struct. If you need the added capabilities of a class sometime later, then you just convert the struct to a class. Two-Phase initialization:• Phase one: Initialize all of the stored properties in the class instance, from the bottom to the top of the class hierarchy. If you use properties and methods before phase one is complete, the compiler will throw errors.• Phase two: We can now use properties and methods of the object. Protocols in the Standard Library: Equatable, Comparable, Hashable, CustomStringConvertible. Generic function parameters: 123func swapped&lt;T, U&gt;(_ x: T, _ y: U) -&gt; (U, T) { (y, x)} Wildcard pattern: 1234if case (_, 0, 0) = coordinate { // x can be any value. y and z must be exactly 0. print(\"On the x-axis\") // Printed! } Value-binding pattern:123if case let (x, y, 0) = coordinate { print(\"On the x-y plane at (\\(x), \\(y))\") // Printed: 1, 0 } “Is” type-casting pattern”:12345switch element { case is String: print(\"Found a string\") default: break} Rethrows: By using rethrows instead of throws, functions indicate that they will only rethrow errors thrown by the functions called inside itself but never errors of its own. Protocol-oriented benefits:By using protocols instead of implementations, we focus on what the object can do instead of how the object does, which makes the application more extendable and testable.Multiple inheritances: One of the real benefits of protocols is that they allow a form of multiple inheritance. Swift is a protocol-oriented language. What I like Well organized. Real examples: There are examples for each topic to make sure readers deeply understand what they just mentioned. Easy to understand: As the content are well-organized, it’s easy to follow the content flow. Stop and think: There are short exercises and challenges throughout the book to give you some programming practice and test your knowledge along the way. Keypoints: They summarize key points at the end of each chapter. What I dislikeI tried to look over the books several times to find a spot that I dislike but there is nothing to complain about, from content to form. GenerallySwift is fun and is filled with programming paradigms. After reading this book, I hope you now feel more comfortable enough with the language to move on to building bigger things. With the language fundamentals we’ve gained, we’re ready to explore advanced frameworks such as Animation, UIKit, etc. to build iOS apps, macOS apps and more.I hope you find this book interesting.Happy weekend!","link":"/2020/02/26/Review-book-Swift-Apprentice-Raywenderlich/"},{"title":"Best practice: iBeacon","text":"Welcome to the next part of the series of “How to deal with BLE in the background“.In the previous part, I guided you how to keep your app alive as long as possible when your app enters to background mode by using State Preservation and Restoration technique supported by Apple. However, there are some usecases this technique can not handle, as described below (refer to Apple document: Conditions Under Which Bluetooth State Restoration Will Relaunch An App)As you can see, there is a common case when users force quit the app from the multiple task view (Whether accidentally or intentionally), the Restoration technique can not awake your app. Let’s imagine that your app has a feature allows users to press a button on your BLE-connected devices to find where their phone is, but if your app is not running or is not able to wake up to handle the BLE signal sent from your devices, this feature would be useless.In this post, I will show you a technique using iBeacon to deal with this case, which makes your app another chance to wake up despite it is terminated by users. Let’s drive-in! Welcome to the world of iBeaconiBeacon is a protocol first introduced by Apple in WWDC 2013. “iBeacon is based on Bluetooth low energy proximity sensing by transmitting a universally unique identifier picked up by a compatible app or operating system. The identifier and several bytes sent with it can be used to determine the device’s physical location, track customers, or trigger a location-based action on the device such as a check-in on social media or a push notification” (Wiki).iBeacon application is very diverse like location-based services, mobile commerce or advertising, to name a few.“The Automatic Museum Guide” is a project that is very impressed me built on iBeacon technology. The app allows visitors to explore exhibits by showing the appropriate contents by tracking their location and their distance with the beacon. That’s a brilliant idea! How it worksApple has standardized the content of iBeacon advertisement data. It consists of a 16 byte UUID, the major and minor version. These three factors are unique for each beacon. A last field in the packet is TX power used to determine how close you are to the beacon.A beacon broadcasts this packet in its range, far from 20m to 300m, at regular intervals of time. These packets are automatically detected by nearby phones, then the app will perform a pre-defined action like showing a notification or pop-up a promotion code. Although iBeacon is based on Bluetooth low energy technology, one of the main differences between the two is iBeacon is one-way transmit technology, by which I mean only the phone can receive data from iBeacon devices. iOS integration: start advertising as an iBeaconFirstly, we need a beacon so that we can do the next step. I’m going to use my iPad to act as a beacon by using a CLBeaconRegion object in CoreBluetooth on iOS.The main UI just simply contains two main buttons that will start and stop the advertisement of the iBeacon, respectively. 123456let region = CLBeaconRegion(proximityUUID: self.uuid!, major: self.major, minor: self.minor, identifier: self.identifier)let peripheralData = region.peripheralData(withMeasuredPower: nil)peripheral.startAdvertising(((peripheralData as NSDictionary) as! [String : Any])) Then, we implement the peripheralManagerDidStartAdvertising(CBPeripheralManager, Error?) delegate to check if the beacon advertises successfully. 1234567func peripheralManagerDidStartAdvertising(_ peripheral: CBPeripheralManager, error: Error?) { if error == nil { print(\"Successfully started advertising our beacon data.\") } else { print(\"Failed to advertise our beacon. Error = \\(String(describing: error))\") }} To stop advertising 1peripheralManager?.stopAdvertising() Leverate iBeacon technology to make our app last foreverFirstly, Inside the didFinishLaunchingWithOptions method of AppDelegate class, I will show a notification to get notified whenever our app is relaunched. 1234func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool { NotificationHandler.shared.showNotification(title: \"App did launch\", body: \"\") return true} After the main view appears, I then tell the location manager to start monitoring the given region and to start ranging iBeacons within that region 1234func startMonitoring() { locationManager.startMonitoring(for: beaconRegion) locationManager.startRangingBeacons(in: beaconRegion)} By default, monitoring notifies you when the region is entered or exited regardless of whether your app is running. Ranging, on the other hand, monitors the proximity of the region only while your app is running. That’s all for setting up. In the following demonstration, you will see I open the app then terminate it from the multiple task view. After that, I press the “Start advertising” button on my iPad (The beacon). You will see the app was relaunched immediately even it had been killed (The “App did launch” notification showed up). That’s amazing. Note: Don’t expect to receive an event right away, because only boundary crossings generate an event. In particular, if the user’s location is already inside the region at registration time, the location manager doesn’t automatically generate an event. Instead, your app must wait for the user to cross the region boundary before an event is generated and sent to the delegate. ConclusionsOne of the most interesting things of iBeacon is iBeacon applications can be waked up event it has been terminated by the user. It means iBeacon applications can last forever. To download the completed projects, please click to the following Github links: Act as an iBeacon: https://github.com/uynguyen/iBeaconDevice Central manager app: https://github.com/uynguyen/CentralManager-iBeacon Feel free to shot me an email if you have any questions. References[1] Region Monitoring and iBeacon","link":"/2018/08/18/Best-practice-iBeacon/"},{"title":"Schedule task in background from foreground service","text":"If you’re running your service on Android, be aware that Android has introduced stricter background execution restrictions in recent versions. Starting from Android 8.0 (API level 26) and above, background services have limitations on their execution time, especially when the app is in the background. Make sure you are aware of these restrictions and adapt your service accordingly. TimerWhen using Timer to schedule tasks, it relies on a single background thread. If the screen turn off, the device may enter a low-power state or go to sleep mode, and this can effect the execution of tasks scheduled with Timer. In such cases, the device’s power-saving features might pause or delay the task execution, leading to unexpected behavior. 1234567private final Timer syncTimer = new Timer();syncTimer.scheduleAtFixedRate(new TimerTask() { @Override public void run() { // Do your task }}); In my case, my app needs to schedule a repeated task in background to sync data and check if the user still has permission to access the Bluetooth device. In the first attempt, we used Timer, and it didn’t work as expected since the Timer does not run when the device falls into doze mode (Doze mode is a power-saving feature introduced in Android 6.0 (Marshmallow) that helps extend battery life by reducing the device’s power consumption when it is idle and not in use. It optimizes app behavior to minimize background activity, network access, and CPU usage during periods of inactivity. When a device is in Doze mode, it restricts background processing, network access, and wake locks to save battery power.).Thus, we need to find an alternative, and there are two other candidates I would like to share to you: AlarmManager and WorkManager. Alarm managerIf you need to schedule tasks that should run even when the app is not actively running, you can use the AlarmManager class. It allows you to schedule tasks at specific times or intervals, even if your app is in the background or not running. The AlarmManager class in Android is a system service that allows you to schedule tasks or events to be executed at specific times or intervals, even when your app is not actively running. It provides a way to perform actions or trigger code execution at specified times, such as setting alarms, scheduling recurring tasks, or executing background operations. The key features of AlarmManager include: Timing Accuracy: AlarmManager provides accurate timing for scheduling tasks. It uses the device’s system clock to determine when the specified time or interval has elapsed. Flexibility in Scheduling: You can schedule tasks to run once (set()), repeat at fixed intervals (setRepeating()), or repeat at specific intervals with flexibility (setInexactRepeating()). This flexibility allows you to schedule tasks according to your specific requirements. Execution Persistence: The scheduled tasks registered with AlarmManager persist even if the device is restarted. This ensures that the tasks will be executed as scheduled even after system reboots. Device Wake-up Capability: AlarmManager can wake up the device from sleep mode to execute the scheduled tasks. This is useful for scenarios where you need to perform background operations that require the device to be awake. Compatibility and Backward Support: AlarmManager has been available since the early versions of Android and provides backward compatibility with older Android versions. This ensures that your scheduled tasks can run on a wide range of devices. Here’s a basic example of using AlarmManager to schedule a task: First, you’ll need to set up the necessary permissions in your AndroidManifest.xml file: 1&lt;uses-permission android:name=\"android.permission.WAKE_LOCK\"/&gt; Next, create a class to handle the task that will be executed when the alarm triggers, and use it 123456789101112131415161718192021public class MyAlarmReceiver extends BroadcastReceiver { @Override public void onReceive(Context context, Intent intent) { // Do your task }}Intent intent = new Intent(this, MyAlarmReceiver.class);PendingIntent pendingIntent = PendingIntent.getBroadcast(this, 0, intent, 0);// Get the AlarmManager serviceAlarmManager alarmManager = (AlarmManager) getSystemService(Context.ALARM_SERVICE);// Set the repeating alarmalarmManager.setRepeating( AlarmManager.RTC_WAKEUP, System.currentTimeMillis() + ALARM_INTERVAL_MS, ALARM_INTERVAL_MS, pendingIntent); Work managerWorkManager is an Android Jetpack library introduced by Google to simplify and manage background tasks in Android applications. It is designed to make it easier for developers to schedule deferrable, periodic, and one-off tasks that need to be executed even when the app is not running or the device is in a low-power state. Using WorkManager, you can perform tasks such as uploading data to a server, syncing data from a remote server, periodic data refreshes, database cleanup, and more, while ensuring efficient and battery-friendly background execution. It abstracts away the complexity of dealing with various Android versions and power-saving features, making it a powerful and recommended solution for background processing in modern Android applications. First, Open your app’s build.gradle file and add the Guava dependency to the dependencies block: 12implementation \"androidx.work:work-runtime:2.8.1\"implementation 'com.google.guava:guava:30.1-android' Next, create a class to handle the task that will be executed and use it 123456789101112131415161718192021222324class SyncDataWorker extends Worker { public SyncDataWorker( @NonNull Context context, @NonNull WorkerParameters params) { super(context, params); } @Override public Result doWork() { // Do your task return Result.success(); }}// somewhere in your codePeriodicWorkRequest periodicWorkRequest = new PeriodicWorkRequest.Builder( SyncDataWorker.class, TIME_IN_MILLISECONDS, TimeUnit.MILLISECONDS) .setConstraints(new Constraints.Builder() .setRequiredNetworkType(NetworkType.CONNECTED) // Set it if your task requires network to be completed .build()) .build();WorkManager.getInstance(context).enqueue(periodicWorkRequest); When using WorkManager and the device screen is off, there are a few limitations and considerations to keep in mind: Delayed Execution: When the device screen is off, Android may enter low-power states like Doze mode or app standby mode to conserve battery. In these states, background tasks, including those scheduled by WorkManager, may be delayed. WorkManager tries to execute tasks during maintenance windows, but there can still be delays in task execution. Network Access Restrictions: Android may restrict network access for background tasks when the screen is off. If your task relies on network connectivity, it may experience delays or have limited access to network resources. You can use constraints like setRequiredNetworkType() in WorkManager to specify network requirements for your tasks. Background Execution Limits: Starting from Android 8.0 (API level 26), Android introduced stricter background execution limits. Background apps, including those running background tasks scheduled by WorkManager, have restrictions on their ability to run CPU-intensive tasks or access certain resources. While WorkManager is designed to handle these limitations and ensure efficient task execution, it may still be subject to restrictions imposed by the operating system. Device-Specific Behavior: Different Android devices and manufacturers may have their own power-saving features or optimizations that can affect background task execution when the screen is off. These optimizations can vary, leading to different behaviors and limitations. It’s important to test your app on various devices to ensure consistent behavior. To optimize the execution of background tasks when the device screen is off, consider the following: Use appropriate constraints: Specify constraints such as network requirements (setRequiredNetworkType()), charging status (setRequiresCharging()), and more to ensure tasks are executed under the desired conditions. Respect battery optimizations: Encourage users to exclude your app from battery optimizations or whitelist it in any power-saving settings on their device. This can help ensure that your app and its background tasks are not excessively restricted. Optimize task execution: Structure your tasks to be as efficient as possible, minimizing the impact on battery life and resources. Break down larger tasks into smaller, manageable units and consider using WorkManager’s ListenableWorker or CoroutineWorker for better performance. By considering these factors and designing your background tasks and scheduling strategies accordingly, you can optimize their execution even when the device screen is off and work within the limitations imposed by the Android system. Which one to use?The choice between AlarmManager and WorkManager depends on your specific use case and requirements. Here are some factors to consider when deciding which one is better suited for your needs: Timing and Flexibility AlarmManager: It offers precise timing for executing tasks at specific times or intervals, even when the app is not actively running. AlarmManager is suitable for time-critical tasks that require exact execution timing. WorkManager: It provides more flexibility and optimization for background tasks. WorkManager considers factors like battery optimizations, network availability, and device idle state to execute tasks efficiently. It is well-suited for tasks that don’t require strict timing precision, such as syncing data or periodic updates that can accept some delay. Power Efficiency and Battery Optimization AlarmManager: It allows for more immediate execution and can wake up the device from sleep mode. However, if used improperly, it can have a significant impact on battery life. WorkManager: It leverages system optimizations to minimize battery usage. WorkManager batches tasks, respects device idle states, and adapts to power-saving features. It provides a more power-efficient approach for executing background tasks. Compatibility and Backward Support AlarmManager: It has been available since early versions of Android and offers backward compatibility with older Android versions. It can be used in a wide range of Android devices. WorkManager: It is part of the Android Jetpack library and is backward compatible down to Android API level 14 (Ice Cream Sandwich). WorkManager is designed to work consistently across different Android versions and devices. Error Handling and Retry Mechanism AlarmManager: It doesn’t provide built-in mechanisms for handling task failures or automatic retries. WorkManager: WorkManager can automatically retry failed tasks with configurable constraints. In general, if you need precise timing, immediate execution, or the ability to wake up the device from sleep mode, AlarmManager might be the better choice. On the other hand, if you require power efficiency, flexible task scheduling, error handling, and compatibility across different Android versions, WorkManager is a more suitable option.In some cases, you may even use both AlarmManager and WorkManager together, depending on the specific requirements of your app. For example, you can use AlarmManager for time-sensitive tasks and WorkManager for power-efficient background processing. ConclusionIn summary, while using Timer might lead to unpredictable behavior when the screen turns off due to single-thread execution and lack of power-saving optimizations, WorkManger and AlarmManager can handle tasks execution more efficiently and reliably, even when the screen is off or the device is in a low-power state. For scheduling background tasks, it’s generally recommended to use WorkManager or AlertManager than using Timer.","link":"/2023/07/22/Schedule-task-in-background-from-foreground-service/"},{"title":"Shipping your iOS app to Store","text":"Submitting your app to the Apple Store isn’t as simple as pressing a “magic” button then it does everything, but it’s not as complicated as you think either. It’s maybe your first time launching your first app, and you don’t have a chance to get familiar with the submitting process before. This step-by-step tutorial will show you the main flow to submit apps from zero to a hero. Kindly note that you need to have a Paid Developer Account to get it done.Jump in! Certificates, app Ids and provisioning profilesIn other to submit your app to App Store, you need to understand what certificates, app IDs and provisioning profiles are. Basically, A distribution certificate identifies your team/organization within a distribution provisioning profile and allows you to submit your app to the Apple App Store. The following image describes the relationship between them. Create a Distribution Certificate On your Mac, Open Key Chain Access app. Go to Certificate Assistant &gt; Request a Certificate From a Certificate Authority. Fill in your email to the email box. The Keychain Access will create a private key, which is stored in the keychain, and a .certSigningRequest file which will be uploaded to Apple. Apple will issue a certificate for you based on the .certSigningRequest. The Certificate contains the public key. After that, you can download the file and open it. The public key will be pushed to the Keychain and paired with the private key to make the “Code Signing Identify”. Just so you know what is CSR A CSR or Certificate Signing request is a block of encoded text that is given to a Certificate Authority when applying for an SSL Certificate. It is usually generated on the server where the certificate will be installed and contains information that will be included in the certificate such as the organization name, common name (domain name), locality, and country. It also contains the public key that will be included in the certificate. A private key is usually created at the same time that you create the CSR, making a key pair. After having the .certSigningRequest file, go to the Apple developer page, sign in to your Apple Account &gt; Certificates, Identifiers &amp; Profiles &gt; Press the “+” button to create a new certification &gt; Remember to select the “iOS Distribution (App Store and Ad Hoc)” option. Next, select to upload your .certSigningRequest file you just created at the step 3. Finally, you now can download the Certificate file to your Mac, open it and the key will be pushed to the keychain automatically. That’s all for creating a Distribution Certificate, let’s move on to the next step, create your app id. Create App Id Press the “+” button on the page “All Identifiers” Fill in your app information, including your bundle Id. Please note that this bundle id must match your bundle id in XCode. You can also use wildcard pattern to define bundle Id for more than one app Ids. Create Provisioning Profile Press the “+” button on the page “Profiles”, then select “App Store” option. Select your app Id that you just created in the previous step, Create App Id. Select your Certificate that you just created in the previous step, Create a Distribution Certificate Now you have a profile that links your Certificate and your app Ids. Download this file and open it. The Provisioning Profiles will be pushed to XCode automatically. UploadingIt’s time to upload your app to Store.Let’s back to your project, from the Top Tool Bar &gt; Product &gt; Archive, XCode will rebuild your project. After that, the XCode Organizer will launch and show all archives you’ve created in the past.Select the current build, then click on “Distribute App” in the right-hand panel. The next window allows you to select your credentials including the Distribution Certificate and the Provisioning Profiles you created in the first section. Finally, press the upload button, XCode will do the rest for you. An email will be sent to notify you right after Apple completes the processing process, it usually takes some minutes.Your app has been successfully uploaded to your iTunes Profile, let’s go to the final step. SubmitingNavigate to App Store Connect, select “My Apps”. you will see your app appear on the page. You need to prepare the following information to fill in on these pages: App Name, Privacy Policy URL, Age Rating, Category. Screenshot in different sizes: This might take your time the most, your screenshots need to meet Apple requirements at Screenshot specifications. Kindly note that users will see these screenshots related to their current devices, so make sure your photos are fancy and extractive as most as you can. Fastlane also supports take screenshots automatically, you can find the document if you’re interesting. Fastlane tools can automate this process making it fast, and consistent while giving you beautiful results! Version description, keywords, support URL. If your app requires sign in, fill in account information with username and password. App notes: Some important notes you want to send the previewer to make sure it works properly. (e.g we strongly recommend using the service with a Wifi connection for best quality) Attachment: It’s best to have a short demo of your app. Contact information: If there are any issues, Apple will contact you via this information. You’re done. Now precess the “Submit” button to start the reviewing process. Reviewing processYour reviewing process takes some time to complete, it may be a couple of days to couple weeks depends on your app category, features, and … the reviewer.If your app violates Apple rules such as using unapproved private APIs, lack of permission description, crashing or poor performance, it will get rejected. In the end, we have to accept that Apple has the final word on allowing anything into the App Store. Just because you think your app is great does not mean that Apple will allow it into App Store. I myself experienced this strickly-randomly-emotionally process when submitting my application. The first submission went smoothly without any troubles. The second one, which is updated some UI, got rejected because Apple thinks my app contains a feature that is not allowed in the App Store. With many emails and phone calls, I finally had to remove this feature from my app. (?!) Final wordsIn this post, I guided you on how to submit your app to Store in a very detailed step. Hope this post saves your time in delivering your amazing apps to users. Can’t wait.In next post, I will show your steps to upload your app to Google Play.Happy coding.","link":"/2018/12/13/Shipping-your-iOS-app-to-Store/"},{"title":"Series React Native and BLE: Part 1 - Building BLE framework for iOS","text":"I have been working in mobile development on both native projects and cross platforms (React Native, Flutter), and I also have experience working on BLE. Sometimes I get emails asking about the communication of RN/Flutter to BLE. Thus, I decided to introduce this series React Native and BLE to guide you on how to develop a native BLE framework and connect it to React Native.Of course, there will be another series for Flutter and BLE after finishing the series of React Native.In this series, I will guide you through a completed process from development to distribution. Create an iOS / Android framework. Script to build and distribute your framework. Import the frameworks to your React Native project. Use your native framework in React Native. Distribute your app. And other cool stuff I want to share with you … If you love what I do, consider supporting me at buy a coffee for Uy Nguyen :)Let’s go. Xcode 13, iOS 15, Swift 5, React 17.0.1, React Native 0.64.1. Prepare iOS frameworkThe first step is creating a BLE framework. You also don’t have to create a framework, you can include your source code inside the iOS project directly if you want to.However, the reason why I recommend moving all BLE logic to a framework is that it’s reusable, you can share your framework to other projects such as Flutter or Native projects without having to duplicate the logic.Another reason is that it will improve the compile time of Xcode, breaking your app into several frameworks can speed up the build times. This is because the Xcode build system doesn’t have to recompile frameworks for which Swift files have not changed. From the top left bar of Xcode, select File &gt; New &gt; Project &gt; From the &quot;Framework &amp; Library&quot; section, select &quot;Framework&quot; &gt; Enter your framework name (I use &quot;BLEFramework&quot;) Now, you can develop your BLE logic in the project you just created. I’m not going to detail implementing all single methods of the framework as it depends on your business logic and your architecture. You can find my previous tutorials to have an idea of how to implement a BLE framework. Bluetooth Low Energy OniOS, Play Central And Peripheral Roles With CoreBluetoothI will take a simple method in my BLE framework as an example: the startScanning method. 12345678910/**Class: CentralManager*//*** @discussion Start scanning nearby peripherals and returns to the `ScanningDelegate`*/public func startScanningFor(delegate: ScanningDelegate, filter: DeviceFilter = DeviceFilter()) throws { //... BLE implementation.} OK now we have a BLE framework, let move to the next step: Building and distributing your framework. Building and distributingThere are many ways to distribute a framework like using CocoaPod, or manually by sending a complied file, etc. In this post, I will provide you with a script to turn your framework into a universal framework that hides all your logic, and can be used for both physical devices and simulators. Make sure you turn “Build Libraries for Distribution” flag in the “Build Settings” to YES. The flag indicates that the compiler should generate one of the stable interfaces so the framework can be used when newer versions of Xcode or the Swift compiler are released. Next, create a bash file, put it in the root of the ios folder, and copy the following commands to the file. Then execute the script. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546### SCRIPT TO BUILD A SWIFT UNIVERSAL FRAMEWORKPRODUCT_NAME=\"REPLACE_BY_YOUR_TARGET_NAME\"BUILD_CONFIGURATION=\"Release\"DERIVED_DATA_PATH=\"$(pwd)/build\"RELEASE_DIR=\"$(pwd)/RELEASE\"BUILD_SCHEME=\"${PRODUCT_NAME}\"FRAMEWORK_NAME=\"${PRODUCT_NAME}.framework\"RELEASE_DEVICE_PATH=\"${RELEASE_DIR}/device/${FRAMEWORK_NAME}\"RELEASE_SIMULATOR_PATH=\"${RELEASE_DIR}/simulator/${FRAMEWORK_NAME}\"rm -rf \"${DERIVED_DATA_PATH}\"rm -rf \"${RELEASE_DIR}\"mkdir -p \"${DERIVED_DATA_PATH}\"mkdir -p \"${RELEASE_DIR}\"mkdir -p \"${RELEASE_DIR}/simulator\"mkdir -p \"${RELEASE_DIR}/device\"# Build library for simulatorfastlane ios build scheme:\"${BUILD_SCHEME}\" \\ configuration:\"${BUILD_CONFIGURATION}\" \\ sdk:iphonesimulator \\ build_dir:\"${DERIVED_DATA_PATH}\" \\ --verboseSIMULATOR_FRAMEWORK_PATH=\"${DERIVED_DATA_PATH}/Build/Products/${BUILD_CONFIGURATION}-iphonesimulator/${FRAMEWORK_NAME}\"mv \"${SIMULATOR_FRAMEWORK_PATH}\" \"${RELEASE_SIMULATOR_PATH}\"# Build library for iphoneosfastlane ios build scheme:\"${BUILD_SCHEME}\" \\ configuration:\"${BUILD_CONFIGURATION}\" \\ sdk:iphoneos \\ build_dir:\"$DERIVED_DATA_PATH\" \\ --verboseDEVICE_FRAMEWORK_PATH=\"${DERIVED_DATA_PATH}/Build/Products/${BUILD_CONFIGURATION}-iphoneos/${FRAMEWORK_NAME}\"mv \"${DEVICE_FRAMEWORK_PATH}\" \"${RELEASE_DEVICE_PATH}\"# Merge SDKsxcodebuild -create-xcframework -output \"${RELEASE_DIR}/${PRODUCT_NAME}.xcframework\" \\ -framework \"${RELEASE_DEVICE_PATH}\" \\ -framework \"${RELEASE_SIMULATOR_PATH}\"open \"${RELEASE_DIR}\" Once you run the script successfully, you should see the result as below In which: YOUR_TARGET_NAME.xcframework: The universal framework can be used for both physical devices and simulators. device folder: contains YOUR_TARGET_NAME.framework which can be used only on physical devices. simulator folder: contains YOUR_TARGET_NAME.framework which can be used only on simulators. Now we have a BLE framework for our application, let’s move to the next step - Create a new React Native project. Init React Native projectTo create a React Native project without using Expo (I recommend to not using Expo because we’re going to add a lot of Native code for Android and iOS to our project, for more details you can refer to what is the difference between expo and react native), open terminal and type 1react-native init projectName Wait a while to set up your project. After running successfully, you should see the folder structure as below: 12345|---projectName |---ios |---projectName.xcworkspace |---android |---...Other files, folders Open the projectName.xcworkspace file, we will config the native code in the next step. Wire them togetherFirst, drag and drop the YOUR_TARGET_NAME.xcframework to your Xcode workspace.As my SDK is built in Swift, I’m going to create a Swift class as a bridge so that we can communicate from the SDK to React Native.From Xcode project, select File &gt; New &gt; File &gt; Swift File &gt; Enter your file name (e.g BLEManager) &gt; Add. A dialog will pop up to ask if you want to create a bridging header, select yes. For those who don’t know what the bridging header is used for, the bridging header is where you define all the Objective-C classes that are exposed to Swift. To use RCT classes, make sure you #import all related headers to your ...-Bridging-Header.h. Otherwise, you will get complied errors. 1234#import &lt;React/RCTBridgeModule.h&gt;#import \"React/RCTEventEmitter.h\"#import \"React/RCTViewManager.h\"#import &lt;React/RCTLog.h&gt; Next, add the interface RCTEventEmitter to the class BLEManager we just created in the previous step. 1234567891011121314151617181920212223242526272829@objc(BLEManager) &lt;--- Remember to add this [1]public class BLEManager: RCTEventEmitter, ScanningDelegate { static let didFoundDeviceEvent = \"didFoundDevice\" @objc &lt;--- Remember to add this public static let shared = BLEManager() override init() { super.init() _ = BLEWrapper.shared } @objc(startScanning) &lt;--- Remember to add this func startScanning() { BLEWrapper.shared.startScanning(self) } public func managerDidFoundDevice(_ manager: CentralManager, device: Device, rssi: Int) { self.sendEvent(withName: Self.didFoundDeviceEvent, body: [\"name\": device.localName, \"rssi\": rssi]) [2] } public override static func requiresMainQueueSetup() -&gt; Bool { return true } override public func supportedEvents() -&gt; [String]! { return [Self.didFoundDeviceEvent] [3] }} [1] Make sure you decorate your class and functions by the @objc keyword to ensure the class and functions are exported properly to the Objective-C runtime.[2] Once a peripheral is discovered, send an event to Javascript.[3] Register supported the event from the native module. Finally, to expose the methods of your native module, create a new file BLEManager.m and add the following code. 12345@interface RCT_EXTERN_MODULE(BLEManager, RCTViewManager)RCT_EXTERN_METHOD(startScanning)@end That’s all. Javacsript now can invoke the startScanning function and listen to the didFoundDeviceEvent event. TestingIt’s time to test our implementation, React Native provides NativeEventEmitter and NativeModules instances that allow you to work with native modules.from the root folder, open App.js and import the necessary things. 12345import { NativeEventEmitter, NativeModules,} from 'react-native';const {BLEManager} = NativeModules; &lt;-- You can then access the BLEManager native module In componentDidMount method, add the following to it 123456789101112componentDidMount() { let beaconManagerEmitter = new NativeEventEmitter(BLEManager); [1] this.didFoundDevice = beaconManagerEmitter.addListener( [2] 'didFoundDevice', data =&gt; { console.log(data); }, ); setTimeout(() =&gt; { BLEManager.startScanning(); [3] }, 3000); // Just to make sure the Bluetooth is on, we will improve it later} [1] Create a new NativeEventEmitter instance and listen to the didFoundDevice event [2][3] Because we do not support the Bluetooth state changes event yet, so we temporarily delay 3s before calling scanning just to make sure the Bluetooth is on. We will improve it later by supporting more events and methods. OK, let’s build and run your project. If you see your console log print the results from the scanning process, congratulation, you make it right! Next stepIn this post, I showed you how to create a BLE framework and how to use a BLE native module in a React Native project such as invoking a method from Javascript to Swift and handling an event from Swift to Javascript. In the next tutorial, we will do the same on Android platform.If you face any troubles, feel free to contact me. I would love to help.Happy holiday. Refs[1] React Native - Native module ios","link":"/2021/12/25/Series-React-Native-and-BLE-Part-1-Building-BLE-framework-for-iOS/"},{"title":"WWDC 2020 - Top reasons why app get killed in background","text":"Ever wonder why your app gets killed from the system when it enters the background? This post is going to summarize the top reasons introduced by Apple in WWDC 2020, and what you can do to prevent your app from being killed in the background. By applying these tips, we can improve our app’s experience because your app does not have to re-launch from the scratch.Let’s rock! Top reasonsThe following describes the top 6 reasons why your app is killed while it is in the background: Crashes: Segmentation fault, illegal instructions, asserts and uncaught exceptions. Watchdog:A long hang during app transitions such as deadlock, infinite loop or unending synchronous tasks on the main thread. In approximately 20s, your app must transition from one state to another. Otherwise, it will be killed. 123+ application(_:didFinishLaunchingWithOptions)+ applicationDidEnterBackground(_:)+ applicationWillEnterForeground(_:) Excessive CPU usage:High sustained CPU load in the background. If your app really needs to do heavy works in the background, you should consider moving the task into the background processing task which gives your app several minutes of running while charging without CPU resource limits. Memory limit exceeded:Your app is using too much memory (same on background and foreground). Remember that the limitation differentiates from device to device. Before iPhone6s, 200M is the memory limitation (The older, the smaller). Memory pressure exit (aka Jetsam):It happens when the system needs to free up memory of background applications for the foreground applications (and other running applications like music or navigation app). To prevent this, try reducing the memory as small as possible, less than 50M (e.g clear out image views). However, we can’t eliminate the risk of jetsam entirely. The best advice to overcome it is leveraging the build-in UI State Restoration to restore the app state right before it had been killed in the background. The following video describes how Jetsam happens on iOS devices. Let say we open the Amazon app for shopping, we then select a favorite item to see its detail. Say we have to leave the app in the background for a moment, then we start opening other apps (Google Maps, Music, Photos, Spotify, etc.). At some point, we open the Amazon app again. As we notice, the app launches from the scratch. This is because the app is terminated by the system. Obviously, the Amazon app did not do anything wrong, it’s just because the system needs to free up memory for other applications that are running in the foreground. Background task timeout:The last common reason is using background tasks improperly. 12UIApplication.beginBackgroundTask(exprirationHandler:)UIApplication.endBackgroundTask(_:) When your app moves from foreground to background, and you want to complete some important tasks, iOS provide you some extra runtime (only a few seconds) by calling the UIApplication.beginBackgroundTask method. When the task is finished, remember to call UIApplication.endBackgroundTask to notify the system that the task gets done. If you forget to call endBackgroundTask explicitly, the timeout will be triggered 30s after suspending the app, and the termination happens. So you should carefully handle background tasks and do not kick off any additional expensive works when your app enters background mode because we only have a few seconds of runtime. While debugging, XCode will generate a log message to notify if there is a task that has been held too long without ending. When seeing this message, you should do an audit to see what went wrong with the background task calls. 12345678Background task still not ended after expiration handlers were called: &lt;_UIBackgroundTaskInfo: 0x28190d140&gt;: taskID = 8, taskName = Called by AppGetKilled, from $s12AppGetKilled13SceneDelegateC23sceneDidEnterBackgroundyySo7UISceneCF, creationTime = 70784 (elapsed = 26). This app will likely be terminated by the system. Call UIApplication.endBackgroundTask(_:) to avoid this.Background Task 5 (\"Called by AppGetKilled, from $s12AppGetKilled13SceneDelegateC23sceneDidEnterBackgroundyySo7UISceneCF\"), was created over 30 seconds ago. In applications running in the background, this creates a risk of termination. Remember to call UIApplication.endBackgroundTask(_:) for your task in a timely manner to avoid this. ConclusionIn this post, I summarized the top 6 reasons why an app can be terminated in the background, how we can do to prevent the problems, and how to recover the app gracefully from unpredictable problems like Jetsam.You can find the full document and video at WWDC 2020 - Why is my app getting killed","link":"/2021/02/25/WWDC-2020-Top-reasons-why-app-get-killed-in-background/"},{"title":"Silent notification","text":"In the ever-evolving world of mobile app development, keeping users engaged and informed is key. For iOS developers, background notifications are a powerful tool that enhances user experience without interrupting their current activities. But what exactly are background notifications, and how do they work? Let’s dive into the details. What Are Background Notifications?Background notifications, or silent notifications, are a type of notification in iOS that allows apps to wake up and perform tasks in the background without alerting the user with a visible notification. Unlike standard notifications that appear on the screen and require user interaction, background notifications are designed to silently update the app’s content or perform background operations. These notifications are particularly useful for apps that need to keep data fresh or perform periodic tasks without bothering the user. For instance, a weather app can use background notifications to update weather information, or a news app can fetch the latest articles in the background. How Do Background Notifications Work?Background notifications rely on the Apple Push Notification Service (APNs), which is a service provided by Apple that delivers notifications to iOS devices. Here’s a simplified overview of how they work: App Registration: The app registers with APNs and receives a unique device token. Server Request: The app’s server sends a push notification request to APNs, specifying the device token and including the payload of the notification. Notification Delivery: APNs delivers the notification to the device. For background notifications, this payload includes the content-available key set to 1, indicating that the notification is intended to wake the app in the background. App Wake-Up: Upon receiving a background notification, iOS wakes up the app to handle the data or perform background tasks. This is done without displaying any visual alert to the user. Handling the Notification: The app’s code processes the notification in the background, updating content or performing necessary actions. Key Considerations Efficiency and Limitations: Background notifications should be used efficiently to avoid unnecessary use of battery and network resources. iOS may limit the frequency and size of background notifications to preserve system performance and battery life. User Privacy and Permissions: Even though background notifications do not display alerts, they still require user permission to receive notifications. Ensure that your app clearly communicates why it needs this permission. Handling Background Tasks: When handling background notifications, it’s crucial to manage tasks efficiently. iOS provides specific APIs for background tasks to ensure that operations are completed in a timely manner. Testing and Debugging: Testing background notifications can be challenging. Use debugging tools and simulators to test different scenarios and ensure your app handles notifications as expected. Practical Use Cases News Apps: Keep users updated with the latest headlines without prompting them with alerts. Social Media Apps: Update content feeds or notify the app about new messages or friend requests silently. Productivity Apps: Sync data or refresh content in the background to ensure users always have the latest information when they open the app. ConclusionBackground notifications in iOS are a powerful feature that enhances the functionality and user experience of mobile apps. By allowing apps to perform tasks in the background without disrupting the user, they enable more seamless and efficient interactions. However, they should be used thoughtfully to balance performance, battery life, and user experience.If you’re developing an iOS app, consider integrating background notifications to provide a more dynamic and responsive experience. With the right implementation, you can keep your app’s content fresh and your users engaged, all while maintaining a smooth and uninterrupted user experience.","link":"/2021/08/06/Silent-notification/"},{"title":"Two weeks at Fossil Group in the US","text":"Last week, I had a chance to visit the US again.","link":"/2019/05/19/Two-weeks-at-Fossil-Group-in-the-US/"},{"title":"Web Bluetooth","text":"Have you ever wanted to create a web application that enables users to communicate with your device using Bluetooth? Until the introduction of Web Bluetooth, this was only possible through native mobile apps. However, with the advent of Web Bluetooth you can now turn your idea into a reality.Web Bluetooth is a game-changing technology that allows web developers to connect their applications directly to Bluetooth devices, opening up a wide range of possibilities for IoT, wearables, and other Bluetooth-enabled devices. By leveraging the power of Web Bluetooth, you can create web applications that can communicate with devices without the need for a separate native app.So if you have been dreaming of creating a web application that can interact with Bluetooth devices, now is the time to explore the possibilities of Web Bluetooth and take your development skills to the next level. What is Web Bluetooth?Web Bluetooth is a set of APIs that provide ability to connect and perform actions such as read value, write data, listen to notifications, etc. with BLE peripherals using the Generic Attribute Profile (GATT). This can enable a wide range of use cases, such as controlling IoT devices, syncing fitness data from a smartwatch, or transferring data between a smartphone and a computer.Web Bluetooth is supported by several major web browsers, including Chrome, Firefox, and Opera, and it also includes a set of industry-standard protocols for secure and efficient communication. However, it is important to note that not all Bluetooth devices may be compatible with Web Bluetooth, as support for the technology varies across different devices and manufacturers. Upside of Web Bluetooth Cross-platform: Web Bluetooth allows developers to create web applications that can communicate with Bluetooth devices on multiple platforms, including desktop and mobile devices. Ease of use: Web Bluetooth simplifies the process of connecting to Bluetooth devices, reducing the need for complex native apps or software. Accessibility: Web Bluetooth enables web developers to create applications that can communicate with Bluetooth devices without requiring users to install separate apps or plugins. Flexibility: Web Bluetooth can be used to connect with a wide range of Bluetooth devices, including IoT devices, wearables, and smart home devices. Downside of Web Bluetooth Browser support: While most modern browsers support Web Bluetooth, some older browsers may not be compatible. Security: Web Bluetooth can present security risks if not implemented properly. For example, if an application has access to a user’s Bluetooth device, it may be able to access other sensitive information on the device. Limited functionality: Web Bluetooth may not offer the same level of functionality as native Bluetooth apps. This can limit the types of applications that can be developed using the technology. Battery life: Bluetooth can be a power-intensive technology, which can drain the battery life of mobile devices. Developers need to be mindful of this when designing applications that rely on Bluetooth connectivity. Supported APIsThe APIs supported by Web Bluetooth are similar to those available on iOS and Android, which makes it straightforward to work with for developers who are already familiar with Bluetooth technology on mobile devices.You can review the flow to estashlish a connection to a peripheral at Play Central And Peripheral Roles With CoreBluetooth navigator.bluetooth.requestDevice(): This API is used to request access to a nearby BLE device. When a user clicks a “Connect” button on your web application, this API is called to scan for available devices and present a dialog box to the user. 123456789101112131415161718192021222324/**// Discovery options match any devices advertising:// . The standard heart rate service. OR// . Service uuid0, and devices with name \"ExampleName1\", and devices with name starting with \"Prefix1\" OR// . Both service uuid1 and uuid2. OR// . Devices with name \"ExampleName2\". OR// . Devices with name starting with \"Prefix2\". OR//// And enables access to the battery service if devices// include it, even if devices do not advertise that service.**/const device = await navigator.bluetooth.requestDevice({ acceptAllDevices: true, filters: [ { services: [\"heart_rate\"] }, { services: [uuid0], name: \"ExampleName1\", namePrefix: \"Prefix1\" }, { services: [uuid1, uuid2] }, { name: \"ExampleName2\" }, { namePrefix: \"Prefix2\" } ], optionalServices: [ \"battery_service\", ],}); BluetoothDevice.gatt.connect(): This API is used to establish a connection with the GATT server on the selected BLE device. Once a connection is established, your web application can interact with the device’s services and characteristics. 1const server = await device.gatt.connect(); BluetoothDevice.gatt.disconnect(): This API is used to disconnect from the BLE device once the interaction is completed. 1const server = await device.gatt.disconnect(); Get services &amp; characteristics:BluetoothDevice.gatt.getPrimaryService(serviceUuid): This API is used to retrieve a primary service from the GATT server on the selected BLE device.BluetoothRemoteGATTService.getCharacteristic(characteristicUuid): This API is used to retrieve a specific characteristic from a service. 12345const services = await server.getPrimaryServices();services.forEach(async (e) =&gt; { const chars = await e.getCharacteristics(); // Doing your logic}); Read &amp; write value:BluetoothRemoteGATTCharacteristic.readValue(): This API is used to read the value of a characteristic.BluetoothRemoteGATTCharacteristic.writeValue(value): This API is used to write a value to a characteristic. 1234await char.writeValue( fromHexString(value));await char.readValue(); Listen to disconnected event: This event listener is triggered when the device disconnects from the GATT server. 123device.addEventListener('gattserverdisconnected', () =&gt; { // Your callback}); Listen to value changed: This event listener is triggered when the value of a characteristic changes. This can be used to receive real-time updates from the device. 123device.addEventListener('characteristicvaluechanged', () =&gt; { // Your callback}); Listen to notification 12await char.stopNotifications();await char.startNotifications(); A simple exampleAt Web Bluetooth example, I have created a simple website that showcases a set of APIs. This demo website provides developers with an easy-to-use interface for testing and understanding the functionality of the APIs. By accessing this demo website, developers can quickly gain insights into how the APIs can be integrated into their applications. By default, the web scan all nearby devices. To scan for specified devices with predefined uuid, select Filters and enter your service uuid to the filter box. Here is the UI after the connection has been established successfully. More samplesYou can find more examples and ideas via this video WebBluetooth demos for Bluetooth.rocks from Niels Leenheer on Vimeo. Limitations For security purposes, we can not automatically scan and connect to a specified device. The user decides whether the web app is allowed to connect, and to which device it is allowed to connect. HTTPS Connection: Web Bluetooth requires a secure HTTPS connection to function properly. This means that the web application must be hosted on a secure server with a valid SSL certificate. If the application is not hosted on a secure server, the user will not be able to connect to Bluetooth devices. Platforms: Web Bluetooth is supported in Chrome on desktop and mobile (Require Android 6+, does not support iOS), Opera, and some versions of Microsoft Edge. It’s important to note that Web Bluetooth may not work in older or outdated browsers. Customization: Unfortunately, it’s not possible to customize the scan dialog of Web Bluetooth to show additional information beyond the default options. The Web Bluetooth API is designed to provide a simple and consistent interface for developers, and the scan dialog is intentionally kept simple to maintain this simplicity. Performance: It’s widely recognized that the stability of Bluetooth connections on native Android apps is often not as reliable as on iOS, and can be affected by factors such as the phone model, manufacturer, and version of Android being used. As a result, it’s important to note that Web Bluetooth does not function as well as native apps, especially on Android devices. Tips &amp; best practicesHere are some tips and best practices for optimizing the performance of Web Bluetooth applications: Minimize data transfers: Bluetooth communication is slow compared to other communication channels. Therefore, it’s important to minimize the amount of data that your application sends and receives over Bluetooth. For example, you can reduce the number of read and write operations and only transfer the data that is necessary for your application. Use notifications instead of polling: Instead of continuously polling the value of a characteristic, use notifications to receive updates when the value changes. This approach can reduce the number of read operations and improve the performance of your application. Disconnect when not in use: Disconnect from the GATT server when you’re not actively communicating with the device. This can reduce power consumption and improve the battery life of the device. Use caching: Caching can be used to store data that is frequently accessed by your application. This can reduce the number of read operations and improve the performance of your application. Optimize the scanning process: Scanning for devices can be a resource-intensive operation. Therefore, it’s important to optimize the scanning process by reducing the scanning time and filtering the results to only include relevant devices. Test your application on different devices: Test your application on different devices to ensure that it performs well across different platforms and hardware configurations. Final thoughtDespite these limitations, Web Bluetooth remains a promising technology with many potential use cases. Developers who are interested in using Web Bluetooth should carefully consider these limitations and design their applications accordingly. Refs https://www.smashingmagazine.com/2019/02/introduction-to-webbluetooth/ https://googlechrome.github.io/samples/web-bluetooth/","link":"/2022/10/30/Web-Bluetooth/"},{"title":"What is refactoring?","text":"","link":"/2018/02/27/What-is-refactoring/"},{"title":"What&#39;s new in iPad OS 14?","text":"To see #5 top updates in iPadOS 14.","link":"/2020/06/26/What-s-new-in-iPad-OS-14/"},{"title":"Working In Thread Safe on iOS","text":"As you might know, the word “Thread safe” is referred to a computer science concept in the context of multi-thread programs. A code is called “Thread safe” if any shared data is accessed by only one thread at any given time. Notice these shared data are called critical sections in an operating system.The point is Swift collection types like Array and Dictionary are not thread-safe when declared mutable (With var keyword).In this post, we will discuss some techniques to make our code thread safe in iOS. Case studyLet’s say we have an array which contains crucial data. In reality, it can be an amount of money in a credit card, transaction states, etc. They are really important so if we don’t protect these values accurately, we will face significant errors at runtime.To simulate a race condition, I’m going to use DispatchQueue.concurrentPerform to create 10 concurrent threads running at the same time. 12345678910111213class ViewController: UIViewController { var array = [Int]() override func viewDidAppear(_ animated: Bool) { super.viewDidAppear(animated) // Do any additional setup after loading the view, typically from a nib. DispatchQueue.concurrentPerform(iterations: 10) { index in self.array.append(index) } } // The rest of code} The result of the above code is unpredictable. You will fall into 2 cases: Most of the times you run this code, you will get a run-time crash like thisThe fundamental problem is because Swift collections like Array and Dictionary are not thread-safe but we let multiple threads modify the array at the same time. Stackoverflow If you luckily don’t get this crash, the elements of the array will look random like this:Element count 5Element count 9Element count 10The point is we do not always get 10 elements as expected. How it happened?It’s not safe to let one thread modify the value while another is reading it. SolutionsThe way to avoid race conditions is to synchronize data, or the critical sections. Synchronizing data usually means to “lock” it so that only one thread can access that part of the code at a time.Since Swift does not support built-in concurrency solutions, we’re going to use Grand Central Dispatch to implement thread safe instead. Using serial queueBy leveraging serial queues, we can prevent race conditions on a resource. As I introduced how a serial queue works in a previous post, Grand-Central-Dispatch-in-Swift, a serial queue allows just only one process run at a time so the array is safe from concurrent processes. 123456789101112131415161718class SafetyArray&lt;T&gt; { var array = [T]() let serialQueue = DispatchQueue(label: \"com.uynguyen.queue\") var last: T? { var result: T? self.serialQueue.sync { result = self.array.last } return result } func append(_ newElement: T) { self.serialQueue.async() { self.array.append(newElement) } } } Although we protect the array from being accessed by multiple threads, using serial queue is not the best solution. Reading the last value is not optimized because multiple read requests have to wait for each other as it is in a serial queue. Reads should be able to happen concurrently, as long as we do not make a write at the same time. Using concurrent queue with the barrier flagThe main idea of this solution is using a concurrent queue instead of a serial queue.Swift supports us to dispatch a block of code to a concurrent queue with a flag called barrier. The barrier flag ensures that the concurrent queue does not execute any other tasks while executing the barrier process. Once the barrier process done, then the queue allows running other tasks simultaneously by default implementation. 123456789101112131415161718class SafeArray&lt;T&gt; { var array = [T]() let concurrentQueue = DispatchQueue(label: \"com.uynguyen.queue\", attributes: .concurrent) var last: T? { var result: T? self.concurrentQueue.sync { result = self.array.last } return result } func append(_ newElement: T) { self.concurrentQueue.async(flags: .barrier) { self.array.append(newElement) } } } We continue to use the sync method for reading the last element, but all readers will run in parallel this time since we are using a concurrent queue. The trade offWorking with multiple threads is a hard part of coding. Although we have to protect critical sections from multiple accesses, we should keep in mind that *”Keep the synchronized sections as small as possible because Locks create delays and add overhead. They are expensive”*. Clean code.Some tips to deal with concurrency: Concurrency does not always improve performance. It sometimes incurs some overhead and bugs come from it are not usually repeatable. Limit the access of the data that is shared between more than two threads. Use copies of data if there is a chance. Multithreaded code behaves differently in different environments: Run tests in every potential deployment environment. Final thoughtsThread safe is one of the most important concepts in computer science, especially in a system which allows accessing data simultaneously. Understand how to make code thread safe, we can avoid serious errors occurring at runtime.Happy coding.","link":"/2018/06/05/Working-In-Thread-Safe-on-iOS/"},{"title":"Hello World","text":"Welcome to Uy Nguyen’s blog!I love writing, so I build this site to write any stupid crap things in my life, my job or whatever related to Software Engineering. In this way, I remember these topics longer. I also want to share what I learned to anyone who needs it.Feel free to kick an email if you need to reach me. “Be a Software Engineer, not a Coder.” - Uy Nguyen","link":"/2017/08/01/hello-world/"},{"title":"Advanced iOS Concurrency: Operations [1]","text":"There are two techniques to deal with Concurrency in iOS: GCD - Grand Central Dispatch and Operations. Most of the time, GCD provides most of the concurrency capabilities you need. Yet, sometimes you’ll want some extra advanced customizations. It’s time to use Operations. This tutorial will introduce Operations in Swift, also explain when and why we use Operation instead of GCD.Let’s switch the gears! There is a big gap between knowing the path and walking through the path. Introduce OperationsOperation is a class allowing you to submit a block of code that should be run on a different thread, it is built on top of GCD. Basically, both GCD and operation roles are similar. However, operations have other benefits that give us more control over the task. OOP design: as the operation is a Swift class, you can subclass it and override its methods if need. It will be easy to use and re-use in the future. State management: An Operation has its own state machine that is changed during its lifecycle. The operation itself handles the changes of its states. We can not modify these states of an object. Dependency among operations: If you want to start a task after other tasks have finished executing, then the operation should be your choice. An operation will not start executing until all of the operations that it depends on have successfully finished their jobs. Cancel the submitted task: By using operations, we have the capability of canceling a running operation. It’s very useful in a case where we want to stop operations that are irrelevant at a certain time. For example, to cancel downloading data when the user scrolls the table making some cells disappear. Dependency and the capability of canceling making operations much more controllable over GCD. Take to practiceLet’s assume that we’re building an application that will fetch some posts of mine. After downloading the cover images, they will be applied a simple filter, then displayed in a table view.Go ahead and create a project. The project simply contains only one main screen with a table view that displays posts with a title and a cover image. To simplify the source of data, I created a JSON file that contains 100 rows describing a post with key as title and value as the url linked to the cover image. 123456789[ // input.json {\"Building your personal page with Hexo\": \"https://uynguyen.github.io/Post-Resources/Hexo/Cover.png\"}, {\"Beta Test and TestFlight\": \"https://uynguyen.github.io/Post-Resources/TestFlight/Cover.png\"}, {\"iOS: Mix and Match\": \"https://uynguyen.github.io/Post-Resources/MixMatch/mix-match-banner.png\"}, {\"Best practice: Core Data Concurrency\": \"https://uynguyen.github.io/Post-Resources/CoreDataConcurrency/banner.png\"}, {\"Two weeks at Fossil Group in the US\": \"https://uynguyen.github.io/Post-Resources/Fossil_Group/Fossil_Group.jpg\"}, ...] Inside the MainViewController, let’s read the input file 12345678910111213141516171819202122class ViewController: UIViewController { @IBOutlet weak var tbPosts: UITableView! var urls = [(title: String, url: String)]() override func viewDidLoad() { super.viewDidLoad() self.setup() // ... } func setup() { let inputUrl = Bundle.main.url(forResource: \"input\", withExtension: \"json\")! do { let data = try Data(contentsOf: inputUrl) if let jsonDict = try JSONSerialization.jsonObject(with: data) as? [[String: String]] { self.urls = jsonDict.map { ($0.first!.key, $0.first!.value) } } } catch { } } By using a simple function of CoreImage, the grayScale(input:) method will transform a UIImage to a black-white image with the Tonal filter 12345678910111213141516171819func grayScale(input: UIImage) -&gt; UIImage? { let context = CIContext(options: nil) var inputImage = CIImage(image: input) let filters = inputImage!.autoAdjustmentFilters() for filter: CIFilter in filters { filter.setValue(inputImage, forKey: kCIInputImageKey) inputImage = filter.outputImage } let cgImage = context.createCGImage(inputImage!, from: inputImage!.extent) let currentFilter = CIFilter(name: \"CIPhotoEffectTonal\") currentFilter!.setValue(CIImage(image: UIImage(cgImage: cgImage!)), forKey: kCIInputImageKey) let output = currentFilter!.outputImage let cgimg = context.createCGImage(output!, from: output!.extent) return UIImage(cgImage: cgimg!)} It’s time to set up the table view, we use URLSession to download the image from the input url, then display to the cell after downloading successfully. 1234567891011121314151617181920extension ViewController: UITableViewDataSource { // The rest omitted func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell { let cell = tableView.dequeueReusableCell(withIdentifier: \"CellId\", for: indexPath) as! PostTableViewCell let input = urls[indexPath.row] URLSession.shared.dataTask(with: URL(string: input.url)!, completionHandler: { (data, res, error) in guard error == nil, let data = data, let image = UIImage(data: data) else { return } DispatchQueue.main.async { cell.lblPostTitle.text = input.title cell.imgPostImage.image = self.grayScale(input: image) } }).resume() return cell }} Build and run the project, you should see the images appear on the list. Let’s try to scroll the table. Can you feel laggy?You might notice where the issue comes from. To set up a cell, we first download the image from the internet, then apply a Tonal filter to the image. These two actions are performing in the main thread, putting too much pressure on the thread that should only use for user interaction. Using GCDWe can dispatch the code of downloading and filtering image to another separated queue 12345678910111213DispatchQueue.global(qos: .background).async { URLSession.shared.dataTask(with: URL(string: input.url)!, completionHandler: { (data, res, error) in guard error == nil, let data = data, let image = UIImage(data: data) else { return } let filteredImage = self.grayScale(input: image) DispatchQueue.main.async { cell.lblPostTitle.text = input.title cell.imgPostImage.image = filteredImage } }).resume()} By executing the code on a background queue, we offload work to the main queue and make the UI much more responsive.Rebuild the project, you will see the differences.Even we resolve the issue of user interaction, the performance of the app is still not optimized.What can be done to make this better?As the user scrolls the table, cells come and gone. There’s no sense in continuing to download and process an image of an invisible cell. It’s better to cancel the block of code to improve the performance and reduce the battery consumption of the app. But how we can cancel a task that is running in GCD?Here is the Operation come to. Switch gear to OperationLet’s break the task to set up a table view cell into two tasks: one is to download the image and another is to apply the filter. 12345678910111213141516171819class DownloadImageOperation: Operation { let url: URL var outputImage: UIImage? init(url: URL) { self.url = url } override func main() { guard !isCancelled else { return } URLSession.shared.dataTask(with: self.url, completionHandler: { (data, res, error) in guard error == nil, let data = data else { return } self.outputImage = UIImage(data: data) }).resume() }} 123456789101112131415161718192021222324252627282930313233343536class ImageFilterOperation: Operation { let context = CIContext(options: nil) var processedImage: UIImage? func grayScale(input: UIImage) -&gt; UIImage? { var inputImage = CIImage(image: input) let filters = inputImage!.autoAdjustmentFilters() for filter: CIFilter in filters { filter.setValue(inputImage, forKey: kCIInputImageKey) inputImage = filter.outputImage } let cgImage = context.createCGImage(inputImage!, from: inputImage!.extent) let currentFilter = CIFilter(name: \"CIPhotoEffectTonal\") currentFilter!.setValue(CIImage(image: UIImage(cgImage: cgImage!)), forKey: kCIInputImageKey) let output = currentFilter!.outputImage let cgimg = context.createCGImage(output!, from: output!.extent) return UIImage(cgImage: cgimg!) } override func main() { guard !isCancelled else { return } let dependencyImage = self.dependencies .compactMap { $0 as? DownloadImageOperation } .first if let image = dependencyImage?.outputImage { guard !isCancelled else { return } self.processedImage = self.grayScale(input: image) } }} To use Operation, we simply subclass the Operation class and override the main method where our task is placed. By default, operations run in the background, so there are no worries about blocking the main thread.Back to the task to set up the table view cell, you might notice that there is a dependency between these two tasks, we only do the filter process after downloading the image. In other words, the ImageFilterOperation operation depends on the DownloadImageOperation operation. Operation Dependencies is one of the “killer functions” of Operation along with the capability of canceling a running operation. By linking the two operations, we ensure that the dependent operation does not begin before the prerequisite operation has completed. Additionally, the linking makes a clean way to pass data from the first one to the second one. 1234e.glet dependencyImage = self.dependencies .compactMap { $0 as? DownloadImageOperation } .first It’s time to do the improvement.Let’s first define an OperationQueue to the ViewController. The OperationQueue class is what we use to manage Operations. 123456789101112131415161718192021222324class ViewController: UIViewController { private let queue = OperationQueue() // The rest omiited // ... func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell { let cell = tableView.dequeueReusableCell(withIdentifier: \"CellId\", for: indexPath) as! PostTableViewCell let input = urls[indexPath.row] let downloadOpt = DownloadImageOperation(url: URL(string: input.url)!) let grayScaleOpt = ImageFilterOperation() grayScaleOpt.addDependency(downloadOpt) grayScaleOpt.completionBlock = { DispatchQueue.main.async { cell.lblPostTitle.text = input.title cell.imgPostImage.contentMode = .scaleToFill cell.imgPostImage.image = grayScaleOpt.processedImage } } self.queue.addOperation(downloadOpt) self.queue.addOperation(grayScaleOpt) return cell }} Here, we init two new instances of the DownloadImageOperation and the ImageFilterOperation classes. Then, we set grayScaleOpt operation depend to downloadOpt that will make sure the grayScaleOpt only be executed after the downloadOpt has completed. Finally, we add these two operations to the OperationQueue. Once an operation is added to the queue, the operation will be scheduled. If the queue finds an available thread on which to run the operation, the job will be executed until it has completed or been canceled. When the operation completes, the completionBlock is called. “Operations have important effects on your application’s performance. For instance, if you want to download a lot of content from the Internet, you might want to do so only when it is absolutely necessary. Also, you might decide to ensure that only a specific number of operations can run at the same time. If you do decide to limit the number of concurrent operations in a queue, you can change the maxConcurrentOperationCount property of your operation queue. This is an integer property that allows you to specify how many operations, at most, can run in a queue at a given time.” (iOS 8 Swift Programming Cookbook) Learning the above theories is enough, now re-build the project to see the result. Ops! Nothing appears, the image is not downloaded! Something went wrong ???In the next tutorial, we will find out what happened to our code and why the Operation did not work properly as expected.Thank you for reading.","link":"/2020/05/16/iOS-Concurrency-Operations/"},{"title":"iOS: Introducing Stack Views Programmatically","text":"As your iOS development skill is growing, I believe you use UIScrollView, UICollectionView, UITableView, and other native views regularly and proficiently in your applications. Yet, some iOS developers still don’t know what exactly UIStackView is, what it uses for or in which situation should we use UIStackView.In this tutorial, I will introduce you to UIStackView - A view helps us to simplify our iOS layouts. Let’s imagine you’re going to build an application that allows the user to add or remove views in run time. Remember how we will accomplish this task? We first have to remove all constraints in the relative area and update them all over again. Or remember the case where you implement the sign-in / sign-up view, you add many text fields and manually set constraints between those views. In such situations, UIStackView appears to be more useful than other views. To demonstrate how to apply UIStackView to your projects, we’re going to build a simple application that allows the user to control smart devices in their home; Users can add or remove which room they want it to show in their list of control. The main key here is all actions of the user are executed in runtime dynamically. Additionally, instead of using Storyboard in this project, I’m going to use code dynamically along with the help of the AutoLayout framework (SnapKit - it is just a matter of preference). Let’s put aside other complex implementation, the application contains only two views: A login view and a home page. Also, there will be no logic code at all. Key propertiesTo understand how a Stack View work, we first need to have a look at its properties. No matter what kind of the Stack View is (Horizontal or Vertical), there are four main properties: Axis, Spacing, Alignment, and Distribution. The following image summarizes the relative among those attributes. Axis: determines the stack’s orientation, including Horizontal and Vertical. Spacing: determines the minimum space between the stack’s views. Alignment: determines the layout of the stack’s views perpendicular to its axis.Both horizontal and vertical stack views have the Fill and Center options. Fill: Stack’s arranged views will be resized so that they fit the stack view perpendicularly to its axis. The leading and trailing edges of vertically stacked items or the top and bottom edges of horizontally, respectively. Center: As the name suggests, center the stack’s views horizontally (Vertical stack) or vertically (Horizontal stack). Fill Center There are some alignment options applied only for horizontal stack views: Top: As the name suggests, center the stack’s views horizontally (Vertical stack) or vertically (Horizontal stack). Bottom: As the name suggests, center the stack’s views horizontally (Vertical stack) or vertically (Horizontal stack). First baseline: A layout where the stack view aligns its arranged views based on their first baseline. Last baseline: A layout where the stack view aligns its arranged views based on their last baseline. Top Bottom First baseline Last baseline Similarly, there are some alignment options worked for vertical stack views only: Leading: The stack view aligns the leading edge (Left) of its arranged views along its leading edge. Similar to top alignment for horizontal stacks. Trailing: The stack view aligns the trailing edge (Right) of its arranged views along its leading edge. Similar to bottom alignment for horizontal stacks. Leading Trailing Distribution: determines the layout of the stack’s views along its axis. The subviews are all resized based on this setting. Fill: This is set as the default distribution when a Stack View is created. When we put views inside a UIStackView with Fill set as the distribution, it will keep trying to stretch the size one of the views to fill the space.So the question is, what criteria will it base on to choose the view to resize? Content Hugging Priority (CHP) will be. To determine which view will be stretched, the stack view will rely on CHP for evaluation, the lower its priority, the more likely it is to be chosen. If all the views have the same CHP, the first one will be picked. Fill Equally: Each control in a UIStackView will be of equal size. Fill Proportionally: All the controls need to have an intrinsic content size, Stack view will ensure the controls maintain the same proportion. Equal Spacing: This distribution type will maintain equal spacing between the subviews. Equal Centering: This distribution type will maintain an equal space between the center of the subviews. Fill Fill Equally Fill Proportionally Equal Spacing Equal Centering Note: UIStackView is a non-rendering view, which means you can not set the background-color property, or override the draw method, etc. Take to practiceNow, with that knowledge in mind, we’re going to apply it to an existed project that currently does not use UIStackView to arrange its view at all. By applying UIStackView into practice, we will really get an understanding of how a UIStackView works and what problems it can resolve. Auto arrange viewsThe first thing UIStackView brings to us is the freedom from setting constraints for all views.The login view is quite simple, it contains two text fields, a login button and some text labels. Without using UIStackView, we have to manually set constraints for all those text fields. 12345678910111213141516171819view.addSubview(lblLogin)lblLogin.snp.makeConstraints { (make) in make.centerX.equalToSuperview() make.centerY.equalToSuperview().offset(-250) make.left.equalToSuperview().offset(20) make.right.equalToSuperview().offset(-20) make.height.equalTo(30)}view.addSubview(lblUsername)lblUsername.snp.makeConstraints { (make) in make.centerX.left.right.equalTo(lblLogin) make.top.equalTo(lblLogin.snp.bottom).offset(30) make.height.equalTo(30)}view.addSubView(btnLogin)//...// The rest omitted But it’s still not a nightmare. Imagine now you want to add some other views, such as a label and a switch view to allow the user to remember the login session. We now have to alter all other views to insert those new views to the right place on the screen! The task will be easier and simpler if we use StackView. Now let see how we can do it.First, let’s add a new property to the Log in view controller. 12345678910111213lazy var stackView: UIStackView = { let stack = UIStackView() stack.axis = .vertical stack.spacing = 20.0 stack.alignment = .fill stack.distribution = .fillEqually [self.lblUsername, self.txtUserName, self.lblPassword, self.txtPassword, self.btnLogin].forEach { stack.addArrangedSubview($0) } [1] return stack}() Notice at [1], this is how we add arraged views to a stack view. Then, we just need to set contraints for the stackView. 12345678910override func viewDidLoad() { super.viewDidLoad() // ... view.addSubview(stackView) stackView.snp.makeConstraints { (make) in make.centerX.left.right.equalTo(lblLogin) make.top.equalTo(lblLogin.snp.bottom).offset(30) make.height.equalTo(280) }} In the future, if we want to add new views, we just need to put it to the arranged views array. As below. 123456789lazy var keepLoginStackView: UIStackView = { let stackView = UIStackView() stackView.axis = .horizontal stackView.alignment = .trailing stackView.distribution = .fill [self.lblRememberMe, self.swKeepLogin].forEach { stackView.addArrangedSubview($0) } return stackView}() 12345// ...self.txtPassword,self.keepLoginStackView,self.btnLogin].forEach { stack.addArrangedSubview($0) }// ... Can you see the differences? The codebase now is cleaner and more maintainable than the old one, isn’t it? Dynamic viewsNow switch to the case where we will implement the Home page of the application.When the user presses the right button of the screen, a new view, which represents for a room to be controlled in this case, will be placed on the main page. The user can also remove any rooms in the list by pressing the “Remove” button. Inside each room, there is a “Hide” / “Show” button that allows hiding and showing the room image. Remember in the past where you have to implement a similar feature in your app without using UIStackView, what will you do? Somewhat painful! We first need to remove all constraints in the relative area and update them all over again. Here is what we’re going to do with UIStackView, the main page contains a vertical stack view embedded inside a scroll view. Whenever the Add button is pressed, a new TaskView view will be added to this stack view. 1234567func addMoreView() { let view = TaskView(delegate: self, data: room[Int.random(in: 0..&lt;room.count)]) let constraint1 = view.heightAnchor.constraint(lessThanOrEqualToConstant: 400.0) constraint1.isActive = true self.taskStackView.addArrangedSubview(view) self.view.layoutIfNeeded()} We also need to set height constraints for this new view. Because the height of the view might be changed when the show/hide button is pressed, we need to define this constraint as lessThanOrEqualToConstant:value so that the stack view can adjust this height constraint. 12345678910func onRemove(_ view: TaskView) { if let first = self.taskStackView.arrangedSubviews.first(where: { $0 === view }) { UIView.animate(withDuration: 0.3, animations: { first.isHidden = true first.removeFromSuperview() }) { (_) in self.view.layoutIfNeeded() } }} When the remove button on a task view is clicked, this view will be removed from the stack view. We can access all arranged views of a stack view by accessing arrangedSubviews property. We first loop for all arranged views and find the appropriate view which have the same address with the sender, then remove it from the super view. Additionally, I make a small animation, UIView.animate(withDuration:animations:), so that the transition looks more smooth and fancier than the last one.By using the same approach, you can do the same thing when the user clicks on Show / Hide button to show/hide the image view. Let’s take a try by yourself. Final thoughIn this tutorial, I introduced you to UIStackView - a subclass of UIView helping to manages the position and size of its arranged views. We also worked through a demonstration that takes UIStackView into practice. Now you get the idea of how the UIStackView works and what the UIStackView uses for, next times try to use UIStackView in your app to leverage its power. I will do, won’t you?You can download the completed demo at Github,Happy coding!","link":"/2020/07/18/iOS-Introducing-Stack-Views/"},{"title":"What&#39;s new of Appclip on iOS 17?","text":"With the introduction of iOS 17, applications now have the ability to launch App Clips from other apps using the App Clip’s invocation URL. This functionality opens up various possibilities. For instance, if you’ve developed a suite of apps, you can enable them to launch App Clips from one another, providing users with access to specific functionalities without the need for a full app installation. Furthermore, your app could extend the offer to launch App Clips from other developers if your workflows involve interactions with those apps. This collaborative approach enhances user convenience, allowing them to seamlessly navigate between apps and leverage diverse functionalities. The interconnectivity fostered by this feature promotes a more integrated and user-centric experience within the iOS ecosystem. https://developer.apple.com/videos/play/wwdc2023/10178/","link":"/2023/11/09/What-s-new-of-Appclip-on-iOS-17/"},{"title":"Series React Native and BLE: Part 2 - Building BLE framework for Android","text":"When it comes to mobile technology, iOS and Android are the two dominant operating systems that power the majority of smartphones and tablets worldwide. As developers, it is essential that we have the knowledge and tools to work with both platforms effectively. This is especially true when it comes to utilizing Bluetooth technology, which is a crucial component of many modern mobile applications.In part 1 of this tutorial series, we created a BLE (Bluetooth Low Energy) framework that could be connected to the UI using React Native. However, this framework only worked on iOS, which meant that we needed to develop a separate solution for Android.In part 2 of this tutorial series, we will be focusing on defining a new SDK for Android and linking it to the UI, just as we did on iOS. This will allow us to fully support both operating systems and provide a seamless Bluetooth experience for all users, regardless of their device of choice. Create new Android SDKThe very first step is to create your own Bluetooth library. Normally, engineers tend to use an open-source library such as RxAndroidBle or Android-BLE-Library powered by Nordic. However, the main goal of this tutorial is to guide you on how to create a new Android module and link it to React Native. This not only applies to Bluetooth but also to any library that you need to use in your app. The other goal is to gain foundational knowledge of Android BLE in case you need to modify something or create your own feature that has not been supported in the market. By creating your own Bluetooth library, you have the freedom to customize and tailor the library to your specific needs. This can provide significant advantages over using pre-existing libraries, as you can optimize the library for your particular use case and avoid potential compatibility issues. From your project, go to File &gt; New &gt; New Module &gt; Fill in the information.A new library will be added to your project. One major different thing from Android and iOS is that from Android 6.0, Google requires the Location Permission to be enabled for Bluetooth Low Energy Scanning (See more Android 6.0 Changes). Next, add the following permissions to your AndroidManifest.xml at android/app/src/main/AndroidManifest.xml 123&lt;uses-permission android:name=\"android.permission.BLUETOOTH\" /&gt;&lt;uses-permission android:name=\"android.permission.BLUETOOTH_ADMIN\" /&gt;&lt;uses-permission android:name=\"android.permission.ACCESS_FINE_LOCATION\" /&gt; note:123456Android 12 update:From Android 12 (API level 31+):- Google requires new permission for scanning nearby devices: + If your app looks for Bluetooth devices, such as BLE peripherals, declare the BLUETOOTH_SCAN permission. + If your app communicates with already-paired Bluetooth devices, declare the BLUETOOTH_CONNECT permission.- If your app does not use Bluetooth scan results for physical location, you can skip declaring location permission by adding `android:usesPermissionFlags` For demo purposes, the SDK exposes only 2 simple APIs startScan to start scanning nearby devices and isBluetoothOn to check if the Bluetooth is turned on. 12345/*Start scanning nearby devices.Accept `callback` as param and return found devices via `callback`*/fun startScan(callback: (device: Device) -&gt; Unit) 1234/*Check if BLE is ready for scanning*/fun isBluetoothOn() : Boolean To request permission on React Native, we’re going to use this module https://github.com/zoontek/react-native-permissions to get the permissions the app needs. Build and release Android SDK moduleNext, let’s distribute the module so that other applications can use it.From the root folder, run ./gradlew kTrackingSDK:assembleRelease to generate an .aar file.The output file will be located at ./KTrackingSDK/build/outputs/aar, then you can import the .aar file to the android project. Connect to React Native partNow, we’ve already had the Bluetooth lib. The next step is to link the module to the React Native part. Firstly, React Native part needs to understand the Native module. Add the following config to your /src/main/java 1234567891011121314151617181920212223242526272829class BLEManager(context: ReactApplicationContext) : ReactContextBaseJavaModule(context) { init { Log.d(\"BLEManager\", \"Init package\") BLEManagerLib.shared.config(context) } override fun getName(): String { return \"BLEManager\" } @ReactMethod fun isBluetoothOn(promise: Promise) { promise.resolve(BLEManagerLib.shared.isBluetoothOn()) } @ReactMethod fun startScanning() { Log.d(\"BLEManager\", \"Start scanning\") BLEManagerLib.shared.startScan { val params: WritableMap = Arguments.createMap() params.putString(\"name\", it.name) params.putInt(\"rssi\", it.rssi) params.putString(\"address\", it.address) this.reactApplicationContext .getJSModule(RCTDeviceEventEmitter::class.java) .emit(\"didFoundDevice\", params) } }} Creating new file to define the BLEManagerPackage 1234567891011class BLEManagerPackage: ReactPackage { override fun createNativeModules(reactContext: ReactApplicationContext): MutableList&lt;NativeModule&gt; { val modules = ArrayList&lt;NativeModule&gt;() modules.add(BLEManager(reactContext)) return modules } override fun createViewManagers(reactContext: ReactApplicationContext): MutableList&lt;ViewManager&lt;View, ReactShadowNode&lt;*&gt;&gt;&gt; { return ArrayList() }} Next, add it to the package list in MainApplication.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class MainApplication extends Application implements ReactApplication { ... @Override protected List&lt;ReactPackage&gt; getPackages() { Log.d(\"BLEManager\", \"Running\"); @SuppressWarnings(\"UnnecessaryLocalVariable\") List&lt;ReactPackage&gt; packages = new PackageList(this).getPackages(); /* Add your custom modules here */ packages.add(new BLEManagerPackage()); /* */ return packages; } ...}Finally, the app needs to ask users to grant permission.```js// somewhere in your codeimport { check, PERMISSIONS, request, RESULTS } from 'react-native-permissions';checkPermission = () =&gt; { check(PERMISSIONS.ANDROID.ACCESS_FINE_LOCATION) .then((result) =&gt; { if (result !== RESULTS.GRANTED) { requestLocation(() =&gt; { // On granted }, () =&gt; { // On denied }); } }) .catch((error) =&gt; { // … });}requestLocation = (grantedCallback, deniedCallback) =&gt; { request(PERMISSIONS.ANDROID.ACCESS_FINE_LOCATION).then(result =&gt; { switch (result) { case RESULTS.DENIED: console.log('User denied permission',); deniedCallback(); break; case RESULTS.GRANTED: console.log('The permission is granted'); grantedCallback(); break; } });} ResultSince we use the same code for both Android and iOS in the React Native part, there is no need to modify the React Native code from the previous tutorial. As long as you follow to the protocol we defined, everything should function as intended. By maintaining a consistent protocol across both platforms, we can ensure that the code is easily portable and that any changes made to one platform will not affect the other. This can significantly streamline the development process and reduce the risk of errors or compatibility issues. ConclusionAfter spending countless hours researching and experimenting, we have finally learned how to create our own Bluetooth library and use it in our React Native project. With this newfound knowledge, the process of adding new features has become significantly easier and more efficient. We only need to implement the logic in Native Code instead of having to develop the UI part twice. This has not only saved us a tremendous amount of time and effort but also allowed us to focus more on enhancing the functionality of our app. We can now dedicate more resources to developing new features, optimizing existing ones, and improving the overall user experience. Moreover, our newfound ability to create custom libraries has opened up a whole new world of possibilities for our development team. We can now leverage our knowledge of React Native to create even more advanced and innovative features, all while maintaining a streamlined development process. Happy coding! Refs Android Native Modules. Android Bluetooth permissions.","link":"/2022/02/13/Series-React-Native-and-BLE-Part-2-Building-BLE-framework-for-Android/"},{"title":"Swift Summit conference in San Francisco 2017","text":"Swift Summit Conference 2017 was held at the Palace Of Fine Arts, San Francisco, which is one of ten palaces at the heart of the Panama-Pacific Exhibition. At the conference, Swift developers from around the world shared new knowledge, tools and ideas on iOS platform and Swift language. Image 1. I was there, at the Swift Summit conference 2017 The conference hosted more than 20 technical sessions and developer labs. Especially, there was an exhibitor hall with top tech companies like Facebook, IBM, Lyft, Capital One, etc. There, I met other developers, talked about new technologies and received swags from sponsors. Image 2. My bag (And another one of my friend's) was full of swags from the conference :)). Ten days to enjoy the US, two days to enjoy the conferenceAs it had been the first time I go to San Francisco, I was not comfortable with the weather there. I remember that in the first morning day I went to the Palace of Fine Arts, the weather was 13c degree at that time. I was freezing to death!When I first entered the main hall, I felt better because of the warm light. The organizers prepared a lot of food and fruits on a table in the center of the hall. My friends and I went around to visit tech companies, tried using their new technologies, and received their swags.The size of the conference was not as I expected. It was quite small, about one hundred people, I guess. But the organizers and the speakers prepared contents very well. Below are some key sessions that I attribute the best during two conference days. Asynchronous programmingAsynchronous methods, (Async for short), are the methods that not immediately returning results like most method, the async methods take some time to produce results.Before attending this session, I often use callback to deal with asynchronous methods like scanning bluetooth devices or retrieving some resources from the internet. In fact, callback is a bad programming technique. Callback will make our code hard to read, hard to debug and take much more time to maintain later. In the end, our code will turn into something that we call the callback hell.In this session, the speaker introduced a framework that helps us to simplify asynchronous programming, PromiseKit. It is easy to learn, easy to use and result in clearer, more readable code.For more details about this session, please refer to another one of my posts: Asynchronous Programming in Swift BuglifeBugLife is an open framework help our users to submit a bug report from their phone, and it immediately shows up in our issue dashboard. The best benefits that I found when I use BugLife are it is free and is easy to integrate to our apps without breaking a sweat.For more details about how to use this framework, please refer to another one of my posts: BugLife in real life MixpanelMixpanel is a library help us to track user behaviors and other events that occur on our apps. Many technology companies use Mixpanel to analyze their data to get to know their users deeper. From the results, they can make decisions to improve their app to please users. Image 3. Developers were attending a developer Lab. Swift on the Server: State of the UnionThis session described the current state of Swift on the server, and make some predictions about what the next year will hold. Unfortunately, I fell asleep in this session so I dont catch many ideas from the speaker.For more details about how to use this framework, please refer to another one of my posts: Swift on the server side iOS Architectures in ContextWhy we have to care about choosing an architecture?Nowadays, we have so many software architectures to choose, if we do not choose a fit architecture for our apps, one day we will find ourselves in being unable to find and fix any issues inside our apps. During this session, the speaker discussed on some iOS architectures like MVC, MVP, MVVM, VIPER, etc. With many years of experience working on software architectures, he evaluated on both upside and downside one by one.For me, this session was quite difficult to grab all ideas of the speaker since I don’t have many experiences in designing software architectures. After that, I had to spend more time to read other documents and technical blogs to get understand what he said. Image 4. The scene around the conference After all …Late on the second day, we had a Halloween party in the hall of the palace. This is my first time attending a technology conference in a technology-led country, the US. After two days attending the conference, I have updated some new technologies and also applied some technologies to projects at my company. Truly to say, there are some sessions that are a little boring and only introductory. Also the jet lag made me feel tired so I did not fully concentrate on some sessions. That’s a regret.In the end, this is still the best trip ever! Image 5. An unforgetable trip","link":"/2017/11/29/Swift-Summit-conference-in-San-Francisco-2017/"},{"title":"iOS: Mix and Match","text":"As Swift has been becoming a flagship language for iOS development, most of the new iOS projects nowadays are built in Swift. However, there are many useful libraries are developed in other low-level programming languages such as Objective-C and / or C++ to boost performance. On the other hand, not all engineering positions are open to new projects, most of them are hired to maintain and develop new features based on the current code base that are built-in Objective-C.Having the knowledge to mix the two languages within a single project is good for your iOS development skills as you will face it someday in your career path. In this post, I’m going to show you not only how to use Objective-C and Swift in one single project but also how to use a set of programming languages in a single one, including C++/ Objective-C/ Swift and React Native. Hope you will find this post interesting.Let’s drive-in. C++ &lt;- Objective-C++For those who have not heard about Objective-C++,Objective-C++ is Objective-C is actually a source code that mixes Objective-C classes and C++ classes in one single file.You just need to change your .m file to .mm to get the magic worked.First, I will create a C++ library that will be used by Objective-C++ classes. 1234class CPlusPlusMath { public: int multiplyTwoNumbers(int a, int b);}; The implementation 123int CPlusPlusMath::multiplyTwoNumbers(int a, int b) { return a * b;} Then, you need to create a bridging header file to your project because our new project is in Swift language. The bridging header is where you define all the Objective-C classes that are exposed to Swift. When we add a new Objective-C class to the Swift code-based project, XCode automatically offers to add this file to the project.Next, you rename the .m file to .mm to change it from Objective-C code to Objective-C++.From now on, you can call to our C++ lib (or other ones) inside this Objective-C++ file 12345678#import \"CPlusPlusMath.hpp\"@implementation ObjMath- (long)multiplyTwoNumbers:(int) num1 num2:(int) num2 { CPlusPlusMath *a = new CPlusPlusMath(); return a-&gt;multiplyTwoNumbers(num1, num2);} Objective-C++ &lt;-&gt; SwiftThe interesting thing is we can call Objective-C(++) code from Swift code and vise versa.To use Objective-C classes from Swift, we need to declare their headers to the bridging header file. Let’s go ahead and include our mathematical library to this file. 12345//// Use this file to import your target's public headers that you would like to expose to Swift.//#include \"ObjMath.h\" That’s all you need to do to build the first line from Objective-C to Swift. 1234func multiply(num1: Int, num2: Int) -&gt; Int { let objMath = ObjMath() return objMath.multiplyTwoNumbers(Int32(num1), num2: Int32(num2))} Next, we need to build the other line from Swift to Objective-C.We use objc keyword before any classes and methods we want to expose to Objective-C classes. A small note is that these exposed classes need to be inherited from the NSObject class. Otherwiser, we will get the complile error Only classes that inherit from NSObject can be declared @objc. 123456789@objcclass SwifthMath: NSObject { @objc func add(num1: Int, num2: Int) -&gt; Int { return num1 + num2 } // The rest omited} Swift &lt;-&gt; React NativePlease find my series at React Native and BLE Limitation Swift objects can have a subclass of an objective-c class, like NSObject. But a swift class cannot be a base class for an objective-c class. TroubleshootConclusionsMany developers are still using Objective-C for many reasons, and they definitely use C++ libraries in their projects, especially in Game development where C++ reaches full its performance.I hope that this post will give you a quick look at how to Mix and Match multiple languages in a single project.You can find the demonstration project at GithubThanks for reading.","link":"/2020/01/30/iOS-Mix-and-Match/"},{"title":"Best practice: iOS vs Android Bluetooth","text":"Bluetooth technology has become an integral part of modern mobile applications, enabling seamless wireless communication between devices. Whether it’s for connecting to a wireless headset, transferring files, or interacting with smart home devices, Bluetooth plays a crucial role in enhancing user experience. For mobile developers, understanding how to implement Bluetooth functionality is essential. In this post, we’ll dive into a detailed comparison of the Bluetooth development frameworks for iOS and Android. We’ll explore the key differences and similarities between these two platforms, covering everything from initial setup to data transfer and error handling. By the end of this comparison, you’ll have a clear understanding of how to leverage Bluetooth technology in your mobile applications, regardless of whether you’re developing for iOS or Android. To have a better visualization, I made an image below to summarize of the flow to establish a connection on Android and iOS At first glance, the two flows appear quite similar. However, the Android flow includes extra steps. Although the connection process is more complex on Android compared to iOS, it provides greater control over the returned data. Let’s break down the flow into three major steps for discussion: Scanning, Getting Ready, Interacting, and Closing. Each of these steps involves specific actions and considerations that contribute to the overall functionality and efficiency of the connection process. ScanningIn the scanning phase, the processes are quite similar between Android and iOS, from initiating a scan to creating a connection. The main difference is that there is more information about the peripheral in the scan result on Android than on iOS. The most interesting value is the MAC address of the device. iOS does not expose this value and instead provides a random UUID.UUIDs on iOS are generated per application and per device pairing, and their lifespan is tied to the session or until the device is forgotten, so do not rely on it to identify or reconnect to your devices. iOS does not expose the MAC address for several reasons, primarily related to privacy and security. By hiding the MAC address, Apple ensures that apps and third parties cannot misuse this information for tracking or profiling users and also helps prevent illegal activities by attackers. One possible solution to overcome this limitation is to include your own unique identifier in the advertising packet, which will be available on all platforms. Another important note is that the Android OS prevents scan start-stops more than approximately 5 times in 30 seconds (please note that this value varies from device to device). Calling the startScan method too frequently in a short time will lead to no devices being discovered. The last common value is the signal strength value, RSSI (Received Signal Strength Indicator), which indicates how far the device is from the phone. The range is from -30 to -99; the closer the value is to -30, the closer the device. Getting ReadyOnce your device has been discovered, the next step is to make it ready so you can perform read and write actions. There are two different approaches to making a device “ready.” The first approach is action on-demand, which involves doing nothing until necessary. This means you don’t need to discover services/characteristics or set notifications until your application performs read or write commands. The advantage is a shorter connection phase, as your application doesn’t need to discover all services and characteristics, set notifications, or handle errors if any fail. The disadvantage is that the first read or write operation will take more time. The second approach involves discovering all Bluetooth profiles upfront and making the device ready for any command. The downsides and upsides are the opposite of the first approach. There is nothing right or wrong with each approach; it’s just a matter of preference. So choose the one that suits you best. For me, I prefer to go with the second approach, as described in the image. The setup phase on iOS is quite simple. Your application just needs to discover all services. For each service, you then call to discover all its characteristics. Finally, set notifications if the characteristics support value changes. You might want to keep a reference to each characteristic item (CBPeripheral) so you can perform read and write operations. On the other hand, the “make ready” flow is quite complicated for Android. If you’re an iOS developer, you might not interact much with the GATT Descriptor in your application. First, you need to get familiar with the GATT Descriptor and MTU (Maximum Transmission Unit) concepts. GATT Descriptor provides extra information about the characteristic they are associated with. For example, when you read a temperature value from a BLE thermometer, the characteristic might have a descriptor indicating the unit of measurement in Celsius or Fahrenheit. The most common GATT Descriptor is the Client Characteristic Configuration Descriptor (CCCD), which you will use to enable/disable notifications/indicators for a characteristic.The main difference in notification and indication types is the reliability. Notifications are sent by the peripheral without requiring an acknowledgment from the central device. In contrast, indications require an acknowledgment from the central device. It’s simple to set a notification on iOS by calling CBCharacteristic.setNotify() and the system will do the rest for you. It will automatically identify the notification type and set the correct value. On Android, you must call it yourself. The following sample code demonstrates how you can set a notification for your characteristic on Android: 12345678910111213141516171819202122232425262728final UUID CCCD_UUID = UUID.fromString(\"00002902-0000-1000-8000-00805f9b34fb\");if (!gattServer.setCharacteristicNotification(characteristic, true)) { return false;}final boolean canNotify = (characteristic.getProperties() &amp; BluetoothGattCharacteristic.PROPERTY_NOTIFY) &gt; 0;final boolean canIndicate = (characteristic.getProperties() &amp; BluetoothGattCharacteristic.PROPERTY_INDICATE) &gt; 0;if (!canNotify &amp;&amp; !canIndicate) { // Do not support notification/indication, doing nothing return true;}final BluetoothGattDescriptor cccDescriptor = characteristic.getDescriptor(CCCD_UUID);if (cccDescriptor == null) { // Can't find the descriptor on the characteristic? return false;}if (cccDescriptor.setValue(canNotify ? BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE : BluetoothGattDescriptor.ENABLE_INDICATION_VALUE)) { gattServer.writeDescriptor(cccDescriptor); return true;}return false; The final step is optional: request to change the MTU value.MTU (Maximum Transmission Unit) refers to the largest amount of data that can be sent in a single Bluetooth packet. By default, the MTU value in BLE is 23 bytes, in other words, for a single read and write command, the maximum bytes your application/device can deliver is 23 bytes (with a 3-byte header), but it can be negotiated between the central and peripheral devices up to 517 bytes. In iOS, you don’t directly request an MTU size; instead, the MTU is automatically negotiated between the central and peripheral devices during the connection process. On Android, use BluetoothGatt.requestMtu() to request a specific MTU size and handle the response in BluetoothGattCallback.onMtuChanged(). It’s a common mistake to forget to increase the MTU while your device is sending more than 20 bytes per request, leading to missing data in the packet. One important comment regarding establishing connections is that there is a maximum number of devices that can connect simultaneously. There are no offical documents for this number, but many developers have found that on iOS around 7 - 10 devices, while on Android it around 10 - 20 depends on phone model and Android version. 123456789101112private final BluetoothGattCallback gattCallback = new BluetoothGattCallback() { @Override public void onMtuChanged(BluetoothGatt gatt, int mtu, int status) { if (status == BluetoothGatt.GATT_SUCCESS) { // MTU size change successful Log.d(\"MTU\", \"MTU changed to \" + mtu); } else { // MTU size change failed Log.d(\"MTU\", \"MTU change failed with status \" + status); } }}; InteractingUpon completing all the steps above successfully, your device is now ready to use. You can read values from a characteristic, transfer data to a specific one, or read the RSSI value to determine the distance. Make sure you handle the value changes properly by checking from which characteristic the value comes. It is worth mentioning that on iOS, if your application transfers a large amount of data to the device (e.g., transferring a file), you should wait for the next peripheralIsReady event to be triggered before sending the next packet. Continuously sending multiple packets without waiting for this event might put pressure on the queueing buffers, leading to missing packet. 123func peripheralIsReady(toSendWriteWithoutResponse peripheral: CBPeripheral) { // Ready to send next packet} ClosingOnce again, the disconnection step on iOS is very simple. You just need to call the cancelPeripheralConnection method. On Android, you need to do more than one operation: disconnect the device and close the Bluetooth GATT. Remember that calling disconnect only cancels the connection with the peripheral, it does not release all the resources (e.g., available slots in the Bluetooth stack) until you call close. You use disconnect when you want to temporarily end the connection but might reconnect to the device later without needing to fully reset the GATT configuration. You use close when you are done with the Bluetooth connection entirely and want to ensure all resources are cleaned up. ConclusionIn this post, we explored the important points of implementing Bluetooth functionality in mobile applications for iOS and Android. Through our detailed comparison, several key points emerged that highlight both the similarities and differences between these two platforms. iOS Core Bluetooth offers a robust and straightforward framework that integrates seamlessly with the iOS ecosystem. It provides a clean and consistent API. The Android Bluetooth, on the other hand, offers flexibility, extensive capabilities and it supports a wide range of Bluetooth functionalities. While the setup and implementation might be slightly more complex compared to iOS, Android’s Bluetooth API provides powerful tools for handling Bluetooth interactions effectively. RefsThe Ultimate Guide to Android Bluetooth Low EnergyThe Ultimate Guide to Apple’s Core Bluetooth","link":"/2024/06/30/Best-practice-iOS-vs-Android-Bluetooth/"},{"title":"Android Bluetooth: A Pitfall","text":"Developing BLE-enabled Android apps is fraught with challenges, especially when it comes to managing concurrent operations. One of the most common pitfalls developers face is the unexpected behavior that occurs when trying to execute BLE operations in rapid succession. In this blog post, we’ll delve into why this happens and how you can overcome it by implementing a custom queuing mechanism for BLE operations. If you’ve worked with BLE on Android, you may have encountered a frustrating issue: when you attempt to execute multiple BLE operations one after another, like reading and writing characteristics or descriptors, only the first operation succeeds, while the others seem to disappear. This is more than just a minor inconvenience; it’s a serious problem because your app logic often depends on the successful completion of these operations. Without them, your UI can’t update with the fresh data from your connected device, leading to a poor user experience. So, what’s going on under the hood? The core issue lies in how Android’s BLE stack handles operations. BLE operations are asynchronous, meaning they don’t complete instantaneously. When you execute the BLE stack with multiple requests in quick succession, the system struggles to keep up, leading to dropped operations and unpredictable behavior. The Conventional Approach: Callback-Based SolutionsOne way to mitigate this issue is by using callbacks to sequence your BLE operations.For example, you might wait for the onCharacteristicWrite() callback to trigger before starting the next operation. This works for simple use cases where your BLE interactions are limited to a single screen or Activity.However, this approach quickly becomes unmanageable as the complexity of your app grows. As you add more BLE operations—such as reading and writing descriptors, handling connections and disconnections, updating the MTU, and performing service discovery. You’ll find that a more scalable solution is needed. The Scalable Solution: Implementing a Queuing MechanismTo handle BLE operations more reliably, a custom queuing mechanism is essential. By queuing BLE operations, you ensure that each operation is executed sequentially, only after the previous operation has either succeeded or failed. This approach not only prevents operations from being dropped but also simplifies the management of BLE tasks across your app. Here’s a basic outline of how you might implement such a mechanism: Create a Queue: Start by creating a queue (such as a LinkedList or Queue) to hold your BLE operations. Each operation can be represented as a task or command object that contains the details of the operation you want to perform. Operation Handler: Implement a handler or manager class responsible for processing the operations in the queue. This class should listen for the completion of each BLE operation, whether it succeeds or fails, before dequeuing and executing the next operation. Callback Integration: Modify your existing BLE callbacks (like onCharacteristicWrite(), onCharacteristicRead(), etc.) to trigger the dequeuing and execution of the next operation in the queue. Error Handling: Implement error handling to ensure that failed operations don’t block the queue. You might also want to perform retry logic for transient errors. UI Updates: Since your UI may depend on the outcome of BLE operations, ensure that your queue manager triggers appropriate UI updates once operations complete. 1234567891011121314151617181920212223242526272829303132333435363738394041424344class BLEManager { ConcurrentLinkedQueue&lt;BLEBaseCommand&gt; commandQueue = new ConcurrentLinkedQueue&lt;&gt;(); // Note that we're using a ConcurrentLinkedQueue to prevent concurrency issues. private void terminateCommands() { commandQueue.clear(); currentCommand = null; } private void enqueueCommand(BLEBaseCommand command) { commandQueue.offer(command); if (currentCommand == null) { executeNextCommand(); } } private void signalCommandEnd() { currentCommand = null; if (!commandQueue.isEmpty()) { // Has remaining command? executeNextCommand(); } } private void executeNextCommand() { BLEBaseCommand next = commandQueue.poll(); if (next == null) { // All done return; } currentCommand = next; try { if (!currentCommand.execute()) { runOnUiThread(currentCommand.fallback); // Handle your error from `fallback` function depends on the command signalCommandEnd(); } } catch (Exception ex) { signalCommandEnd(); } } private void runOnUiThread(Runnable runnable) { new Handler(Looper.getMainLooper()).post(runnable); }} Somewhere from your BluetoothGattCallback class. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Override public void onConnectionStateChange(BluetoothGatt gatt, int status, int newState) { // Your logic manager.signalCommandEnd();}@Overridepublic void onServiceChanged(@NonNull BluetoothGatt gatt) { // Your logic manager.signalCommandEnd();}@Overridepublic void onServicesDiscovered(BluetoothGatt gatt, int status) { // Your logic manager.signalCommandEnd();}@Overridepublic void onCharacteristicRead(BluetoothGatt gatt, BluetoothGattCharacteristic characteristic, int status) { // Your logic manager.signalCommandEnd();}@Overridepublic void onCharacteristicWrite(BluetoothGatt gatt, BluetoothGattCharacteristic characteristic, int status) { // Your logic manager.signalCommandEnd();}@Overridepublic void onDescriptorRead(BluetoothGatt gatt, BluetoothGattDescriptor descriptor, int status) { // Your logic manager.signalCommandEnd();}@Overridepublic void onDescriptorWrite(BluetoothGatt gatt, BluetoothGattDescriptor descriptor, int status) { // Your logic manager.signalCommandEnd();}@Overridepublic void onReadRemoteRssi(BluetoothGatt gatt, int rssi, int status) { // Your logic manager.signalCommandEnd();}@Overridepublic void onMtuChanged(BluetoothGatt gatt, int mtu, int status) { // Your logic manager.signalCommandEnd();} Below is the basic class diagram Why This MattersImplementing a queuing mechanism for BLE operations isn’t just about avoiding dropped operations; it’s about creating a more reliable and scalable architecture for your app. As you expand your app’s BLE functionality, you’ll be thankful for the stability and predictability that a queuing system provides. It’s worth mentioning that more modern paradigms like RxJava or Kotlin framework can offer even more elegant solutions to this problem. These tools can help you manage asynchronous operations with greater flexibility and less boilerplate code. However, for many developers, a custom queuing mechanism provides a solid foundation that can be easily understood and implemented without introducing additional dependencies. We might discuss this in another thread. ConclusionBLE on Android can be challenging, but with the right strategies, you can build robust applications that reliably communicate with BLE devices. By implementing a custom queuing mechanism, you can overcome many of the concurrency-related issues. Whether you’re just starting with BLE or looking to enhance your existing apps, adopting a queuing approach will make your development process smoother and your applications more reliable.Happy Coding!","link":"/2024/08/04/Android-Bluetooth-A-Pitfall/"},{"title":"Bluetooth security: Pairing and Bonding","text":"In modern times, Bluetooth plays a crucial role in connecting devices seamlessly. From fitness trackers to smart home devices, Bluetooth Low Energy (BLE) allows devices to communicate efficiently while reducing power consumption. However, with the rise of wireless communication, ensuring security has become a key concern. Two core concepts of Bluetooth security are Pairing and Bonding, which are often misunderstood in the context of BLE. Ensuring that devices pair and bond securely is critical for protecting sensitive data. Improper implementation of these processes can lead to several types of attacks. For example, attackers can intercept communications and steal valuable information. In this blog, we’ll explore what pairing and bonding are, why they are important for security, and how they work in practice, particularly for mobile applications. Low level: Security Manager (SM)At the core of BLE security is the Security Manager (SM), a crucial component that manages various security functions. The SM handles the exchange of security keys and ensures that all data transmitted between devices is encrypted and protected from unauthorized access. Key responsibilities of the SM include managing pairing, bonding, encryption and authentication, and key management. The SM provides different authentication methods for different levels of security: Just Works: No authentication involved. Used for low-security applications. Passkey Entry: A passkey (PIN) is entered on one or both devices to authenticate. Numeric Comparison: Both devices display a number, and the user must confirm that they match. Out-of-Band (OOB): Another wireless technology, like NFC, is used to exchange information, providing enhanced security. Establish pairing and bonding sequencePairing is the process of establishing a secure communication link between two Bluetooth devices. This step is essential to ensure that the devices can share data securely. During the pairing process, the devices exchange information, authenticate each other, and create encryption keys to protect the data being transmitted. Bonding is the next step after pairing. Once two devices successfully pair, they can store the encryption keys and related security information for future use. It ensures that devices don’t need to pair again the next time they connect. By storing these keys, devices can reconnect more quickly and securely in the future. In a high level, steps in the pairing and bonding process include: PAIRING Initiating: One device sends a pairing request to the other. Exchanging Security Parameters: Devices share their capabilities, including available authentication methods. Authentication: Depending on the available methods (Just Works, Passkey Entry, Numeric Comparison, or Out-of-Band), the devices authenticate themselves. Key Generation: Encryption keys are generated and used to secure the communication. Establishing Encryption: Devices begin encrypted communication after the keys are successfully exchanged. BONDING Storing Security Information: After pairing, both devices save encryption keys for future connections. Reconnection: During future interactions, devices can use the saved keys to re-establish a secure, encrypted link without repeating the pairing process. Below is a summary of the flow in the example of a mobile device (central) and a peripheral (e.g., smartwatches, monitors, etc.). Mobile application sideiOS does not provide an explicit bonding API. However, the bonding process occurs transparently when you connect to a BLE device that requires it, and the OS will prompt the user for necessary authentication. The pairing request is usually triggered by accessing secured characteristics. In contrast, you have more control over the pairing and bonding proces in Android. 1234567891011121314151617181920212223242526272829BluetoothDevice device = bluetoothAdapter.getRemoteDevice(deviceAddress);// Checking bond stateint bondState = device.getBondState();if (bondState == BluetoothDevice.BOND_BONDED) { // Already bonded} else { // Create bond device.createBond();}...// Moniroting updatesBroadcastReceiver receiver = new BroadcastReceiver() { @Override public void onReceive(Context context, Intent intent) { final String action = intent.getAction(); if (BluetoothDevice.ACTION_BOND_STATE_CHANGED.equals(action)) { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); if (bondState == BluetoothDevice.BOND_BONDED) { // Device is bonded } else if (bondState == BluetoothDevice.BOND_BONDING) { // Bonding in progress } else if (bondState == BluetoothDevice.BOND_NONE) { // Bonding failed } } }}; On Android, there is no public API to programmatically remove a bonded device. However, there is a private API method available that can be accessed using reflection to remove a bond. Kindly note that, because this is a private API, it is unsupported by Google, and using it in production code may result in unpredictable behavior on certain devices or your application being rejected during Google’s review process. 123456789public static boolean removeBond(BluetoothDevice device) { try { Method removeBondMethod = BluetoothDevice.class.getMethod(\"removeBond\"); return (boolean) removeBondMethod.invoke(device); } catch (Exception e) { e.printStackTrace(); } return false;} Best practiceWhile working with devices that need encrypted data, I ran into some issues. Below are the key points I’ve learned, which might help save you time: To support auto-connect from the iOS system, the device must contain either the HID profile or be subscribed to the ANCS profile of the phone. On Android, the OS does not auto-reconnect to the device when bonding; it’s the job of your services. The iOS system automatically shows the pairing pop-up immediately after successfully calling connect to the device if it contains the HID profile. Removing all encrypted characteristics of the HID profile from your device prevents the system from automatically showing the pairing pop-up. When reading a custom encrypted characteristic of the GATT profile, the pairing request pop-up will appear. The OS will still auto-connect to the device after pairing it with our encrypted characteristic, even if the HID device is unencrypted. Use Strong Authentication Methods: Prefer Numeric Comparison or Passkey Entry over Just Works. Update Encryption Protocols: Ensure that your devices use modern, strong encryption protocols. ConclusionBluetooth pairing and bonding are foundational processes that enable secure communication between devices. By understanding these mechanisms, developers can significantly enhance the security of their Bluetooth connections. As the number of connected devices grows, ensuring strong Bluetooth security will continue to be a priority for safeguarding personal-sensity data. Refs Kevin Townsend, Carles Cufí, Akiba, Robert Davidson - Getting Started with Bluetooth Low Energy_ Tools and Techniques for Low-Power Networking-O’Reilly Media (2014) How iOS and Android Handle Connections with BLE Human Interface Devices, Punch Through BLE Pairing and Bonding","link":"/2024/08/31/Bluetooth-security-Pairing-and-Bonding/"},{"title":"iOS 18: What&#39;s news in CoreBluetooth?","text":"AccessorySetupKit, introduced in iOS 18, revolutionizes how third-party Bluetooth and Wi-Fi accessories integrate with iOS devices. This framework delivers a seamless setup experience, enhancing convenience for users and expanding capabilities for developers.While AccessorySetupKit supports discovery for Bluetooth, Wi-Fi, and Local Network devices, this post will focus specifically on BLE (Bluetooth Low Energy). The setup process for Wi-Fi and Local Network devices follows a similar approach. Key FeaturesBelow, we’ll explore the key functionalities that make AccessorySetupKit a major change for accessory management. Streamlined Pairing Process: Users can now pair or unpair accessories and toggle Bluetooth directly within the app, eliminating the need to go through system settings. This streamlined approach enhances the user experience and reduces setup time. Unified Access Management: Once an accessory is paired, it appears in the new “Accessories” section within the Privacy settings. Here, users can manage permissions and view connected devices, providing a centralized location for accessory management. Enhanced Developer Control: Developers can define scanning filters and provide custom images and names for devices, ensuring branded setup experience. Setup flowYou can find the example project provided by Apple on WWWDC24.To simulate the accessories, I used CoreBluetooth and defined my Bluetooth profile with two different UUIDs: 1FA2FD8A-17E0-4D3B-AF45-305DA6130E39 and 1FA2FD8A-17E0-4D3B-AF45-305DA6130E38, then started advertising them.Next, you need to modify the scanning UUID service in your Info.plist file to match your Bluetooth profiles. This informs the system of the accessory types your app supports.Apple supports different filter types, such as: 123456789101112131415161718&lt;dict&gt; &lt;key&gt;NSAccessorySetupBluetoothCompanyIdentifiers&lt;/key&gt; &lt;array&gt; #Matches the key of an advertised manufacturing data field &lt;/array&gt; &lt;key&gt;NSAccessorySetupBluetoothServices&lt;/key&gt; &lt;array&gt; #Matches either an advertised service UUID field or the key (service UUID) of an advertised service data field &lt;/array&gt; &lt;key&gt;NSAccessorySetupBluetoothNames&lt;/key&gt; &lt;array&gt; #Match any substring within the advertised name &lt;/array&gt; &lt;key&gt;NSAccessorySetupKitSupports&lt;/key&gt; &lt;array&gt; &lt;string&gt;Bluetooth&lt;/string&gt; &lt;/array&gt;&lt;/dict&gt; Next, create an ASAccessorySession. This session is essential for managing the accessory setup process, enabling you to present the accessory picker to users and handle various accessory-related events efficiently. 1private var session = ASAccessorySession() Then, present the Accessory Picker. This allows you to display the picker interface, enabling users to easily select and pair their accessories with the app. 123456789101112131415161718192021222324252627let pickerDevice1: ASPickerDisplayItem = { let descriptor = ASDiscoveryDescriptor() descriptor.bluetoothServiceUUID = ### return ASPickerDisplayItem( name: ###, productImage: UIImage(named: ###)!, descriptor: descriptor )}()let pickerDevice2: ASPickerDisplayItem = { let descriptor = ASDiscoveryDescriptor() descriptor.bluetoothServiceUUID = ### return ASPickerDisplayItem( name: ###, productImage: UIImage(named: ###)!, descriptor: descriptor )}()session.showPicker(for: [pickerDevice1, pickerDevice2]) { error in if let error { print(\"Failed to show picker due to: \\(error.localizedDescription)\") }} The user will now see a list of discovered devices and can select one to begin the pairing process, following the standard flow. 1234567891011121314151617private func handleSessionEvent(event: ASAccessoryEvent) { switch event.eventType { case .accessoryAdded, .accessoryChanged: guard let device = event.accessory else { return } # Save your device case .activated: guard let device = session.accessories.first else { return } # Save your device case .accessoryRemoved: # Clean up case .pickerDidPresent: # Your logic case .pickerDidDismiss: # Your logic default: ### }} What’s importants?AccessorySetupKit streamlines the setup process for users, making it more intuitive and efficient while eliminating the complexity often associated with connecting third-party accessories.For developers, it provides a standardized integration framework, ensuring consistent user experiences and simplified codebases. By adopting AccessorySetupKit, developers can deliver a seamless and cohesive experience that aligns third-party accessories with the high standards users associate with Apple products. RefsMeet AccessorySetupKit, WWWDC 2024iOS 18 AccessorySetupKit: Everything BLE Developers Need To Know","link":"/2024/11/03/iOS-18-What-s-news-in-CoreBluetooth/"}],"tags":[{"name":"Concurrency","slug":"Concurrency","link":"/tags/Concurrency/"},{"name":"Operations","slug":"Operations","link":"/tags/Operations/"},{"name":"iOS","slug":"iOS","link":"/tags/iOS/"},{"name":"Swift","slug":"Swift","link":"/tags/Swift/"},{"name":"BLE","slug":"BLE","link":"/tags/BLE/"},{"name":"Core Data","slug":"Core-Data","link":"/tags/Core-Data/"},{"name":"Bluetooth","slug":"Bluetooth","link":"/tags/Bluetooth/"},{"name":"Appclip","slug":"Appclip","link":"/tags/Appclip/"},{"name":"Objective-C","slug":"Objective-C","link":"/tags/Objective-C/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Vendor","slug":"Vendor","link":"/tags/Vendor/"},{"name":"Study","slug":"Study","link":"/tags/Study/"},{"name":"CoreBluetooh","slug":"CoreBluetooh","link":"/tags/CoreBluetooh/"},{"name":"WatchOS","slug":"WatchOS","link":"/tags/WatchOS/"},{"name":"Design Patterns","slug":"Design-Patterns","link":"/tags/Design-Patterns/"},{"name":"UML","slug":"UML","link":"/tags/UML/"},{"name":"Software Architecture","slug":"Software-Architecture","link":"/tags/Software-Architecture/"},{"name":"DispatchQueue","slug":"DispatchQueue","link":"/tags/DispatchQueue/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"Cocoa","slug":"Cocoa","link":"/tags/Cocoa/"},{"name":"Memory management","slug":"Memory-management","link":"/tags/Memory-management/"},{"name":"ReactNative","slug":"ReactNative","link":"/tags/ReactNative/"},{"name":"CrossPlatform","slug":"CrossPlatform","link":"/tags/CrossPlatform/"},{"name":"Notification","slug":"Notification","link":"/tags/Notification/"},{"name":"Books","slug":"Books","link":"/tags/Books/"},{"name":"iBeacon","slug":"iBeacon","link":"/tags/iBeacon/"},{"name":"books","slug":"books","link":"/tags/books/"},{"name":"study","slug":"study","link":"/tags/study/"},{"name":"Web Bluetooth","slug":"Web-Bluetooth","link":"/tags/Web-Bluetooth/"},{"name":"UI","slug":"UI","link":"/tags/UI/"},{"name":"UIStackView","slug":"UIStackView","link":"/tags/UIStackView/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"Conference","slug":"Conference","link":"/tags/Conference/"}],"categories":[]}